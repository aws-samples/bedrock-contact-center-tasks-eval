{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "import yaml\n",
    "import time\n",
    "import glob\n",
    "import logging\n",
    "import pandas as pd\n",
    "from typing import Dict\n",
    "from pathlib import Path\n",
    "from tokenizer_utils import count_tokens\n",
    "from bedrock_utils import get_bedrock_client\n",
    "from utils import  (\n",
    "    get_rouge_l_score,\n",
    "    get_cosine_similarity,\n",
    "    parse_model_response,\n",
    "    is_amazon_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global constants\n",
    "CONFIG_FILE_PATH = \"config.yaml\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-04 18:08:37,215] p93154 {2625127137.py:5} INFO - config read from config.yaml -> {\n",
      "  \"app_name\": \"contact-center-transcript-summarization\",\n",
      "  \"aws\": {\n",
      "    \"region\": \"us-east-1\",\n",
      "    \"sagemaker_execution_role\": \"Admin\"\n",
      "  },\n",
      "  \"dir\": {\n",
      "    \"data\": \"data\",\n",
      "    \"raw\": \"data/raw\",\n",
      "    \"golden\": \"data/raw/golden\",\n",
      "    \"prompts\": \"data/prompts\",\n",
      "    \"models\": \"data/models\",\n",
      "    \"metrics\": \"data/metrics\",\n",
      "    \"completions\": \"data/completions\"\n",
      "  },\n",
      "  \"data\": {\n",
      "    \"raw_data_file\": \"data.csv\",\n",
      "    \"golden_transcript\": \"data/raw/golden/transcript.txt\",\n",
      "    \"golden_transcript_summary\": \"data/raw/golden/summary.txt\"\n",
      "  },\n",
      "  \"prompt\": {\n",
      "    \"very_large_prompt\": {\n",
      "      \"sleep_time\": 180,\n",
      "      \"threshold\": 70000\n",
      "    },\n",
      "    \"normal_prompt\": {\n",
      "      \"sleep_time\": 60\n",
      "    }\n",
      "  },\n",
      "  \"max_retries\": 3,\n",
      "  \"desired_word_count_for_summary\": 80,\n",
      "  \"experiments\": [\n",
      "    {\n",
      "      \"name\": \"single-line-reason\",\n",
      "      \"prompt_template\": null,\n",
      "      \"reps\": 3,\n",
      "      \"model_list\": [\n",
      "        {\n",
      "          \"model\": \"anthropic.claude-instant-v1\",\n",
      "          \"prompt_template\": \"anthropic_template_single_line_reason.txt\"\n",
      "        },\n",
      "        {\n",
      "          \"model\": \"amazon.titan-text-express-v1\",\n",
      "          \"prompt_template\": \"titan_template.txt\"\n",
      "        },\n",
      "        {\n",
      "          \"model\": \"cohere.command-text-v14\",\n",
      "          \"prompt_template\": \"cohere_template.txt\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"bedrock_models\": {\n",
      "    \"cohere.command-text-v14\": {\n",
      "      \"context_length\": 4000,\n",
      "      \"prompt_token_pricing_per_million\": 1.5,\n",
      "      \"completion_token_pricing_per_million\": 2.0,\n",
      "      \"inference_param_set\": \"cohere\"\n",
      "    },\n",
      "    \"amazon.titan-text-express-v1\": {\n",
      "      \"context_length\": 8000,\n",
      "      \"prompt_token_pricing_per_million\": 0.8,\n",
      "      \"completion_token_pricing_per_million\": 1.6,\n",
      "      \"inference_param_set\": \"titan\"\n",
      "    },\n",
      "    \"anthropic.claude-v2:1\": {\n",
      "      \"context_length\": 100000,\n",
      "      \"prompt_token_pricing_per_million\": 8,\n",
      "      \"completion_token_pricing_per_million\": 24,\n",
      "      \"inference_param_set\": \"claude\"\n",
      "    },\n",
      "    \"anthropic.claude-instant-v1\": {\n",
      "      \"context_length\": 9000,\n",
      "      \"prompt_token_pricing_per_million\": 1.63,\n",
      "      \"completion_token_pricing_per_million\": 5.51,\n",
      "      \"inference_param_set\": \"claude\"\n",
      "    }\n",
      "  },\n",
      "  \"inference_params\": {\n",
      "    \"claude\": {\n",
      "      \"max_tokens_to_sample\": 512,\n",
      "      \"temperature\": 0.1,\n",
      "      \"top_k\": 250,\n",
      "      \"top_p\": 0.5,\n",
      "      \"stop_sequences\": [],\n",
      "      \"anthropic_version\": \"bedrock-2023-05-31\"\n",
      "    },\n",
      "    \"titan\": {\n",
      "      \"maxTokenCount\": 512,\n",
      "      \"stopSequences\": [],\n",
      "      \"temperature\": 0.1,\n",
      "      \"topP\": 0.9\n",
      "    },\n",
      "    \"cohere\": {\n",
      "      \"max_tokens\": 512,\n",
      "      \"temperature\": 0.1,\n",
      "      \"p\": 0.9,\n",
      "      \"k\": 0\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# read the config yaml file\n",
    "fpath = CONFIG_FILE_PATH\n",
    "with open(fpath, 'r') as yaml_in:\n",
    "    config = yaml.safe_load(yaml_in)\n",
    "logger.info(f\"config read from {fpath} -> {json.dumps(config, indent=2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-04 18:08:37,234] p93154 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new client\n",
      "  Using region: None\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock-runtime(https://bedrock-runtime.us-east-1.amazonaws.com)\n"
     ]
    }
   ],
   "source": [
    "bedrock_client = get_bedrock_client()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-04 18:08:37,305] p93154 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new client\n",
      "  Using region: None\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock(https://bedrock.us-east-1.amazonaws.com)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelArn</th>\n",
       "      <th>modelId</th>\n",
       "      <th>modelName</th>\n",
       "      <th>providerName</th>\n",
       "      <th>inputModalities</th>\n",
       "      <th>outputModalities</th>\n",
       "      <th>responseStreamingSupported</th>\n",
       "      <th>customizationsSupported</th>\n",
       "      <th>inferenceTypesSupported</th>\n",
       "      <th>modelLifecycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-tg1-large</td>\n",
       "      <td>Titan Text Large</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-e1t-medium</td>\n",
       "      <td>Titan Text Embeddings</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[EMBEDDING]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'LEGACY'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-image-generator-v1:0</td>\n",
       "      <td>Titan Image Generator G1</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT, IMAGE]</td>\n",
       "      <td>[IMAGE]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[FINE_TUNING]</td>\n",
       "      <td>[ON_DEMAND, PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-image-generator-v1</td>\n",
       "      <td>Titan Image Generator G1</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT, IMAGE]</td>\n",
       "      <td>[IMAGE]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-embed-g1-text-02</td>\n",
       "      <td>Titan Text Embeddings v2</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[EMBEDDING]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-text-lite-v1:0:4k</td>\n",
       "      <td>Titan Text G1 - Lite</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[FINE_TUNING, CONTINUED_PRE_TRAINING]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-text-lite-v1</td>\n",
       "      <td>Titan Text G1 - Lite</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-text-express-v1:0:8k</td>\n",
       "      <td>Titan Text G1 - Express</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[FINE_TUNING, CONTINUED_PRE_TRAINING]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-text-express-v1</td>\n",
       "      <td>Titan Text G1 - Express</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-embed-text-v1:2:8k</td>\n",
       "      <td>Titan Embeddings G1 - Text</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[EMBEDDING]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-embed-text-v1</td>\n",
       "      <td>Titan Embeddings G1 - Text</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[EMBEDDING]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-embed-image-v1:0</td>\n",
       "      <td>Titan Multimodal Embeddings G1</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT, IMAGE]</td>\n",
       "      <td>[EMBEDDING]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[FINE_TUNING]</td>\n",
       "      <td>[ON_DEMAND, PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-embed-image-v1</td>\n",
       "      <td>Titan Multimodal Embeddings G1</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT, IMAGE]</td>\n",
       "      <td>[EMBEDDING]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/st...</td>\n",
       "      <td>stability.stable-diffusion-xl</td>\n",
       "      <td>SDXL 0.8</td>\n",
       "      <td>Stability AI</td>\n",
       "      <td>[TEXT, IMAGE]</td>\n",
       "      <td>[IMAGE]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/st...</td>\n",
       "      <td>stability.stable-diffusion-xl-v0</td>\n",
       "      <td>SDXL 0.8</td>\n",
       "      <td>Stability AI</td>\n",
       "      <td>[TEXT, IMAGE]</td>\n",
       "      <td>[IMAGE]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/st...</td>\n",
       "      <td>stability.stable-diffusion-xl-v1:0</td>\n",
       "      <td>SDXL 1.0</td>\n",
       "      <td>Stability AI</td>\n",
       "      <td>[TEXT, IMAGE]</td>\n",
       "      <td>[IMAGE]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/st...</td>\n",
       "      <td>stability.stable-diffusion-xl-v1</td>\n",
       "      <td>SDXL 1.0</td>\n",
       "      <td>Stability AI</td>\n",
       "      <td>[TEXT, IMAGE]</td>\n",
       "      <td>[IMAGE]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/ai...</td>\n",
       "      <td>ai21.j2-grande-instruct</td>\n",
       "      <td>J2 Grande Instruct</td>\n",
       "      <td>AI21 Labs</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/ai...</td>\n",
       "      <td>ai21.j2-jumbo-instruct</td>\n",
       "      <td>J2 Jumbo Instruct</td>\n",
       "      <td>AI21 Labs</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/ai...</td>\n",
       "      <td>ai21.j2-mid</td>\n",
       "      <td>Jurassic-2 Mid</td>\n",
       "      <td>AI21 Labs</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/ai...</td>\n",
       "      <td>ai21.j2-mid-v1</td>\n",
       "      <td>Jurassic-2 Mid</td>\n",
       "      <td>AI21 Labs</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/ai...</td>\n",
       "      <td>ai21.j2-ultra</td>\n",
       "      <td>Jurassic-2 Ultra</td>\n",
       "      <td>AI21 Labs</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/ai...</td>\n",
       "      <td>ai21.j2-ultra-v1</td>\n",
       "      <td>Jurassic-2 Ultra</td>\n",
       "      <td>AI21 Labs</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/an...</td>\n",
       "      <td>anthropic.claude-instant-v1:2:100k</td>\n",
       "      <td>Claude Instant</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/an...</td>\n",
       "      <td>anthropic.claude-instant-v1</td>\n",
       "      <td>Claude Instant</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/an...</td>\n",
       "      <td>anthropic.claude-v1</td>\n",
       "      <td>Claude</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'LEGACY'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/an...</td>\n",
       "      <td>anthropic.claude-v2:0:18k</td>\n",
       "      <td>Claude</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/an...</td>\n",
       "      <td>anthropic.claude-v2:0:100k</td>\n",
       "      <td>Claude</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/an...</td>\n",
       "      <td>anthropic.claude-v2:1:18k</td>\n",
       "      <td>Claude</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/an...</td>\n",
       "      <td>anthropic.claude-v2:1:200k</td>\n",
       "      <td>Claude</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/an...</td>\n",
       "      <td>anthropic.claude-v2:1</td>\n",
       "      <td>Claude</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/an...</td>\n",
       "      <td>anthropic.claude-v2</td>\n",
       "      <td>Claude</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/co...</td>\n",
       "      <td>cohere.command-text-v14:7:4k</td>\n",
       "      <td>Command</td>\n",
       "      <td>Cohere</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[FINE_TUNING]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/co...</td>\n",
       "      <td>cohere.command-text-v14</td>\n",
       "      <td>Command</td>\n",
       "      <td>Cohere</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/co...</td>\n",
       "      <td>cohere.command-light-text-v14:7:4k</td>\n",
       "      <td>Command Light</td>\n",
       "      <td>Cohere</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[FINE_TUNING]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/co...</td>\n",
       "      <td>cohere.command-light-text-v14</td>\n",
       "      <td>Command Light</td>\n",
       "      <td>Cohere</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/co...</td>\n",
       "      <td>cohere.embed-english-v3</td>\n",
       "      <td>Embed English</td>\n",
       "      <td>Cohere</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[EMBEDDING]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/co...</td>\n",
       "      <td>cohere.embed-multilingual-v3</td>\n",
       "      <td>Embed Multilingual</td>\n",
       "      <td>Cohere</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[EMBEDDING]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/me...</td>\n",
       "      <td>meta.llama2-13b-chat-v1:0:4k</td>\n",
       "      <td>Llama 2 Chat 13B</td>\n",
       "      <td>Meta</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/me...</td>\n",
       "      <td>meta.llama2-13b-chat-v1</td>\n",
       "      <td>Llama 2 Chat 13B</td>\n",
       "      <td>Meta</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/me...</td>\n",
       "      <td>meta.llama2-70b-chat-v1:0:4k</td>\n",
       "      <td>Llama 2 Chat 70B</td>\n",
       "      <td>Meta</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/me...</td>\n",
       "      <td>meta.llama2-70b-chat-v1</td>\n",
       "      <td>Llama 2 Chat 70B</td>\n",
       "      <td>Meta</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/me...</td>\n",
       "      <td>meta.llama2-13b-v1:0:4k</td>\n",
       "      <td>Llama 2 13B</td>\n",
       "      <td>Meta</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[FINE_TUNING]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/me...</td>\n",
       "      <td>meta.llama2-13b-v1</td>\n",
       "      <td>Llama 2 13B</td>\n",
       "      <td>Meta</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/me...</td>\n",
       "      <td>meta.llama2-70b-v1:0:4k</td>\n",
       "      <td>Llama 2 70B</td>\n",
       "      <td>Meta</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[FINE_TUNING]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/me...</td>\n",
       "      <td>meta.llama2-70b-v1</td>\n",
       "      <td>Llama 2 70B</td>\n",
       "      <td>Meta</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             modelArn  \\\n",
       "0   arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "1   arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "2   arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "3   arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "4   arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "5   arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "6   arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "7   arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "8   arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "9   arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "10  arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "11  arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "12  arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "13  arn:aws:bedrock:us-east-1::foundation-model/st...   \n",
       "14  arn:aws:bedrock:us-east-1::foundation-model/st...   \n",
       "15  arn:aws:bedrock:us-east-1::foundation-model/st...   \n",
       "16  arn:aws:bedrock:us-east-1::foundation-model/st...   \n",
       "17  arn:aws:bedrock:us-east-1::foundation-model/ai...   \n",
       "18  arn:aws:bedrock:us-east-1::foundation-model/ai...   \n",
       "19  arn:aws:bedrock:us-east-1::foundation-model/ai...   \n",
       "20  arn:aws:bedrock:us-east-1::foundation-model/ai...   \n",
       "21  arn:aws:bedrock:us-east-1::foundation-model/ai...   \n",
       "22  arn:aws:bedrock:us-east-1::foundation-model/ai...   \n",
       "23  arn:aws:bedrock:us-east-1::foundation-model/an...   \n",
       "24  arn:aws:bedrock:us-east-1::foundation-model/an...   \n",
       "25  arn:aws:bedrock:us-east-1::foundation-model/an...   \n",
       "26  arn:aws:bedrock:us-east-1::foundation-model/an...   \n",
       "27  arn:aws:bedrock:us-east-1::foundation-model/an...   \n",
       "28  arn:aws:bedrock:us-east-1::foundation-model/an...   \n",
       "29  arn:aws:bedrock:us-east-1::foundation-model/an...   \n",
       "30  arn:aws:bedrock:us-east-1::foundation-model/an...   \n",
       "31  arn:aws:bedrock:us-east-1::foundation-model/an...   \n",
       "32  arn:aws:bedrock:us-east-1::foundation-model/co...   \n",
       "33  arn:aws:bedrock:us-east-1::foundation-model/co...   \n",
       "34  arn:aws:bedrock:us-east-1::foundation-model/co...   \n",
       "35  arn:aws:bedrock:us-east-1::foundation-model/co...   \n",
       "36  arn:aws:bedrock:us-east-1::foundation-model/co...   \n",
       "37  arn:aws:bedrock:us-east-1::foundation-model/co...   \n",
       "38  arn:aws:bedrock:us-east-1::foundation-model/me...   \n",
       "39  arn:aws:bedrock:us-east-1::foundation-model/me...   \n",
       "40  arn:aws:bedrock:us-east-1::foundation-model/me...   \n",
       "41  arn:aws:bedrock:us-east-1::foundation-model/me...   \n",
       "42  arn:aws:bedrock:us-east-1::foundation-model/me...   \n",
       "43  arn:aws:bedrock:us-east-1::foundation-model/me...   \n",
       "44  arn:aws:bedrock:us-east-1::foundation-model/me...   \n",
       "45  arn:aws:bedrock:us-east-1::foundation-model/me...   \n",
       "\n",
       "                               modelId                       modelName  \\\n",
       "0               amazon.titan-tg1-large                Titan Text Large   \n",
       "1              amazon.titan-e1t-medium           Titan Text Embeddings   \n",
       "2    amazon.titan-image-generator-v1:0        Titan Image Generator G1   \n",
       "3      amazon.titan-image-generator-v1        Titan Image Generator G1   \n",
       "4        amazon.titan-embed-g1-text-02        Titan Text Embeddings v2   \n",
       "5       amazon.titan-text-lite-v1:0:4k            Titan Text G1 - Lite   \n",
       "6            amazon.titan-text-lite-v1            Titan Text G1 - Lite   \n",
       "7    amazon.titan-text-express-v1:0:8k         Titan Text G1 - Express   \n",
       "8         amazon.titan-text-express-v1         Titan Text G1 - Express   \n",
       "9      amazon.titan-embed-text-v1:2:8k      Titan Embeddings G1 - Text   \n",
       "10          amazon.titan-embed-text-v1      Titan Embeddings G1 - Text   \n",
       "11       amazon.titan-embed-image-v1:0  Titan Multimodal Embeddings G1   \n",
       "12         amazon.titan-embed-image-v1  Titan Multimodal Embeddings G1   \n",
       "13       stability.stable-diffusion-xl                        SDXL 0.8   \n",
       "14    stability.stable-diffusion-xl-v0                        SDXL 0.8   \n",
       "15  stability.stable-diffusion-xl-v1:0                        SDXL 1.0   \n",
       "16    stability.stable-diffusion-xl-v1                        SDXL 1.0   \n",
       "17             ai21.j2-grande-instruct              J2 Grande Instruct   \n",
       "18              ai21.j2-jumbo-instruct               J2 Jumbo Instruct   \n",
       "19                         ai21.j2-mid                  Jurassic-2 Mid   \n",
       "20                      ai21.j2-mid-v1                  Jurassic-2 Mid   \n",
       "21                       ai21.j2-ultra                Jurassic-2 Ultra   \n",
       "22                    ai21.j2-ultra-v1                Jurassic-2 Ultra   \n",
       "23  anthropic.claude-instant-v1:2:100k                  Claude Instant   \n",
       "24         anthropic.claude-instant-v1                  Claude Instant   \n",
       "25                 anthropic.claude-v1                          Claude   \n",
       "26           anthropic.claude-v2:0:18k                          Claude   \n",
       "27          anthropic.claude-v2:0:100k                          Claude   \n",
       "28           anthropic.claude-v2:1:18k                          Claude   \n",
       "29          anthropic.claude-v2:1:200k                          Claude   \n",
       "30               anthropic.claude-v2:1                          Claude   \n",
       "31                 anthropic.claude-v2                          Claude   \n",
       "32        cohere.command-text-v14:7:4k                         Command   \n",
       "33             cohere.command-text-v14                         Command   \n",
       "34  cohere.command-light-text-v14:7:4k                   Command Light   \n",
       "35       cohere.command-light-text-v14                   Command Light   \n",
       "36             cohere.embed-english-v3                   Embed English   \n",
       "37        cohere.embed-multilingual-v3              Embed Multilingual   \n",
       "38        meta.llama2-13b-chat-v1:0:4k                Llama 2 Chat 13B   \n",
       "39             meta.llama2-13b-chat-v1                Llama 2 Chat 13B   \n",
       "40        meta.llama2-70b-chat-v1:0:4k                Llama 2 Chat 70B   \n",
       "41             meta.llama2-70b-chat-v1                Llama 2 Chat 70B   \n",
       "42             meta.llama2-13b-v1:0:4k                     Llama 2 13B   \n",
       "43                  meta.llama2-13b-v1                     Llama 2 13B   \n",
       "44             meta.llama2-70b-v1:0:4k                     Llama 2 70B   \n",
       "45                  meta.llama2-70b-v1                     Llama 2 70B   \n",
       "\n",
       "    providerName inputModalities outputModalities responseStreamingSupported  \\\n",
       "0         Amazon          [TEXT]           [TEXT]                       True   \n",
       "1         Amazon          [TEXT]      [EMBEDDING]                        NaN   \n",
       "2         Amazon   [TEXT, IMAGE]          [IMAGE]                        NaN   \n",
       "3         Amazon   [TEXT, IMAGE]          [IMAGE]                        NaN   \n",
       "4         Amazon          [TEXT]      [EMBEDDING]                        NaN   \n",
       "5         Amazon          [TEXT]           [TEXT]                       True   \n",
       "6         Amazon          [TEXT]           [TEXT]                       True   \n",
       "7         Amazon          [TEXT]           [TEXT]                       True   \n",
       "8         Amazon          [TEXT]           [TEXT]                       True   \n",
       "9         Amazon          [TEXT]      [EMBEDDING]                      False   \n",
       "10        Amazon          [TEXT]      [EMBEDDING]                      False   \n",
       "11        Amazon   [TEXT, IMAGE]      [EMBEDDING]                        NaN   \n",
       "12        Amazon   [TEXT, IMAGE]      [EMBEDDING]                        NaN   \n",
       "13  Stability AI   [TEXT, IMAGE]          [IMAGE]                        NaN   \n",
       "14  Stability AI   [TEXT, IMAGE]          [IMAGE]                        NaN   \n",
       "15  Stability AI   [TEXT, IMAGE]          [IMAGE]                        NaN   \n",
       "16  Stability AI   [TEXT, IMAGE]          [IMAGE]                        NaN   \n",
       "17     AI21 Labs          [TEXT]           [TEXT]                      False   \n",
       "18     AI21 Labs          [TEXT]           [TEXT]                      False   \n",
       "19     AI21 Labs          [TEXT]           [TEXT]                      False   \n",
       "20     AI21 Labs          [TEXT]           [TEXT]                      False   \n",
       "21     AI21 Labs          [TEXT]           [TEXT]                      False   \n",
       "22     AI21 Labs          [TEXT]           [TEXT]                      False   \n",
       "23     Anthropic          [TEXT]           [TEXT]                       True   \n",
       "24     Anthropic          [TEXT]           [TEXT]                       True   \n",
       "25     Anthropic          [TEXT]           [TEXT]                       True   \n",
       "26     Anthropic          [TEXT]           [TEXT]                       True   \n",
       "27     Anthropic          [TEXT]           [TEXT]                       True   \n",
       "28     Anthropic          [TEXT]           [TEXT]                       True   \n",
       "29     Anthropic          [TEXT]           [TEXT]                       True   \n",
       "30     Anthropic          [TEXT]           [TEXT]                       True   \n",
       "31     Anthropic          [TEXT]           [TEXT]                       True   \n",
       "32        Cohere          [TEXT]           [TEXT]                       True   \n",
       "33        Cohere          [TEXT]           [TEXT]                       True   \n",
       "34        Cohere          [TEXT]           [TEXT]                       True   \n",
       "35        Cohere          [TEXT]           [TEXT]                       True   \n",
       "36        Cohere          [TEXT]      [EMBEDDING]                      False   \n",
       "37        Cohere          [TEXT]      [EMBEDDING]                      False   \n",
       "38          Meta          [TEXT]           [TEXT]                       True   \n",
       "39          Meta          [TEXT]           [TEXT]                       True   \n",
       "40          Meta          [TEXT]           [TEXT]                       True   \n",
       "41          Meta          [TEXT]           [TEXT]                       True   \n",
       "42          Meta          [TEXT]           [TEXT]                       True   \n",
       "43          Meta          [TEXT]           [TEXT]                       True   \n",
       "44          Meta          [TEXT]           [TEXT]                       True   \n",
       "45          Meta          [TEXT]           [TEXT]                       True   \n",
       "\n",
       "                  customizationsSupported   inferenceTypesSupported  \\\n",
       "0                                      []               [ON_DEMAND]   \n",
       "1                                      []               [ON_DEMAND]   \n",
       "2                           [FINE_TUNING]  [ON_DEMAND, PROVISIONED]   \n",
       "3                                      []               [ON_DEMAND]   \n",
       "4                                      []               [ON_DEMAND]   \n",
       "5   [FINE_TUNING, CONTINUED_PRE_TRAINING]             [PROVISIONED]   \n",
       "6                                      []               [ON_DEMAND]   \n",
       "7   [FINE_TUNING, CONTINUED_PRE_TRAINING]             [PROVISIONED]   \n",
       "8                                      []               [ON_DEMAND]   \n",
       "9                                      []             [PROVISIONED]   \n",
       "10                                     []               [ON_DEMAND]   \n",
       "11                          [FINE_TUNING]  [ON_DEMAND, PROVISIONED]   \n",
       "12                                     []               [ON_DEMAND]   \n",
       "13                                     []               [ON_DEMAND]   \n",
       "14                                     []               [ON_DEMAND]   \n",
       "15                                     []             [PROVISIONED]   \n",
       "16                                     []               [ON_DEMAND]   \n",
       "17                                     []               [ON_DEMAND]   \n",
       "18                                     []               [ON_DEMAND]   \n",
       "19                                     []               [ON_DEMAND]   \n",
       "20                                     []               [ON_DEMAND]   \n",
       "21                                     []               [ON_DEMAND]   \n",
       "22                                     []               [ON_DEMAND]   \n",
       "23                                     []             [PROVISIONED]   \n",
       "24                                     []               [ON_DEMAND]   \n",
       "25                                     []               [ON_DEMAND]   \n",
       "26                                     []             [PROVISIONED]   \n",
       "27                                     []             [PROVISIONED]   \n",
       "28                                     []             [PROVISIONED]   \n",
       "29                                     []             [PROVISIONED]   \n",
       "30                                     []               [ON_DEMAND]   \n",
       "31                                     []               [ON_DEMAND]   \n",
       "32                          [FINE_TUNING]             [PROVISIONED]   \n",
       "33                                     []               [ON_DEMAND]   \n",
       "34                          [FINE_TUNING]             [PROVISIONED]   \n",
       "35                                     []               [ON_DEMAND]   \n",
       "36                                     []               [ON_DEMAND]   \n",
       "37                                     []               [ON_DEMAND]   \n",
       "38                                     []             [PROVISIONED]   \n",
       "39                                     []               [ON_DEMAND]   \n",
       "40                                     []                        []   \n",
       "41                                     []               [ON_DEMAND]   \n",
       "42                          [FINE_TUNING]                        []   \n",
       "43                                     []                        []   \n",
       "44                          [FINE_TUNING]                        []   \n",
       "45                                     []                        []   \n",
       "\n",
       "          modelLifecycle  \n",
       "0   {'status': 'ACTIVE'}  \n",
       "1   {'status': 'LEGACY'}  \n",
       "2   {'status': 'ACTIVE'}  \n",
       "3   {'status': 'ACTIVE'}  \n",
       "4   {'status': 'ACTIVE'}  \n",
       "5   {'status': 'ACTIVE'}  \n",
       "6   {'status': 'ACTIVE'}  \n",
       "7   {'status': 'ACTIVE'}  \n",
       "8   {'status': 'ACTIVE'}  \n",
       "9   {'status': 'ACTIVE'}  \n",
       "10  {'status': 'ACTIVE'}  \n",
       "11  {'status': 'ACTIVE'}  \n",
       "12  {'status': 'ACTIVE'}  \n",
       "13  {'status': 'ACTIVE'}  \n",
       "14  {'status': 'ACTIVE'}  \n",
       "15  {'status': 'ACTIVE'}  \n",
       "16  {'status': 'ACTIVE'}  \n",
       "17  {'status': 'ACTIVE'}  \n",
       "18  {'status': 'ACTIVE'}  \n",
       "19  {'status': 'ACTIVE'}  \n",
       "20  {'status': 'ACTIVE'}  \n",
       "21  {'status': 'ACTIVE'}  \n",
       "22  {'status': 'ACTIVE'}  \n",
       "23  {'status': 'ACTIVE'}  \n",
       "24  {'status': 'ACTIVE'}  \n",
       "25  {'status': 'LEGACY'}  \n",
       "26  {'status': 'ACTIVE'}  \n",
       "27  {'status': 'ACTIVE'}  \n",
       "28  {'status': 'ACTIVE'}  \n",
       "29  {'status': 'ACTIVE'}  \n",
       "30  {'status': 'ACTIVE'}  \n",
       "31  {'status': 'ACTIVE'}  \n",
       "32  {'status': 'ACTIVE'}  \n",
       "33  {'status': 'ACTIVE'}  \n",
       "34  {'status': 'ACTIVE'}  \n",
       "35  {'status': 'ACTIVE'}  \n",
       "36  {'status': 'ACTIVE'}  \n",
       "37  {'status': 'ACTIVE'}  \n",
       "38  {'status': 'ACTIVE'}  \n",
       "39  {'status': 'ACTIVE'}  \n",
       "40  {'status': 'ACTIVE'}  \n",
       "41  {'status': 'ACTIVE'}  \n",
       "42  {'status': 'ACTIVE'}  \n",
       "43  {'status': 'ACTIVE'}  \n",
       "44  {'status': 'ACTIVE'}  \n",
       "45  {'status': 'ACTIVE'}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "boto3_bedrock = get_bedrock_client(runtime=False)\n",
    "fm_list_response = boto3_bedrock.list_foundation_models()\n",
    "fm_list = fm_list_response['modelSummaries']\n",
    "df_fm = pd.DataFrame(fm_list)\n",
    "display(df_fm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-04 18:08:37,680] p93154 {3189124487.py:2} INFO - found 5 transcript_files ->\n",
      "['data/raw/0/call_center_transcript_1_transcript.txt', 'data/raw/1/call_center_transcript_0_transcript.txt', 'data/raw/4/call_center_transcript_4_transcript.txt', 'data/raw/3/call_center_transcript_3_transcript.txt', 'data/raw/2/call_center_transcript_2_transcript.txt']\n"
     ]
    }
   ],
   "source": [
    "transcript_files = glob.glob(os.path.join(config['dir']['raw'], \"*\", \"*transcript.txt\"))\n",
    "logger.info(f\"found {len(transcript_files)} transcript_files ->\\n{transcript_files}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to encapsulate call to any Bedrock model for text generation\n",
    "def get_text_response_from_bedrock(prompt: str, inference_parameters: Dict, model_id: str) -> Dict:\n",
    "\n",
    "    logger.info(f\"model_id={model_id}, prompt length is {len(prompt)} characters, {len(prompt.split())} words\")      \n",
    "    # initialize the response dict\n",
    "    ret = dict(exception = None,\n",
    "               prompt = prompt,\n",
    "               completion = None,\n",
    "               model_id = model_id,\n",
    "               time_taken_in_seconds = None,\n",
    "               completion_token_count = None,\n",
    "               prompt_token_count=None)\n",
    "    \n",
    "    if is_amazon_model(model_id) is False:\n",
    "        body = dict(prompt=prompt) | inference_parameters\n",
    "    else:\n",
    "        body = dict(inputText=prompt, textGenerationConfig=inference_parameters)\n",
    "\n",
    "    body_bytes = json.dumps(body).encode('utf-8')\n",
    "\n",
    "    # invoke the bedrock API for inferences\n",
    "    st = time.time()\n",
    "    try:\n",
    "        response = bedrock_client.invoke_model(\n",
    "                        modelId=model_id,\n",
    "                        contentType=\"application/json\",\n",
    "                        accept=\"*/*\",\n",
    "                        body=body_bytes,\n",
    "                    )\n",
    "    except Exception as e:\n",
    "        logger.error(f\"exception when calling invoke_model, model_id={model_id}, exception={e}\")\n",
    "        ret['exception'] = e\n",
    "        return ret\n",
    "    \n",
    "    ret['time_taken_in_seconds'] = time.time() - st\n",
    "    # response is a Boto3 object, read it to convert into bytes\n",
    "    resp_body = json.loads(response[\"body\"].read().decode('utf-8'))\n",
    "    \n",
    "    parsed_response = parse_model_response(model_id, resp_body)\n",
    "    ret.update(parsed_response)\n",
    "    logger.info(json.dumps(ret, indent=2))\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-04 18:08:37,697] p93154 {544935498.py:19} INFO - idx=0, tf=data/raw/0/call_center_transcript_1_transcript.txt, file_id=call_center_transcript_1, golden_summary_fpath=data/raw/0/example_prompt_transcript_golden_summary.txt\n",
      "[2024-01-04 18:08:37,698] p93154 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=anthropic_template_single_line_reason.txt, reps=3\n",
      "[2024-01-04 18:08:37,698] p93154 {544935498.py:35} INFO - going to summarize idx=0, file=data/raw/0/call_center_transcript_1_transcript.txt via anthropic.claude-instant-v1\n",
      "[2024-01-04 18:08:37,698] p93154 {544935498.py:38} INFO - read prompt template from data/prompts/anthropic_template_single_line_reason.txt\n",
      "[2024-01-04 18:08:37,763] p93154 {544935498.py:43} INFO - prompt for data/raw/0/call_center_transcript_1_transcript.txt has 778 tokens\n",
      "[2024-01-04 18:08:37,763] p93154 {528272729.py:4} INFO - model_id=anthropic.claude-instant-v1, prompt length is 3486 characters, 584 words\n",
      "[2024-01-04 18:08:39,757] p93154 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to discuss our strategy around generative AI and how we should approach this emerging technology. As you know, several applications have captured a lot of attention recently. \\nAction item: Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n\\nB: Yes, generative AI is definitely a hot topic right now. All the major tech companies seem to be investing heavily in this space.\\nAction item: Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nA: Exactly. I think we need to have a plan here too or risk falling behind. What kind of applications do you see for generative AI in our products? Could it be used to automate certain processes or enhance our users' experience?\\nAction item: Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nC: There's certainly potential, but we'd need to proceed cautiously. While the capabilities are impressive, the technology still has problems with accuracy and bias that could negatively impact customers if we don't validate it thoroughly before rolling anything out.\\nAction item: Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nB: I agree. We'll want to set clear guidelines for what generative AI should and\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \" <output>\\nA: \\n- Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n- Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nB:\\n- Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nC: \\n- Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 1.993049144744873,\n",
      "  \"completion_token_count\": 107,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-04 18:08:39,757] p93154 {544935498.py:76} INFO - prompt_token_count is None for anthropic.claude-instant-v1, setting it to 778 \n",
      "[2024-01-04 18:08:39,759] p93154 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to discuss our strategy around generative AI and how we should approach this emerging technology. As you know, several applications have captured a lot of attention recently. \\nAction item: Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n\\nB: Yes, generative AI is definitely a hot topic right now. All the major tech companies seem to be investing heavily in this space.\\nAction item: Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nA: Exactly. I think we need to have a plan here too or risk falling behind. What kind of applications do you see for generative AI in our products? Could it be used to automate certain processes or enhance our users' experience?\\nAction item: Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nC: There's certainly potential, but we'd need to proceed cautiously. While the capabilities are impressive, the technology still has problems with accuracy and bias that could negatively impact customers if we don't validate it thoroughly before rolling anything out.\\nAction item: Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nB: I agree. We'll want to set clear guidelines for what generative AI should and\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \"<output>\\nA: \\n- Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n- Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nB:\\n- Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nC: \\n- Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 1.993049144744873,\n",
      "  \"completion_token_count\": 107,\n",
      "  \"prompt_token_count\": 778,\n",
      "  \"cost\": 0.00185771,\n",
      "  \"completion_word_count\": 76,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-04 18:08:39,759] p93154 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=titan_template.txt, reps=3\n",
      "[2024-01-04 18:08:39,760] p93154 {544935498.py:35} INFO - going to summarize idx=0, file=data/raw/0/call_center_transcript_1_transcript.txt via amazon.titan-text-express-v1\n",
      "[2024-01-04 18:08:39,760] p93154 {544935498.py:38} INFO - read prompt template from data/prompts/titan_template.txt\n",
      "[2024-01-04 18:08:39,763] p93154 {544935498.py:43} INFO - prompt for data/raw/0/call_center_transcript_1_transcript.txt has 796 tokens\n",
      "[2024-01-04 18:08:39,763] p93154 {528272729.py:4} INFO - model_id=amazon.titan-text-express-v1, prompt length is 3569 characters, 601 words\n",
      "[2024-01-04 18:08:43,365] p93154 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nA: I wanted to discuss our strategy around generative AI and how we should approach this emerging technology. As you know, several applications have captured a lot of attention recently. \\nAction item: Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n\\nB: Yes, generative AI is definitely a hot topic right now. All the major tech companies seem to be investing heavily in this space.\\nAction item: Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nA: Exactly. I think we need to have a plan here too or risk falling behind. What kind of applications do you see for generative AI in our products? Could it be used to automate certain processes or enhance our users' experience?\\nAction item: Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nC: There's certainly potential, but we'd need to proceed cautiously. While the capabilities are impressive, the technology still has problems with accuracy and bias that could negatively impact customers if we don't validate it thoroughly before rolling anything out.\\nAction item: Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nB: I agree. We'll want to set clear guidelines for what generative AI should and\\n</conversation>\",\n",
      "  \"completion\": \"\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n- Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nB:\\n- Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nC:\\n- None explicitly stated\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 3.6013588905334473,\n",
      "  \"completion_token_count\": 100,\n",
      "  \"prompt_token_count\": 798\n",
      "}\n",
      "[2024-01-04 18:08:43,366] p93154 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nA: I wanted to discuss our strategy around generative AI and how we should approach this emerging technology. As you know, several applications have captured a lot of attention recently. \\nAction item: Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n\\nB: Yes, generative AI is definitely a hot topic right now. All the major tech companies seem to be investing heavily in this space.\\nAction item: Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nA: Exactly. I think we need to have a plan here too or risk falling behind. What kind of applications do you see for generative AI in our products? Could it be used to automate certain processes or enhance our users' experience?\\nAction item: Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nC: There's certainly potential, but we'd need to proceed cautiously. While the capabilities are impressive, the technology still has problems with accuracy and bias that could negatively impact customers if we don't validate it thoroughly before rolling anything out.\\nAction item: Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nB: I agree. We'll want to set clear guidelines for what generative AI should and\\n</conversation>\",\n",
      "  \"completion\": \"<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n- Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nB:\\n- Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nC:\\n- None explicitly stated\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 3.6013588905334473,\n",
      "  \"completion_token_count\": 100,\n",
      "  \"prompt_token_count\": 798,\n",
      "  \"cost\": 0.0007984,\n",
      "  \"completion_word_count\": 72,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-04 18:08:43,368] p93154 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=cohere_template.txt, reps=3\n",
      "[2024-01-04 18:08:43,369] p93154 {544935498.py:35} INFO - going to summarize idx=0, file=data/raw/0/call_center_transcript_1_transcript.txt via cohere.command-text-v14\n",
      "[2024-01-04 18:08:43,370] p93154 {544935498.py:38} INFO - read prompt template from data/prompts/cohere_template.txt\n",
      "[2024-01-04 18:08:43,374] p93154 {544935498.py:43} INFO - prompt for data/raw/0/call_center_transcript_1_transcript.txt has 791 tokens\n",
      "[2024-01-04 18:08:43,374] p93154 {528272729.py:4} INFO - model_id=cohere.command-text-v14, prompt length is 3564 characters, 600 words\n",
      "[2024-01-04 18:08:49,537] p93154 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to discuss our strategy around generative AI and how we should approach this emerging technology. As you know, several applications have captured a lot of attention recently. \\nAction item: Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n\\nB: Yes, generative AI is definitely a hot topic right now. All the major tech companies seem to be investing heavily in this space.\\nAction item: Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nA: Exactly. I think we need to have a plan here too or risk falling behind. What kind of applications do you see for generative AI in our products? Could it be used to automate certain processes or enhance our users' experience?\\nAction item: Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nC: There's certainly potential, but we'd need to proceed cautiously. While the capabilities are impressive, the technology still has problems with accuracy and bias that could negatively impact customers if we don't validate it thoroughly before rolling anything out.\\nAction item: Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nB: I agree. We'll want to set clear guidelines for what generative AI should and\\n</conversation>\",\n",
      "  \"completion\": \" <output>\\nA: \\n- Follow up on the generative AI idea and set up a meeting to brainstorm ideas \\n- Participate in the brainstorming session to contribute ideas for applying generative AI in company products \\n\\nB: \\n- Research tech company initiatives in generative AI to understand the competitive landscape \\n- Come up with a detailed assessment to share with the team on the competitive analysis \\n\\nC: \\n- Outline the potential risks of using generative AI with a particular focus on its accuracy and ethics \\n- Develop a framework to validate the safety and accuracy of any generative AI initiatives \\n\\n</output>\\n\\nPlease note that the action items are based on the conversation above and are limited to the scope of the discussion. If you have any further questions or would like to generate action items for additional topics, feel free to let me know! \",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 6.162084102630615,\n",
      "  \"completion_token_count\": 189,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-04 18:08:49,538] p93154 {544935498.py:76} INFO - prompt_token_count is None for cohere.command-text-v14, setting it to 791 \n",
      "[2024-01-04 18:08:49,540] p93154 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to discuss our strategy around generative AI and how we should approach this emerging technology. As you know, several applications have captured a lot of attention recently. \\nAction item: Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n\\nB: Yes, generative AI is definitely a hot topic right now. All the major tech companies seem to be investing heavily in this space.\\nAction item: Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nA: Exactly. I think we need to have a plan here too or risk falling behind. What kind of applications do you see for generative AI in our products? Could it be used to automate certain processes or enhance our users' experience?\\nAction item: Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nC: There's certainly potential, but we'd need to proceed cautiously. While the capabilities are impressive, the technology still has problems with accuracy and bias that could negatively impact customers if we don't validate it thoroughly before rolling anything out.\\nAction item: Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nB: I agree. We'll want to set clear guidelines for what generative AI should and\\n</conversation>\",\n",
      "  \"completion\": \"<output>\\nA: \\n- Follow up on the generative AI idea and set up a meeting to brainstorm ideas \\n- Participate in the brainstorming session to contribute ideas for applying generative AI in company products \\n\\nB: \\n- Research tech company initiatives in generative AI to understand the competitive landscape \\n- Come up with a detailed assessment to share with the team on the competitive analysis \\n\\nC: \\n- Outline the potential risks of using generative AI with a particular focus on its accuracy and ethics \\n- Develop a framework to validate the safety and accuracy of any generative AI initiatives \\n\\n</output>\\n\\nPlease note that the action items are based on the conversation above and are limited to the scope of the discussion. If you have any further questions or would like to generate action items for additional topics, feel free to let me know!\",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 6.162084102630615,\n",
      "  \"completion_token_count\": 189,\n",
      "  \"prompt_token_count\": 791,\n",
      "  \"cost\": 0.0015645000000000001,\n",
      "  \"completion_word_count\": 142,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-04 18:08:49,541] p93154 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=anthropic_template_single_line_reason.txt, reps=3\n",
      "[2024-01-04 18:08:49,542] p93154 {544935498.py:35} INFO - going to summarize idx=0, file=data/raw/0/call_center_transcript_1_transcript.txt via anthropic.claude-instant-v1\n",
      "[2024-01-04 18:08:49,543] p93154 {544935498.py:38} INFO - read prompt template from data/prompts/anthropic_template_single_line_reason.txt\n",
      "[2024-01-04 18:08:49,547] p93154 {544935498.py:43} INFO - prompt for data/raw/0/call_center_transcript_1_transcript.txt has 778 tokens\n",
      "[2024-01-04 18:08:49,548] p93154 {528272729.py:4} INFO - model_id=anthropic.claude-instant-v1, prompt length is 3486 characters, 584 words\n",
      "[2024-01-04 18:08:50,955] p93154 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to discuss our strategy around generative AI and how we should approach this emerging technology. As you know, several applications have captured a lot of attention recently. \\nAction item: Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n\\nB: Yes, generative AI is definitely a hot topic right now. All the major tech companies seem to be investing heavily in this space.\\nAction item: Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nA: Exactly. I think we need to have a plan here too or risk falling behind. What kind of applications do you see for generative AI in our products? Could it be used to automate certain processes or enhance our users' experience?\\nAction item: Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nC: There's certainly potential, but we'd need to proceed cautiously. While the capabilities are impressive, the technology still has problems with accuracy and bias that could negatively impact customers if we don't validate it thoroughly before rolling anything out.\\nAction item: Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nB: I agree. We'll want to set clear guidelines for what generative AI should and\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \" <output>\\nA: \\n- Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n- Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nB:\\n- Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nC: \\n- Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 1.4055302143096924,\n",
      "  \"completion_token_count\": 107,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-04 18:08:50,957] p93154 {544935498.py:76} INFO - prompt_token_count is None for anthropic.claude-instant-v1, setting it to 778 \n",
      "[2024-01-04 18:08:50,959] p93154 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to discuss our strategy around generative AI and how we should approach this emerging technology. As you know, several applications have captured a lot of attention recently. \\nAction item: Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n\\nB: Yes, generative AI is definitely a hot topic right now. All the major tech companies seem to be investing heavily in this space.\\nAction item: Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nA: Exactly. I think we need to have a plan here too or risk falling behind. What kind of applications do you see for generative AI in our products? Could it be used to automate certain processes or enhance our users' experience?\\nAction item: Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nC: There's certainly potential, but we'd need to proceed cautiously. While the capabilities are impressive, the technology still has problems with accuracy and bias that could negatively impact customers if we don't validate it thoroughly before rolling anything out.\\nAction item: Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nB: I agree. We'll want to set clear guidelines for what generative AI should and\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \"<output>\\nA: \\n- Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n- Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nB:\\n- Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nC: \\n- Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 1.4055302143096924,\n",
      "  \"completion_token_count\": 107,\n",
      "  \"prompt_token_count\": 778,\n",
      "  \"cost\": 0.00185771,\n",
      "  \"completion_word_count\": 76,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-04 18:08:50,962] p93154 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=titan_template.txt, reps=3\n",
      "[2024-01-04 18:08:50,963] p93154 {544935498.py:35} INFO - going to summarize idx=0, file=data/raw/0/call_center_transcript_1_transcript.txt via amazon.titan-text-express-v1\n",
      "[2024-01-04 18:08:50,964] p93154 {544935498.py:38} INFO - read prompt template from data/prompts/titan_template.txt\n",
      "[2024-01-04 18:08:50,970] p93154 {544935498.py:43} INFO - prompt for data/raw/0/call_center_transcript_1_transcript.txt has 796 tokens\n",
      "[2024-01-04 18:08:50,972] p93154 {528272729.py:4} INFO - model_id=amazon.titan-text-express-v1, prompt length is 3569 characters, 601 words\n",
      "[2024-01-04 18:08:54,600] p93154 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nA: I wanted to discuss our strategy around generative AI and how we should approach this emerging technology. As you know, several applications have captured a lot of attention recently. \\nAction item: Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n\\nB: Yes, generative AI is definitely a hot topic right now. All the major tech companies seem to be investing heavily in this space.\\nAction item: Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nA: Exactly. I think we need to have a plan here too or risk falling behind. What kind of applications do you see for generative AI in our products? Could it be used to automate certain processes or enhance our users' experience?\\nAction item: Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nC: There's certainly potential, but we'd need to proceed cautiously. While the capabilities are impressive, the technology still has problems with accuracy and bias that could negatively impact customers if we don't validate it thoroughly before rolling anything out.\\nAction item: Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nB: I agree. We'll want to set clear guidelines for what generative AI should and\\n</conversation>\",\n",
      "  \"completion\": \"\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n- Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nB:\\n- Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nC:\\n- None explicitly stated\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 3.6275548934936523,\n",
      "  \"completion_token_count\": 100,\n",
      "  \"prompt_token_count\": 798\n",
      "}\n",
      "[2024-01-04 18:08:54,605] p93154 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nA: I wanted to discuss our strategy around generative AI and how we should approach this emerging technology. As you know, several applications have captured a lot of attention recently. \\nAction item: Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n\\nB: Yes, generative AI is definitely a hot topic right now. All the major tech companies seem to be investing heavily in this space.\\nAction item: Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nA: Exactly. I think we need to have a plan here too or risk falling behind. What kind of applications do you see for generative AI in our products? Could it be used to automate certain processes or enhance our users' experience?\\nAction item: Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nC: There's certainly potential, but we'd need to proceed cautiously. While the capabilities are impressive, the technology still has problems with accuracy and bias that could negatively impact customers if we don't validate it thoroughly before rolling anything out.\\nAction item: Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nB: I agree. We'll want to set clear guidelines for what generative AI should and\\n</conversation>\",\n",
      "  \"completion\": \"<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n- Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nB:\\n- Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nC:\\n- None explicitly stated\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 3.6275548934936523,\n",
      "  \"completion_token_count\": 100,\n",
      "  \"prompt_token_count\": 798,\n",
      "  \"cost\": 0.0007984,\n",
      "  \"completion_word_count\": 72,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-04 18:08:54,607] p93154 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=cohere_template.txt, reps=3\n",
      "[2024-01-04 18:08:54,608] p93154 {544935498.py:35} INFO - going to summarize idx=0, file=data/raw/0/call_center_transcript_1_transcript.txt via cohere.command-text-v14\n",
      "[2024-01-04 18:08:54,610] p93154 {544935498.py:38} INFO - read prompt template from data/prompts/cohere_template.txt\n",
      "[2024-01-04 18:08:54,617] p93154 {544935498.py:43} INFO - prompt for data/raw/0/call_center_transcript_1_transcript.txt has 791 tokens\n",
      "[2024-01-04 18:08:54,619] p93154 {528272729.py:4} INFO - model_id=cohere.command-text-v14, prompt length is 3564 characters, 600 words\n",
      "[2024-01-04 18:09:00,686] p93154 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to discuss our strategy around generative AI and how we should approach this emerging technology. As you know, several applications have captured a lot of attention recently. \\nAction item: Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n\\nB: Yes, generative AI is definitely a hot topic right now. All the major tech companies seem to be investing heavily in this space.\\nAction item: Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nA: Exactly. I think we need to have a plan here too or risk falling behind. What kind of applications do you see for generative AI in our products? Could it be used to automate certain processes or enhance our users' experience?\\nAction item: Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nC: There's certainly potential, but we'd need to proceed cautiously. While the capabilities are impressive, the technology still has problems with accuracy and bias that could negatively impact customers if we don't validate it thoroughly before rolling anything out.\\nAction item: Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nB: I agree. We'll want to set clear guidelines for what generative AI should and\\n</conversation>\",\n",
      "  \"completion\": \" <output>\\nA: \\n- Follow up on the generative AI idea and set up a brainstorming meeting\\n- Share research and analysis of competitors working on generative AI \\n- Come up with ideas for applying AI for automation and user experience\\n\\nB: \\n- Research tech company applications and investments in generative AI \\n- Share competitive analysis with the team\\n\\nC:\\n- Outline the validation framework for accuracy, ethics and safety of applications \\n- Set guidelines for use of generative AI within the company \\n\\n</output>\\n\\nWhoever is responsible for taking these actions is subjective and based on the participants' roles and responsibilities. I have assigned the above actions based on the conversation's flow and who is speaking mainly on each topic. Please let me know if you would like me to change the distribution of these action items. \",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 6.065985918045044,\n",
      "  \"completion_token_count\": 181,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-04 18:09:00,687] p93154 {544935498.py:76} INFO - prompt_token_count is None for cohere.command-text-v14, setting it to 791 \n",
      "[2024-01-04 18:09:00,690] p93154 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to discuss our strategy around generative AI and how we should approach this emerging technology. As you know, several applications have captured a lot of attention recently. \\nAction item: Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n\\nB: Yes, generative AI is definitely a hot topic right now. All the major tech companies seem to be investing heavily in this space.\\nAction item: Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nA: Exactly. I think we need to have a plan here too or risk falling behind. What kind of applications do you see for generative AI in our products? Could it be used to automate certain processes or enhance our users' experience?\\nAction item: Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nC: There's certainly potential, but we'd need to proceed cautiously. While the capabilities are impressive, the technology still has problems with accuracy and bias that could negatively impact customers if we don't validate it thoroughly before rolling anything out.\\nAction item: Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nB: I agree. We'll want to set clear guidelines for what generative AI should and\\n</conversation>\",\n",
      "  \"completion\": \"<output>\\nA: \\n- Follow up on the generative AI idea and set up a brainstorming meeting\\n- Share research and analysis of competitors working on generative AI \\n- Come up with ideas for applying AI for automation and user experience\\n\\nB: \\n- Research tech company applications and investments in generative AI \\n- Share competitive analysis with the team\\n\\nC:\\n- Outline the validation framework for accuracy, ethics and safety of applications \\n- Set guidelines for use of generative AI within the company \\n\\n</output>\\n\\nWhoever is responsible for taking these actions is subjective and based on the participants' roles and responsibilities. I have assigned the above actions based on the conversation's flow and who is speaking mainly on each topic. Please let me know if you would like me to change the distribution of these action items.\",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 6.065985918045044,\n",
      "  \"completion_token_count\": 181,\n",
      "  \"prompt_token_count\": 791,\n",
      "  \"cost\": 0.0015485,\n",
      "  \"completion_word_count\": 136,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-04 18:09:00,692] p93154 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=anthropic_template_single_line_reason.txt, reps=3\n",
      "[2024-01-04 18:09:00,693] p93154 {544935498.py:35} INFO - going to summarize idx=0, file=data/raw/0/call_center_transcript_1_transcript.txt via anthropic.claude-instant-v1\n",
      "[2024-01-04 18:09:00,694] p93154 {544935498.py:38} INFO - read prompt template from data/prompts/anthropic_template_single_line_reason.txt\n",
      "[2024-01-04 18:09:00,699] p93154 {544935498.py:43} INFO - prompt for data/raw/0/call_center_transcript_1_transcript.txt has 778 tokens\n",
      "[2024-01-04 18:09:00,700] p93154 {528272729.py:4} INFO - model_id=anthropic.claude-instant-v1, prompt length is 3486 characters, 584 words\n",
      "[2024-01-04 18:09:02,032] p93154 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to discuss our strategy around generative AI and how we should approach this emerging technology. As you know, several applications have captured a lot of attention recently. \\nAction item: Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n\\nB: Yes, generative AI is definitely a hot topic right now. All the major tech companies seem to be investing heavily in this space.\\nAction item: Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nA: Exactly. I think we need to have a plan here too or risk falling behind. What kind of applications do you see for generative AI in our products? Could it be used to automate certain processes or enhance our users' experience?\\nAction item: Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nC: There's certainly potential, but we'd need to proceed cautiously. While the capabilities are impressive, the technology still has problems with accuracy and bias that could negatively impact customers if we don't validate it thoroughly before rolling anything out.\\nAction item: Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nB: I agree. We'll want to set clear guidelines for what generative AI should and\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \" <output>\\nA: \\n- Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n- Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nB:\\n- Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nC: \\n- Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 1.3296446800231934,\n",
      "  \"completion_token_count\": 107,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-04 18:09:02,034] p93154 {544935498.py:76} INFO - prompt_token_count is None for anthropic.claude-instant-v1, setting it to 778 \n",
      "[2024-01-04 18:09:02,036] p93154 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to discuss our strategy around generative AI and how we should approach this emerging technology. As you know, several applications have captured a lot of attention recently. \\nAction item: Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n\\nB: Yes, generative AI is definitely a hot topic right now. All the major tech companies seem to be investing heavily in this space.\\nAction item: Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nA: Exactly. I think we need to have a plan here too or risk falling behind. What kind of applications do you see for generative AI in our products? Could it be used to automate certain processes or enhance our users' experience?\\nAction item: Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nC: There's certainly potential, but we'd need to proceed cautiously. While the capabilities are impressive, the technology still has problems with accuracy and bias that could negatively impact customers if we don't validate it thoroughly before rolling anything out.\\nAction item: Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nB: I agree. We'll want to set clear guidelines for what generative AI should and\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \"<output>\\nA: \\n- Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n- Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nB:\\n- Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nC: \\n- Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 1.3296446800231934,\n",
      "  \"completion_token_count\": 107,\n",
      "  \"prompt_token_count\": 778,\n",
      "  \"cost\": 0.00185771,\n",
      "  \"completion_word_count\": 76,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-04 18:09:02,038] p93154 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=titan_template.txt, reps=3\n",
      "[2024-01-04 18:09:02,039] p93154 {544935498.py:35} INFO - going to summarize idx=0, file=data/raw/0/call_center_transcript_1_transcript.txt via amazon.titan-text-express-v1\n",
      "[2024-01-04 18:09:02,040] p93154 {544935498.py:38} INFO - read prompt template from data/prompts/titan_template.txt\n",
      "[2024-01-04 18:09:02,047] p93154 {544935498.py:43} INFO - prompt for data/raw/0/call_center_transcript_1_transcript.txt has 796 tokens\n",
      "[2024-01-04 18:09:02,049] p93154 {528272729.py:4} INFO - model_id=amazon.titan-text-express-v1, prompt length is 3569 characters, 601 words\n",
      "[2024-01-04 18:09:05,581] p93154 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nA: I wanted to discuss our strategy around generative AI and how we should approach this emerging technology. As you know, several applications have captured a lot of attention recently. \\nAction item: Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n\\nB: Yes, generative AI is definitely a hot topic right now. All the major tech companies seem to be investing heavily in this space.\\nAction item: Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nA: Exactly. I think we need to have a plan here too or risk falling behind. What kind of applications do you see for generative AI in our products? Could it be used to automate certain processes or enhance our users' experience?\\nAction item: Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nC: There's certainly potential, but we'd need to proceed cautiously. While the capabilities are impressive, the technology still has problems with accuracy and bias that could negatively impact customers if we don't validate it thoroughly before rolling anything out.\\nAction item: Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nB: I agree. We'll want to set clear guidelines for what generative AI should and\\n</conversation>\",\n",
      "  \"completion\": \"\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n- Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nB:\\n- Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nC:\\n- None explicitly stated\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 3.529287815093994,\n",
      "  \"completion_token_count\": 100,\n",
      "  \"prompt_token_count\": 798\n",
      "}\n",
      "[2024-01-04 18:09:05,585] p93154 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nA: I wanted to discuss our strategy around generative AI and how we should approach this emerging technology. As you know, several applications have captured a lot of attention recently. \\nAction item: Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n\\nB: Yes, generative AI is definitely a hot topic right now. All the major tech companies seem to be investing heavily in this space.\\nAction item: Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nA: Exactly. I think we need to have a plan here too or risk falling behind. What kind of applications do you see for generative AI in our products? Could it be used to automate certain processes or enhance our users' experience?\\nAction item: Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nC: There's certainly potential, but we'd need to proceed cautiously. While the capabilities are impressive, the technology still has problems with accuracy and bias that could negatively impact customers if we don't validate it thoroughly before rolling anything out.\\nAction item: Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nB: I agree. We'll want to set clear guidelines for what generative AI should and\\n</conversation>\",\n",
      "  \"completion\": \"<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n- Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nB:\\n- Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nC:\\n- None explicitly stated\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 3.529287815093994,\n",
      "  \"completion_token_count\": 100,\n",
      "  \"prompt_token_count\": 798,\n",
      "  \"cost\": 0.0007984,\n",
      "  \"completion_word_count\": 72,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-04 18:09:05,588] p93154 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=cohere_template.txt, reps=3\n",
      "[2024-01-04 18:09:05,589] p93154 {544935498.py:35} INFO - going to summarize idx=0, file=data/raw/0/call_center_transcript_1_transcript.txt via cohere.command-text-v14\n",
      "[2024-01-04 18:09:05,590] p93154 {544935498.py:38} INFO - read prompt template from data/prompts/cohere_template.txt\n",
      "[2024-01-04 18:09:05,597] p93154 {544935498.py:43} INFO - prompt for data/raw/0/call_center_transcript_1_transcript.txt has 791 tokens\n",
      "[2024-01-04 18:09:05,602] p93154 {528272729.py:4} INFO - model_id=cohere.command-text-v14, prompt length is 3564 characters, 600 words\n",
      "[2024-01-04 18:09:13,698] p93154 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to discuss our strategy around generative AI and how we should approach this emerging technology. As you know, several applications have captured a lot of attention recently. \\nAction item: Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n\\nB: Yes, generative AI is definitely a hot topic right now. All the major tech companies seem to be investing heavily in this space.\\nAction item: Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nA: Exactly. I think we need to have a plan here too or risk falling behind. What kind of applications do you see for generative AI in our products? Could it be used to automate certain processes or enhance our users' experience?\\nAction item: Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nC: There's certainly potential, but we'd need to proceed cautiously. While the capabilities are impressive, the technology still has problems with accuracy and bias that could negatively impact customers if we don't validate it thoroughly before rolling anything out.\\nAction item: Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nB: I agree. We'll want to set clear guidelines for what generative AI should and\\n</conversation>\",\n",
      "  \"completion\": \" <output>\\nA: \\n- Follow up on the generative AI idea and set up a meeting to brainstorm ideas \\n- Participate in the brainstorming session to contribute ideas on how generative AI can be applicable for products\\n\\nB: \\n- Research tech companies' current initiatives on generative AI to understand the competitive landscape \\n- Come up with a detailed assessment to be presented in the next meeting\\n\\nC:\\n- Outline the potential risks of generative AI technologies\\n- Participate in the discussion of high-level ideas to enhance user experience with generative AI\\n- Lead the development of a validation framework to assess the accuracy and ethics of generative AI applications\\n\\n</output>\\n\\nEach speaker in the conversation is required to follow up on the proposed ideas and participate in discussions to develop a deeper understanding of the potential applications of generative AI. As the conversation progresses, it might be useful to create more specific action items based on the outcomes of the initial research and assessments. Would you like me to assist you with anything else regarding this conversation? \\n\\nFeel free to provide more conversation transcripts for me to analyze and generate action items!\",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 8.093671798706055,\n",
      "  \"completion_token_count\": 254,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-04 18:09:13,700] p93154 {544935498.py:76} INFO - prompt_token_count is None for cohere.command-text-v14, setting it to 791 \n",
      "[2024-01-04 18:09:13,703] p93154 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to discuss our strategy around generative AI and how we should approach this emerging technology. As you know, several applications have captured a lot of attention recently. \\nAction item: Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n\\nB: Yes, generative AI is definitely a hot topic right now. All the major tech companies seem to be investing heavily in this space.\\nAction item: Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nA: Exactly. I think we need to have a plan here too or risk falling behind. What kind of applications do you see for generative AI in our products? Could it be used to automate certain processes or enhance our users' experience?\\nAction item: Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nC: There's certainly potential, but we'd need to proceed cautiously. While the capabilities are impressive, the technology still has problems with accuracy and bias that could negatively impact customers if we don't validate it thoroughly before rolling anything out.\\nAction item: Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nB: I agree. We'll want to set clear guidelines for what generative AI should and\\n</conversation>\",\n",
      "  \"completion\": \"<output>\\nA: \\n- Follow up on the generative AI idea and set up a meeting to brainstorm ideas \\n- Participate in the brainstorming session to contribute ideas on how generative AI can be applicable for products\\n\\nB: \\n- Research tech companies' current initiatives on generative AI to understand the competitive landscape \\n- Come up with a detailed assessment to be presented in the next meeting\\n\\nC:\\n- Outline the potential risks of generative AI technologies\\n- Participate in the discussion of high-level ideas to enhance user experience with generative AI\\n- Lead the development of a validation framework to assess the accuracy and ethics of generative AI applications\\n\\n</output>\\n\\nEach speaker in the conversation is required to follow up on the proposed ideas and participate in discussions to develop a deeper understanding of the potential applications of generative AI. As the conversation progresses, it might be useful to create more specific action items based on the outcomes of the initial research and assessments. Would you like me to assist you with anything else regarding this conversation? \\n\\nFeel free to provide more conversation transcripts for me to analyze and generate action items!\",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 8.093671798706055,\n",
      "  \"completion_token_count\": 254,\n",
      "  \"prompt_token_count\": 791,\n",
      "  \"cost\": 0.0016945,\n",
      "  \"completion_word_count\": 191,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-04 18:09:13,705] p93154 {544935498.py:19} INFO - idx=1, tf=data/raw/1/call_center_transcript_0_transcript.txt, file_id=call_center_transcript_0, golden_summary_fpath=data/raw/0/example_prompt_transcript_golden_summary.txt\n",
      "[2024-01-04 18:09:13,706] p93154 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=anthropic_template_single_line_reason.txt, reps=3\n",
      "[2024-01-04 18:09:13,707] p93154 {544935498.py:35} INFO - going to summarize idx=1, file=data/raw/1/call_center_transcript_0_transcript.txt via anthropic.claude-instant-v1\n",
      "[2024-01-04 18:09:13,708] p93154 {544935498.py:38} INFO - read prompt template from data/prompts/anthropic_template_single_line_reason.txt\n",
      "[2024-01-04 18:09:13,715] p93154 {544935498.py:43} INFO - prompt for data/raw/1/call_center_transcript_0_transcript.txt has 728 tokens\n",
      "[2024-01-04 18:09:13,717] p93154 {528272729.py:4} INFO - model_id=anthropic.claude-instant-v1, prompt length is 3004 characters, 543 words\n",
      "[2024-01-04 18:09:15,099] p93154 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nMeeting transcript: \\nA: Hi B, I want to discuss the workstream for our new product launch\\nB: Sure A, is there anything in particular you want to discuss?\\nA: Yes, I want to talk about how users enter into the product.  \\nB: Ok, in that case let me add in C.\\nC: Hey everyone\\nB: Hi C, A wants to discuss how users enter into the product.\\nA: its too complicated and we should remove friction.  for example, why do I need to fill out additional forms? I also find it difficult to find where to access the product when I first land on the landing page.  \\nB: I would also add that I think there are too many steps.\\nC: Ok, I can work on the landing page to make the product more discoverable but B can you work on the additonal forms?\\nB: Yes but I would need to work with James from another team as he needs to unblock the sign up workflow. A can you document any other concerns so that I can discuss with James only once?\\nA: Sure.\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \" <output>\\nA: \\n- Document any other concerns with the user entry process to discuss with James\\n\\nB:\\n- Work with James from another team to streamline the additional forms in the signup workflow  \\n- Discuss concerns documented by A with James\\n\\nC: \\n- Work on improving the landing page to make the product more discoverable for new users\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 1.3791210651397705,\n",
      "  \"completion_token_count\": 82,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-04 18:09:15,100] p93154 {544935498.py:76} INFO - prompt_token_count is None for anthropic.claude-instant-v1, setting it to 728 \n",
      "[2024-01-04 18:09:15,103] p93154 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nMeeting transcript: \\nA: Hi B, I want to discuss the workstream for our new product launch\\nB: Sure A, is there anything in particular you want to discuss?\\nA: Yes, I want to talk about how users enter into the product.  \\nB: Ok, in that case let me add in C.\\nC: Hey everyone\\nB: Hi C, A wants to discuss how users enter into the product.\\nA: its too complicated and we should remove friction.  for example, why do I need to fill out additional forms? I also find it difficult to find where to access the product when I first land on the landing page.  \\nB: I would also add that I think there are too many steps.\\nC: Ok, I can work on the landing page to make the product more discoverable but B can you work on the additonal forms?\\nB: Yes but I would need to work with James from another team as he needs to unblock the sign up workflow. A can you document any other concerns so that I can discuss with James only once?\\nA: Sure.\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \"<output>\\nA: \\n- Document any other concerns with the user entry process to discuss with James\\n\\nB:\\n- Work with James from another team to streamline the additional forms in the signup workflow  \\n- Discuss concerns documented by A with James\\n\\nC: \\n- Work on improving the landing page to make the product more discoverable for new users\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 1.3791210651397705,\n",
      "  \"completion_token_count\": 82,\n",
      "  \"prompt_token_count\": 728,\n",
      "  \"cost\": 0.0016384599999999998,\n",
      "  \"completion_word_count\": 59,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-04 18:09:15,105] p93154 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=titan_template.txt, reps=3\n",
      "[2024-01-04 18:09:15,106] p93154 {544935498.py:35} INFO - going to summarize idx=1, file=data/raw/1/call_center_transcript_0_transcript.txt via amazon.titan-text-express-v1\n",
      "[2024-01-04 18:09:15,107] p93154 {544935498.py:38} INFO - read prompt template from data/prompts/titan_template.txt\n",
      "[2024-01-04 18:09:15,114] p93154 {544935498.py:43} INFO - prompt for data/raw/1/call_center_transcript_0_transcript.txt has 746 tokens\n",
      "[2024-01-04 18:09:15,116] p93154 {528272729.py:4} INFO - model_id=amazon.titan-text-express-v1, prompt length is 3087 characters, 560 words\n",
      "[2024-01-04 18:09:18,949] p93154 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nMeeting transcript: \\nA: Hi B, I want to discuss the workstream for our new product launch\\nB: Sure A, is there anything in particular you want to discuss?\\nA: Yes, I want to talk about how users enter into the product.  \\nB: Ok, in that case let me add in C.\\nC: Hey everyone\\nB: Hi C, A wants to discuss how users enter into the product.\\nA: its too complicated and we should remove friction.  for example, why do I need to fill out additional forms? I also find it difficult to find where to access the product when I first land on the landing page.  \\nB: I would also add that I think there are too many steps.\\nC: Ok, I can work on the landing page to make the product more discoverable but B can you work on the additonal forms?\\nB: Yes but I would need to work with James from another team as he needs to unblock the sign up workflow. A can you document any other concerns so that I can discuss with James only once?\\nA: Sure.\\n</conversation>\",\n",
      "  \"completion\": \"\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Document any other concerns related to user entry into the product so that B can discuss with James only once\\n\\nB:\\n- Work with James from another team to unblock the sign up workflow\\n- Work on the landing page to make the product more discoverable\\n\\nC:\\n- Work on the landing page to make the product more discoverable\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 3.8320460319519043,\n",
      "  \"completion_token_count\": 96,\n",
      "  \"prompt_token_count\": 750\n",
      "}\n",
      "[2024-01-04 18:09:18,953] p93154 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nMeeting transcript: \\nA: Hi B, I want to discuss the workstream for our new product launch\\nB: Sure A, is there anything in particular you want to discuss?\\nA: Yes, I want to talk about how users enter into the product.  \\nB: Ok, in that case let me add in C.\\nC: Hey everyone\\nB: Hi C, A wants to discuss how users enter into the product.\\nA: its too complicated and we should remove friction.  for example, why do I need to fill out additional forms? I also find it difficult to find where to access the product when I first land on the landing page.  \\nB: I would also add that I think there are too many steps.\\nC: Ok, I can work on the landing page to make the product more discoverable but B can you work on the additonal forms?\\nB: Yes but I would need to work with James from another team as he needs to unblock the sign up workflow. A can you document any other concerns so that I can discuss with James only once?\\nA: Sure.\\n</conversation>\",\n",
      "  \"completion\": \"<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Document any other concerns related to user entry into the product so that B can discuss with James only once\\n\\nB:\\n- Work with James from another team to unblock the sign up workflow\\n- Work on the landing page to make the product more discoverable\\n\\nC:\\n- Work on the landing page to make the product more discoverable\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 3.8320460319519043,\n",
      "  \"completion_token_count\": 96,\n",
      "  \"prompt_token_count\": 750,\n",
      "  \"cost\": 0.0007536000000000001,\n",
      "  \"completion_word_count\": 73,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-04 18:09:18,956] p93154 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=cohere_template.txt, reps=3\n",
      "[2024-01-04 18:09:18,957] p93154 {544935498.py:35} INFO - going to summarize idx=1, file=data/raw/1/call_center_transcript_0_transcript.txt via cohere.command-text-v14\n",
      "[2024-01-04 18:09:18,959] p93154 {544935498.py:38} INFO - read prompt template from data/prompts/cohere_template.txt\n",
      "[2024-01-04 18:09:18,965] p93154 {544935498.py:43} INFO - prompt for data/raw/1/call_center_transcript_0_transcript.txt has 741 tokens\n",
      "[2024-01-04 18:09:18,967] p93154 {528272729.py:4} INFO - model_id=cohere.command-text-v14, prompt length is 3082 characters, 559 words\n",
      "[2024-01-04 18:09:25,863] p93154 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nMeeting transcript: \\nA: Hi B, I want to discuss the workstream for our new product launch\\nB: Sure A, is there anything in particular you want to discuss?\\nA: Yes, I want to talk about how users enter into the product.  \\nB: Ok, in that case let me add in C.\\nC: Hey everyone\\nB: Hi C, A wants to discuss how users enter into the product.\\nA: its too complicated and we should remove friction.  for example, why do I need to fill out additional forms? I also find it difficult to find where to access the product when I first land on the landing page.  \\nB: I would also add that I think there are too many steps.\\nC: Ok, I can work on the landing page to make the product more discoverable but B can you work on the additonal forms?\\nB: Yes but I would need to work with James from another team as he needs to unblock the sign up workflow. A can you document any other concerns so that I can discuss with James only once?\\nA: Sure.\\n</conversation>\",\n",
      "  \"completion\": \" <output>\\nHere are the action items for each speaker based on the conversation:\\n\\nA:\\n- Document specific concerns about the sign-up workflow to simplify user entry\\n- Collaborate with B and James to streamline the forms and questions asked during user sign-up \\n\\nB:\\n- Work with James to unblock the sign-up workflow and simplify the process\\n- Take lead on further simplifying user entry by consolidating sign-up steps and making the product more accessible \\n\\nC:\\n- Focus on improving the discoverability of the product on the landing page\\n</output>\\n\\nDo these action items seem reasonable based on the conversation? \",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 6.895195960998535,\n",
      "  \"completion_token_count\": 132,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-04 18:09:25,865] p93154 {544935498.py:76} INFO - prompt_token_count is None for cohere.command-text-v14, setting it to 741 \n",
      "[2024-01-04 18:09:25,868] p93154 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nMeeting transcript: \\nA: Hi B, I want to discuss the workstream for our new product launch\\nB: Sure A, is there anything in particular you want to discuss?\\nA: Yes, I want to talk about how users enter into the product.  \\nB: Ok, in that case let me add in C.\\nC: Hey everyone\\nB: Hi C, A wants to discuss how users enter into the product.\\nA: its too complicated and we should remove friction.  for example, why do I need to fill out additional forms? I also find it difficult to find where to access the product when I first land on the landing page.  \\nB: I would also add that I think there are too many steps.\\nC: Ok, I can work on the landing page to make the product more discoverable but B can you work on the additonal forms?\\nB: Yes but I would need to work with James from another team as he needs to unblock the sign up workflow. A can you document any other concerns so that I can discuss with James only once?\\nA: Sure.\\n</conversation>\",\n",
      "  \"completion\": \"<output>\\nHere are the action items for each speaker based on the conversation:\\n\\nA:\\n- Document specific concerns about the sign-up workflow to simplify user entry\\n- Collaborate with B and James to streamline the forms and questions asked during user sign-up \\n\\nB:\\n- Work with James to unblock the sign-up workflow and simplify the process\\n- Take lead on further simplifying user entry by consolidating sign-up steps and making the product more accessible \\n\\nC:\\n- Focus on improving the discoverability of the product on the landing page\\n</output>\\n\\nDo these action items seem reasonable based on the conversation?\",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 6.895195960998535,\n",
      "  \"completion_token_count\": 132,\n",
      "  \"prompt_token_count\": 741,\n",
      "  \"cost\": 0.0013755,\n",
      "  \"completion_word_count\": 99,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-04 18:09:25,871] p93154 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=anthropic_template_single_line_reason.txt, reps=3\n",
      "[2024-01-04 18:09:25,873] p93154 {544935498.py:35} INFO - going to summarize idx=1, file=data/raw/1/call_center_transcript_0_transcript.txt via anthropic.claude-instant-v1\n",
      "[2024-01-04 18:09:25,874] p93154 {544935498.py:38} INFO - read prompt template from data/prompts/anthropic_template_single_line_reason.txt\n",
      "[2024-01-04 18:09:25,880] p93154 {544935498.py:43} INFO - prompt for data/raw/1/call_center_transcript_0_transcript.txt has 728 tokens\n",
      "[2024-01-04 18:09:25,885] p93154 {528272729.py:4} INFO - model_id=anthropic.claude-instant-v1, prompt length is 3004 characters, 543 words\n",
      "[2024-01-04 18:09:27,399] p93154 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nMeeting transcript: \\nA: Hi B, I want to discuss the workstream for our new product launch\\nB: Sure A, is there anything in particular you want to discuss?\\nA: Yes, I want to talk about how users enter into the product.  \\nB: Ok, in that case let me add in C.\\nC: Hey everyone\\nB: Hi C, A wants to discuss how users enter into the product.\\nA: its too complicated and we should remove friction.  for example, why do I need to fill out additional forms? I also find it difficult to find where to access the product when I first land on the landing page.  \\nB: I would also add that I think there are too many steps.\\nC: Ok, I can work on the landing page to make the product more discoverable but B can you work on the additonal forms?\\nB: Yes but I would need to work with James from another team as he needs to unblock the sign up workflow. A can you document any other concerns so that I can discuss with James only once?\\nA: Sure.\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \" <output>\\nA: \\n- Document any other concerns with the user entry process to discuss with James\\n\\nB:\\n- Work with James from another team to streamline the additional forms as part of sign up workflow  \\n- Discuss documented concerns from A with James\\n\\nC: \\n- Work on improving the landing page to make the product more discoverable for new users\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 1.5114150047302246,\n",
      "  \"completion_token_count\": 84,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-04 18:09:27,402] p93154 {544935498.py:76} INFO - prompt_token_count is None for anthropic.claude-instant-v1, setting it to 728 \n",
      "[2024-01-04 18:09:27,406] p93154 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nMeeting transcript: \\nA: Hi B, I want to discuss the workstream for our new product launch\\nB: Sure A, is there anything in particular you want to discuss?\\nA: Yes, I want to talk about how users enter into the product.  \\nB: Ok, in that case let me add in C.\\nC: Hey everyone\\nB: Hi C, A wants to discuss how users enter into the product.\\nA: its too complicated and we should remove friction.  for example, why do I need to fill out additional forms? I also find it difficult to find where to access the product when I first land on the landing page.  \\nB: I would also add that I think there are too many steps.\\nC: Ok, I can work on the landing page to make the product more discoverable but B can you work on the additonal forms?\\nB: Yes but I would need to work with James from another team as he needs to unblock the sign up workflow. A can you document any other concerns so that I can discuss with James only once?\\nA: Sure.\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \"<output>\\nA: \\n- Document any other concerns with the user entry process to discuss with James\\n\\nB:\\n- Work with James from another team to streamline the additional forms as part of sign up workflow  \\n- Discuss documented concerns from A with James\\n\\nC: \\n- Work on improving the landing page to make the product more discoverable for new users\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 1.5114150047302246,\n",
      "  \"completion_token_count\": 84,\n",
      "  \"prompt_token_count\": 728,\n",
      "  \"cost\": 0.0016494799999999998,\n",
      "  \"completion_word_count\": 61,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-04 18:09:27,408] p93154 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=titan_template.txt, reps=3\n",
      "[2024-01-04 18:09:27,409] p93154 {544935498.py:35} INFO - going to summarize idx=1, file=data/raw/1/call_center_transcript_0_transcript.txt via amazon.titan-text-express-v1\n",
      "[2024-01-04 18:09:27,410] p93154 {544935498.py:38} INFO - read prompt template from data/prompts/titan_template.txt\n",
      "[2024-01-04 18:09:27,418] p93154 {544935498.py:43} INFO - prompt for data/raw/1/call_center_transcript_0_transcript.txt has 746 tokens\n",
      "[2024-01-04 18:09:27,419] p93154 {528272729.py:4} INFO - model_id=amazon.titan-text-express-v1, prompt length is 3087 characters, 560 words\n",
      "[2024-01-04 18:09:30,866] p93154 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nMeeting transcript: \\nA: Hi B, I want to discuss the workstream for our new product launch\\nB: Sure A, is there anything in particular you want to discuss?\\nA: Yes, I want to talk about how users enter into the product.  \\nB: Ok, in that case let me add in C.\\nC: Hey everyone\\nB: Hi C, A wants to discuss how users enter into the product.\\nA: its too complicated and we should remove friction.  for example, why do I need to fill out additional forms? I also find it difficult to find where to access the product when I first land on the landing page.  \\nB: I would also add that I think there are too many steps.\\nC: Ok, I can work on the landing page to make the product more discoverable but B can you work on the additonal forms?\\nB: Yes but I would need to work with James from another team as he needs to unblock the sign up workflow. A can you document any other concerns so that I can discuss with James only once?\\nA: Sure.\\n</conversation>\",\n",
      "  \"completion\": \"\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Document any other concerns about the product launch workstream so that they can be discussed with James from another team\\n\\nB:\\n- Work with James from another team to unblock the sign up workflow\\n- Make changes to the landing page to make the product more discoverable\\n\\nC:\\n- Work on the landing page to make the product more discoverable\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 3.4449400901794434,\n",
      "  \"completion_token_count\": 98,\n",
      "  \"prompt_token_count\": 750\n",
      "}\n",
      "[2024-01-04 18:09:30,869] p93154 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nMeeting transcript: \\nA: Hi B, I want to discuss the workstream for our new product launch\\nB: Sure A, is there anything in particular you want to discuss?\\nA: Yes, I want to talk about how users enter into the product.  \\nB: Ok, in that case let me add in C.\\nC: Hey everyone\\nB: Hi C, A wants to discuss how users enter into the product.\\nA: its too complicated and we should remove friction.  for example, why do I need to fill out additional forms? I also find it difficult to find where to access the product when I first land on the landing page.  \\nB: I would also add that I think there are too many steps.\\nC: Ok, I can work on the landing page to make the product more discoverable but B can you work on the additonal forms?\\nB: Yes but I would need to work with James from another team as he needs to unblock the sign up workflow. A can you document any other concerns so that I can discuss with James only once?\\nA: Sure.\\n</conversation>\",\n",
      "  \"completion\": \"<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Document any other concerns about the product launch workstream so that they can be discussed with James from another team\\n\\nB:\\n- Work with James from another team to unblock the sign up workflow\\n- Make changes to the landing page to make the product more discoverable\\n\\nC:\\n- Work on the landing page to make the product more discoverable\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 3.4449400901794434,\n",
      "  \"completion_token_count\": 98,\n",
      "  \"prompt_token_count\": 750,\n",
      "  \"cost\": 0.0007568000000000001,\n",
      "  \"completion_word_count\": 74,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-04 18:09:30,871] p93154 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=cohere_template.txt, reps=3\n",
      "[2024-01-04 18:09:30,872] p93154 {544935498.py:35} INFO - going to summarize idx=1, file=data/raw/1/call_center_transcript_0_transcript.txt via cohere.command-text-v14\n",
      "[2024-01-04 18:09:30,872] p93154 {544935498.py:38} INFO - read prompt template from data/prompts/cohere_template.txt\n",
      "[2024-01-04 18:09:30,877] p93154 {544935498.py:43} INFO - prompt for data/raw/1/call_center_transcript_0_transcript.txt has 741 tokens\n",
      "[2024-01-04 18:09:30,878] p93154 {528272729.py:4} INFO - model_id=cohere.command-text-v14, prompt length is 3082 characters, 559 words\n",
      "[2024-01-04 18:09:38,045] p93154 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nMeeting transcript: \\nA: Hi B, I want to discuss the workstream for our new product launch\\nB: Sure A, is there anything in particular you want to discuss?\\nA: Yes, I want to talk about how users enter into the product.  \\nB: Ok, in that case let me add in C.\\nC: Hey everyone\\nB: Hi C, A wants to discuss how users enter into the product.\\nA: its too complicated and we should remove friction.  for example, why do I need to fill out additional forms? I also find it difficult to find where to access the product when I first land on the landing page.  \\nB: I would also add that I think there are too many steps.\\nC: Ok, I can work on the landing page to make the product more discoverable but B can you work on the additonal forms?\\nB: Yes but I would need to work with James from another team as he needs to unblock the sign up workflow. A can you document any other concerns so that I can discuss with James only once?\\nA: Sure.\\n</conversation>\",\n",
      "  \"completion\": \" <output>\\nHere are the action items for each speaker based on the conversation:\\n\\nA:\\n- Document specific concerns about the sign-up workflow to simplify user entrance to the product \\n- Collaborate with B and James to simplify the forms during the sign-up process \\n\\nB:\\n- Unblock the sign-up workflow by working with James \\n- Delegate A's concerns to James \\n\\nC: \\n- Work on the landing page to make the product more discoverable \\n\\nIf there are any other action items resulting from this conversation, please provide additional information or details from the conversation that would be helpful in generating a comprehensive list of action items.  I am happy to revise the list based on any additional information.</output> \",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 7.166618824005127,\n",
      "  \"completion_token_count\": 154,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-04 18:09:38,047] p93154 {544935498.py:76} INFO - prompt_token_count is None for cohere.command-text-v14, setting it to 741 \n",
      "[2024-01-04 18:09:38,050] p93154 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nMeeting transcript: \\nA: Hi B, I want to discuss the workstream for our new product launch\\nB: Sure A, is there anything in particular you want to discuss?\\nA: Yes, I want to talk about how users enter into the product.  \\nB: Ok, in that case let me add in C.\\nC: Hey everyone\\nB: Hi C, A wants to discuss how users enter into the product.\\nA: its too complicated and we should remove friction.  for example, why do I need to fill out additional forms? I also find it difficult to find where to access the product when I first land on the landing page.  \\nB: I would also add that I think there are too many steps.\\nC: Ok, I can work on the landing page to make the product more discoverable but B can you work on the additonal forms?\\nB: Yes but I would need to work with James from another team as he needs to unblock the sign up workflow. A can you document any other concerns so that I can discuss with James only once?\\nA: Sure.\\n</conversation>\",\n",
      "  \"completion\": \"<output>\\nHere are the action items for each speaker based on the conversation:\\n\\nA:\\n- Document specific concerns about the sign-up workflow to simplify user entrance to the product \\n- Collaborate with B and James to simplify the forms during the sign-up process \\n\\nB:\\n- Unblock the sign-up workflow by working with James \\n- Delegate A's concerns to James \\n\\nC: \\n- Work on the landing page to make the product more discoverable \\n\\nIf there are any other action items resulting from this conversation, please provide additional information or details from the conversation that would be helpful in generating a comprehensive list of action items.  I am happy to revise the list based on any additional information.</output>\",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 7.166618824005127,\n",
      "  \"completion_token_count\": 154,\n",
      "  \"prompt_token_count\": 741,\n",
      "  \"cost\": 0.0014195000000000002,\n",
      "  \"completion_word_count\": 116,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-04 18:09:38,052] p93154 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=anthropic_template_single_line_reason.txt, reps=3\n",
      "[2024-01-04 18:09:38,053] p93154 {544935498.py:35} INFO - going to summarize idx=1, file=data/raw/1/call_center_transcript_0_transcript.txt via anthropic.claude-instant-v1\n",
      "[2024-01-04 18:09:38,054] p93154 {544935498.py:38} INFO - read prompt template from data/prompts/anthropic_template_single_line_reason.txt\n",
      "[2024-01-04 18:09:38,059] p93154 {544935498.py:43} INFO - prompt for data/raw/1/call_center_transcript_0_transcript.txt has 728 tokens\n",
      "[2024-01-04 18:09:38,060] p93154 {528272729.py:4} INFO - model_id=anthropic.claude-instant-v1, prompt length is 3004 characters, 543 words\n",
      "[2024-01-04 18:09:40,657] p93154 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nMeeting transcript: \\nA: Hi B, I want to discuss the workstream for our new product launch\\nB: Sure A, is there anything in particular you want to discuss?\\nA: Yes, I want to talk about how users enter into the product.  \\nB: Ok, in that case let me add in C.\\nC: Hey everyone\\nB: Hi C, A wants to discuss how users enter into the product.\\nA: its too complicated and we should remove friction.  for example, why do I need to fill out additional forms? I also find it difficult to find where to access the product when I first land on the landing page.  \\nB: I would also add that I think there are too many steps.\\nC: Ok, I can work on the landing page to make the product more discoverable but B can you work on the additonal forms?\\nB: Yes but I would need to work with James from another team as he needs to unblock the sign up workflow. A can you document any other concerns so that I can discuss with James only once?\\nA: Sure.\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \" <output>\\nA: \\n- Document any other concerns with the user entry process to discuss with James\\n\\nB:\\n- Work with James from another team to streamline the additional forms in the signup workflow  \\n- Discuss concerns documented by A with James\\n\\nC: \\n- Work on improving the landing page to make the product more discoverable for new users\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 2.594956159591675,\n",
      "  \"completion_token_count\": 82,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-04 18:09:40,658] p93154 {544935498.py:76} INFO - prompt_token_count is None for anthropic.claude-instant-v1, setting it to 728 \n",
      "[2024-01-04 18:09:40,662] p93154 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nMeeting transcript: \\nA: Hi B, I want to discuss the workstream for our new product launch\\nB: Sure A, is there anything in particular you want to discuss?\\nA: Yes, I want to talk about how users enter into the product.  \\nB: Ok, in that case let me add in C.\\nC: Hey everyone\\nB: Hi C, A wants to discuss how users enter into the product.\\nA: its too complicated and we should remove friction.  for example, why do I need to fill out additional forms? I also find it difficult to find where to access the product when I first land on the landing page.  \\nB: I would also add that I think there are too many steps.\\nC: Ok, I can work on the landing page to make the product more discoverable but B can you work on the additonal forms?\\nB: Yes but I would need to work with James from another team as he needs to unblock the sign up workflow. A can you document any other concerns so that I can discuss with James only once?\\nA: Sure.\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \"<output>\\nA: \\n- Document any other concerns with the user entry process to discuss with James\\n\\nB:\\n- Work with James from another team to streamline the additional forms in the signup workflow  \\n- Discuss concerns documented by A with James\\n\\nC: \\n- Work on improving the landing page to make the product more discoverable for new users\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 2.594956159591675,\n",
      "  \"completion_token_count\": 82,\n",
      "  \"prompt_token_count\": 728,\n",
      "  \"cost\": 0.0016384599999999998,\n",
      "  \"completion_word_count\": 59,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-04 18:09:40,667] p93154 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=titan_template.txt, reps=3\n",
      "[2024-01-04 18:09:40,668] p93154 {544935498.py:35} INFO - going to summarize idx=1, file=data/raw/1/call_center_transcript_0_transcript.txt via amazon.titan-text-express-v1\n",
      "[2024-01-04 18:09:40,669] p93154 {544935498.py:38} INFO - read prompt template from data/prompts/titan_template.txt\n",
      "[2024-01-04 18:09:40,675] p93154 {544935498.py:43} INFO - prompt for data/raw/1/call_center_transcript_0_transcript.txt has 746 tokens\n",
      "[2024-01-04 18:09:40,677] p93154 {528272729.py:4} INFO - model_id=amazon.titan-text-express-v1, prompt length is 3087 characters, 560 words\n",
      "[2024-01-04 18:09:43,951] p93154 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nMeeting transcript: \\nA: Hi B, I want to discuss the workstream for our new product launch\\nB: Sure A, is there anything in particular you want to discuss?\\nA: Yes, I want to talk about how users enter into the product.  \\nB: Ok, in that case let me add in C.\\nC: Hey everyone\\nB: Hi C, A wants to discuss how users enter into the product.\\nA: its too complicated and we should remove friction.  for example, why do I need to fill out additional forms? I also find it difficult to find where to access the product when I first land on the landing page.  \\nB: I would also add that I think there are too many steps.\\nC: Ok, I can work on the landing page to make the product more discoverable but B can you work on the additonal forms?\\nB: Yes but I would need to work with James from another team as he needs to unblock the sign up workflow. A can you document any other concerns so that I can discuss with James only once?\\nA: Sure.\\n</conversation>\",\n",
      "  \"completion\": \"\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Document any other concerns related to user entry into the product\\n- Discuss with James from another team to unblock the sign up workflow\\n\\nB:\\n- Work with James from another team to unblock the sign up workflow\\n\\nC:\\n- Work on the landing page to make the product more discoverable\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 3.2725372314453125,\n",
      "  \"completion_token_count\": 87,\n",
      "  \"prompt_token_count\": 750\n",
      "}\n",
      "[2024-01-04 18:09:43,955] p93154 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nMeeting transcript: \\nA: Hi B, I want to discuss the workstream for our new product launch\\nB: Sure A, is there anything in particular you want to discuss?\\nA: Yes, I want to talk about how users enter into the product.  \\nB: Ok, in that case let me add in C.\\nC: Hey everyone\\nB: Hi C, A wants to discuss how users enter into the product.\\nA: its too complicated and we should remove friction.  for example, why do I need to fill out additional forms? I also find it difficult to find where to access the product when I first land on the landing page.  \\nB: I would also add that I think there are too many steps.\\nC: Ok, I can work on the landing page to make the product more discoverable but B can you work on the additonal forms?\\nB: Yes but I would need to work with James from another team as he needs to unblock the sign up workflow. A can you document any other concerns so that I can discuss with James only once?\\nA: Sure.\\n</conversation>\",\n",
      "  \"completion\": \"<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Document any other concerns related to user entry into the product\\n- Discuss with James from another team to unblock the sign up workflow\\n\\nB:\\n- Work with James from another team to unblock the sign up workflow\\n\\nC:\\n- Work on the landing page to make the product more discoverable\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 3.2725372314453125,\n",
      "  \"completion_token_count\": 87,\n",
      "  \"prompt_token_count\": 750,\n",
      "  \"cost\": 0.0007392000000000001,\n",
      "  \"completion_word_count\": 65,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-04 18:09:43,958] p93154 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=cohere_template.txt, reps=3\n",
      "[2024-01-04 18:09:43,959] p93154 {544935498.py:35} INFO - going to summarize idx=1, file=data/raw/1/call_center_transcript_0_transcript.txt via cohere.command-text-v14\n",
      "[2024-01-04 18:09:43,961] p93154 {544935498.py:38} INFO - read prompt template from data/prompts/cohere_template.txt\n",
      "[2024-01-04 18:09:43,969] p93154 {544935498.py:43} INFO - prompt for data/raw/1/call_center_transcript_0_transcript.txt has 741 tokens\n",
      "[2024-01-04 18:09:43,970] p93154 {528272729.py:4} INFO - model_id=cohere.command-text-v14, prompt length is 3082 characters, 559 words\n",
      "[2024-01-04 18:09:51,256] p93154 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nMeeting transcript: \\nA: Hi B, I want to discuss the workstream for our new product launch\\nB: Sure A, is there anything in particular you want to discuss?\\nA: Yes, I want to talk about how users enter into the product.  \\nB: Ok, in that case let me add in C.\\nC: Hey everyone\\nB: Hi C, A wants to discuss how users enter into the product.\\nA: its too complicated and we should remove friction.  for example, why do I need to fill out additional forms? I also find it difficult to find where to access the product when I first land on the landing page.  \\nB: I would also add that I think there are too many steps.\\nC: Ok, I can work on the landing page to make the product more discoverable but B can you work on the additonal forms?\\nB: Yes but I would need to work with James from another team as he needs to unblock the sign up workflow. A can you document any other concerns so that I can discuss with James only once?\\nA: Sure.\\n</conversation>\",\n",
      "  \"completion\": \" <output>\\nHere are the action items arising from the conversation:\\n\\nA:\\n- Document specific friction points and areas of improvement in the user entry process for follow-up with B and James. \\n- Collaborate with B and James to streamline the sign-up workflow. \\n\\nB:\\n- Work with James from the other team to unblock the sign-up workflow and reduce the number of steps. \\n- Ensure that A documents any other concerns to streamline discussions with James.\\n\\nC: \\n- Make the product more discoverable by working on the landing page to improve user experience.\\n</output>\\n\\nIn summary, A, B, and C have clear action items to work on following their discussion. A and B will collaborate to improve the sign-up process, including reducing friction and working with James from another team. C will focus on making the product more discoverable by improving the landing page. These actions aim to improve the user experience in entering and accessing the product.\",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 7.284584999084473,\n",
      "  \"completion_token_count\": 209,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-04 18:09:51,258] p93154 {544935498.py:76} INFO - prompt_token_count is None for cohere.command-text-v14, setting it to 741 \n",
      "[2024-01-04 18:09:51,260] p93154 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nMeeting transcript: \\nA: Hi B, I want to discuss the workstream for our new product launch\\nB: Sure A, is there anything in particular you want to discuss?\\nA: Yes, I want to talk about how users enter into the product.  \\nB: Ok, in that case let me add in C.\\nC: Hey everyone\\nB: Hi C, A wants to discuss how users enter into the product.\\nA: its too complicated and we should remove friction.  for example, why do I need to fill out additional forms? I also find it difficult to find where to access the product when I first land on the landing page.  \\nB: I would also add that I think there are too many steps.\\nC: Ok, I can work on the landing page to make the product more discoverable but B can you work on the additonal forms?\\nB: Yes but I would need to work with James from another team as he needs to unblock the sign up workflow. A can you document any other concerns so that I can discuss with James only once?\\nA: Sure.\\n</conversation>\",\n",
      "  \"completion\": \"<output>\\nHere are the action items arising from the conversation:\\n\\nA:\\n- Document specific friction points and areas of improvement in the user entry process for follow-up with B and James. \\n- Collaborate with B and James to streamline the sign-up workflow. \\n\\nB:\\n- Work with James from the other team to unblock the sign-up workflow and reduce the number of steps. \\n- Ensure that A documents any other concerns to streamline discussions with James.\\n\\nC: \\n- Make the product more discoverable by working on the landing page to improve user experience.\\n</output>\\n\\nIn summary, A, B, and C have clear action items to work on following their discussion. A and B will collaborate to improve the sign-up process, including reducing friction and working with James from another team. C will focus on making the product more discoverable by improving the landing page. These actions aim to improve the user experience in entering and accessing the product.\",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 7.284584999084473,\n",
      "  \"completion_token_count\": 209,\n",
      "  \"prompt_token_count\": 741,\n",
      "  \"cost\": 0.0015295,\n",
      "  \"completion_word_count\": 157,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-04 18:09:51,264] p93154 {544935498.py:19} INFO - idx=2, tf=data/raw/4/call_center_transcript_4_transcript.txt, file_id=call_center_transcript_4, golden_summary_fpath=data/raw/0/example_prompt_transcript_golden_summary.txt\n",
      "[2024-01-04 18:09:51,264] p93154 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=anthropic_template_single_line_reason.txt, reps=3\n",
      "[2024-01-04 18:09:51,265] p93154 {544935498.py:35} INFO - going to summarize idx=2, file=data/raw/4/call_center_transcript_4_transcript.txt via anthropic.claude-instant-v1\n",
      "[2024-01-04 18:09:51,266] p93154 {544935498.py:38} INFO - read prompt template from data/prompts/anthropic_template_single_line_reason.txt\n",
      "[2024-01-04 18:09:51,277] p93154 {544935498.py:43} INFO - prompt for data/raw/4/call_center_transcript_4_transcript.txt has 950 tokens\n",
      "[2024-01-04 18:09:51,278] p93154 {528272729.py:4} INFO - model_id=anthropic.claude-instant-v1, prompt length is 4345 characters, 717 words\n",
      "[2024-01-04 18:09:53,614] p93154 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to further discuss options for the optimal cloud instance type to host our new product recommendation model. As a refresher on the requirements - this model will be query intensive, with thousands of customers hitting the prediction API simultaneously. And it relies on a large deep neural network for the recommendations. \\n\\nB: Yes, we should go through the pros and cons again of the main instance family options available. For standard instance types without GPUs, we'd likely need to go with a high CPU and memory specification to handle the computation and concurrency needs.\\n\\nC: Standard instances would be more cost-effective, but prediction latency would suffer without GPU acceleration. The neural network calculations could be 5-10x slower based on our initial benchmarks. For a customer-facing model, slow predictions could lead to poor user experience.\\n\\nA: That's a very good point. While GPU-powered instances would be more expensive, the business value of sub-second prediction latency for users is high. We want customers to get engaging, personalized recommendations immediately to drive conversions.\\n\\nB: I agree, I think GPU acceleration makes more sense despite the increased cloud costs. In addition to the deep learning performance boost, some of the other model parallelization and tuning optimizations we're doing would also run faster on GPUs.\\n\\nC: It seems like GPU instances are the way to go then as long as the total monthly cost is affordable. However, we may be able to optimize the specific type of GPU instance to find the best balance of throughput versus cost. \\n\\nA: Definitely, the major cloud providers offer an array of GPU instance types optimized for different use cases. We should benchmark performance against our workload with NVIDIA T4 GPUs, which are cost-optimized options, as well as some higher-end options like A100 GPUs.\\n\\nC: Do you think we should also explore using something like Elastic Inference GPU attachments? Those let you augment existing instances with fractional GPU access that is more cost-effective.\\n\\nB: Hmm good question. In theory that could work well for the cost-performance balance. We'd need to test compatibility with the types of GPU optimizations we're running in the model though...\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \" <output>\\nA: \\n- Benchmark performance of recommendation model against different GPU instance types from major cloud providers including NVIDIA T4 and A100 GPUs\\n- Consider exploring Elastic Inference GPU attachments and test compatibility with model optimizations\\n\\nB: \\n- Help benchmark performance against different GPU instance types\\n- Consider exploring Elastic Inference GPU attachments and provide input on compatibility with model optimizations\\n\\nC: \\n- Consider exploring Elastic Inference GPU attachments as an alternative to full GPU instances for cost-performance balance  \\n- Help benchmark performance against different GPU instance types\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 2.333359956741333,\n",
      "  \"completion_token_count\": 122,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-04 18:09:53,616] p93154 {544935498.py:76} INFO - prompt_token_count is None for anthropic.claude-instant-v1, setting it to 950 \n",
      "[2024-01-04 18:09:53,620] p93154 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to further discuss options for the optimal cloud instance type to host our new product recommendation model. As a refresher on the requirements - this model will be query intensive, with thousands of customers hitting the prediction API simultaneously. And it relies on a large deep neural network for the recommendations. \\n\\nB: Yes, we should go through the pros and cons again of the main instance family options available. For standard instance types without GPUs, we'd likely need to go with a high CPU and memory specification to handle the computation and concurrency needs.\\n\\nC: Standard instances would be more cost-effective, but prediction latency would suffer without GPU acceleration. The neural network calculations could be 5-10x slower based on our initial benchmarks. For a customer-facing model, slow predictions could lead to poor user experience.\\n\\nA: That's a very good point. While GPU-powered instances would be more expensive, the business value of sub-second prediction latency for users is high. We want customers to get engaging, personalized recommendations immediately to drive conversions.\\n\\nB: I agree, I think GPU acceleration makes more sense despite the increased cloud costs. In addition to the deep learning performance boost, some of the other model parallelization and tuning optimizations we're doing would also run faster on GPUs.\\n\\nC: It seems like GPU instances are the way to go then as long as the total monthly cost is affordable. However, we may be able to optimize the specific type of GPU instance to find the best balance of throughput versus cost. \\n\\nA: Definitely, the major cloud providers offer an array of GPU instance types optimized for different use cases. We should benchmark performance against our workload with NVIDIA T4 GPUs, which are cost-optimized options, as well as some higher-end options like A100 GPUs.\\n\\nC: Do you think we should also explore using something like Elastic Inference GPU attachments? Those let you augment existing instances with fractional GPU access that is more cost-effective.\\n\\nB: Hmm good question. In theory that could work well for the cost-performance balance. We'd need to test compatibility with the types of GPU optimizations we're running in the model though...\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \"<output>\\nA: \\n- Benchmark performance of recommendation model against different GPU instance types from major cloud providers including NVIDIA T4 and A100 GPUs\\n- Consider exploring Elastic Inference GPU attachments and test compatibility with model optimizations\\n\\nB: \\n- Help benchmark performance against different GPU instance types\\n- Consider exploring Elastic Inference GPU attachments and provide input on compatibility with model optimizations\\n\\nC: \\n- Consider exploring Elastic Inference GPU attachments as an alternative to full GPU instances for cost-performance balance  \\n- Help benchmark performance against different GPU instance types\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 2.333359956741333,\n",
      "  \"completion_token_count\": 122,\n",
      "  \"prompt_token_count\": 950,\n",
      "  \"cost\": 0.00222072,\n",
      "  \"completion_word_count\": 89,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-04 18:09:53,623] p93154 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=titan_template.txt, reps=3\n",
      "[2024-01-04 18:09:53,624] p93154 {544935498.py:35} INFO - going to summarize idx=2, file=data/raw/4/call_center_transcript_4_transcript.txt via amazon.titan-text-express-v1\n",
      "[2024-01-04 18:09:53,626] p93154 {544935498.py:38} INFO - read prompt template from data/prompts/titan_template.txt\n",
      "[2024-01-04 18:09:53,634] p93154 {544935498.py:43} INFO - prompt for data/raw/4/call_center_transcript_4_transcript.txt has 968 tokens\n",
      "[2024-01-04 18:09:53,635] p93154 {528272729.py:4} INFO - model_id=amazon.titan-text-express-v1, prompt length is 4428 characters, 734 words\n",
      "[2024-01-04 18:10:00,001] p93154 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nA: I wanted to further discuss options for the optimal cloud instance type to host our new product recommendation model. As a refresher on the requirements - this model will be query intensive, with thousands of customers hitting the prediction API simultaneously. And it relies on a large deep neural network for the recommendations. \\n\\nB: Yes, we should go through the pros and cons again of the main instance family options available. For standard instance types without GPUs, we'd likely need to go with a high CPU and memory specification to handle the computation and concurrency needs.\\n\\nC: Standard instances would be more cost-effective, but prediction latency would suffer without GPU acceleration. The neural network calculations could be 5-10x slower based on our initial benchmarks. For a customer-facing model, slow predictions could lead to poor user experience.\\n\\nA: That's a very good point. While GPU-powered instances would be more expensive, the business value of sub-second prediction latency for users is high. We want customers to get engaging, personalized recommendations immediately to drive conversions.\\n\\nB: I agree, I think GPU acceleration makes more sense despite the increased cloud costs. In addition to the deep learning performance boost, some of the other model parallelization and tuning optimizations we're doing would also run faster on GPUs.\\n\\nC: It seems like GPU instances are the way to go then as long as the total monthly cost is affordable. However, we may be able to optimize the specific type of GPU instance to find the best balance of throughput versus cost. \\n\\nA: Definitely, the major cloud providers offer an array of GPU instance types optimized for different use cases. We should benchmark performance against our workload with NVIDIA T4 GPUs, which are cost-optimized options, as well as some higher-end options like A100 GPUs.\\n\\nC: Do you think we should also explore using something like Elastic Inference GPU attachments? Those let you augment existing instances with fractional GPU access that is more cost-effective.\\n\\nB: Hmm good question. In theory that could work well for the cost-performance balance. We'd need to test compatibility with the types of GPU optimizations we're running in the model though...\\n</conversation>\",\n",
      "  \"completion\": \"\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Evaluate cost-optimized GPU instance types like NVIDIA T4 GPUs and higher-end options like A100 GPUs for benchmarking performance against workload\\n- Explore using Elastic Inference GPU attachments for cost-effective GPU access\\n- Determine compatibility with model's GPU optimizations\\n\\nB:\\n- None explicitly stated\\n\\nC:\\n- Research and evaluate cost-optimized GPU instance types like NVIDIA T4 GPUs and higher-end options like A100 GPUs for benchmarking performance against workload\\n- Explore using Elastic Inference GPU attachments for cost-effective GPU access\\n- Determine compatibility with model's GPU optimizations\\n- Recommend the optimal cloud instance type based on cost, performance, and compatibility requirements\\n- Collaborate with the cloud team to provision and configure the instance type\\n- Monitor performance and adjust as needed\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 6.36501407623291,\n",
      "  \"completion_token_count\": 198,\n",
      "  \"prompt_token_count\": 976\n",
      "}\n",
      "[2024-01-04 18:10:00,002] p93154 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nA: I wanted to further discuss options for the optimal cloud instance type to host our new product recommendation model. As a refresher on the requirements - this model will be query intensive, with thousands of customers hitting the prediction API simultaneously. And it relies on a large deep neural network for the recommendations. \\n\\nB: Yes, we should go through the pros and cons again of the main instance family options available. For standard instance types without GPUs, we'd likely need to go with a high CPU and memory specification to handle the computation and concurrency needs.\\n\\nC: Standard instances would be more cost-effective, but prediction latency would suffer without GPU acceleration. The neural network calculations could be 5-10x slower based on our initial benchmarks. For a customer-facing model, slow predictions could lead to poor user experience.\\n\\nA: That's a very good point. While GPU-powered instances would be more expensive, the business value of sub-second prediction latency for users is high. We want customers to get engaging, personalized recommendations immediately to drive conversions.\\n\\nB: I agree, I think GPU acceleration makes more sense despite the increased cloud costs. In addition to the deep learning performance boost, some of the other model parallelization and tuning optimizations we're doing would also run faster on GPUs.\\n\\nC: It seems like GPU instances are the way to go then as long as the total monthly cost is affordable. However, we may be able to optimize the specific type of GPU instance to find the best balance of throughput versus cost. \\n\\nA: Definitely, the major cloud providers offer an array of GPU instance types optimized for different use cases. We should benchmark performance against our workload with NVIDIA T4 GPUs, which are cost-optimized options, as well as some higher-end options like A100 GPUs.\\n\\nC: Do you think we should also explore using something like Elastic Inference GPU attachments? Those let you augment existing instances with fractional GPU access that is more cost-effective.\\n\\nB: Hmm good question. In theory that could work well for the cost-performance balance. We'd need to test compatibility with the types of GPU optimizations we're running in the model though...\\n</conversation>\",\n",
      "  \"completion\": \"<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Evaluate cost-optimized GPU instance types like NVIDIA T4 GPUs and higher-end options like A100 GPUs for benchmarking performance against workload\\n- Explore using Elastic Inference GPU attachments for cost-effective GPU access\\n- Determine compatibility with model's GPU optimizations\\n\\nB:\\n- None explicitly stated\\n\\nC:\\n- Research and evaluate cost-optimized GPU instance types like NVIDIA T4 GPUs and higher-end options like A100 GPUs for benchmarking performance against workload\\n- Explore using Elastic Inference GPU attachments for cost-effective GPU access\\n- Determine compatibility with model's GPU optimizations\\n- Recommend the optimal cloud instance type based on cost, performance, and compatibility requirements\\n- Collaborate with the cloud team to provision and configure the instance type\\n- Monitor performance and adjust as needed\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 6.36501407623291,\n",
      "  \"completion_token_count\": 198,\n",
      "  \"prompt_token_count\": 976,\n",
      "  \"cost\": 0.0010976,\n",
      "  \"completion_word_count\": 133,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-04 18:10:00,003] p93154 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=cohere_template.txt, reps=3\n",
      "[2024-01-04 18:10:00,003] p93154 {544935498.py:35} INFO - going to summarize idx=2, file=data/raw/4/call_center_transcript_4_transcript.txt via cohere.command-text-v14\n",
      "[2024-01-04 18:10:00,004] p93154 {544935498.py:38} INFO - read prompt template from data/prompts/cohere_template.txt\n",
      "[2024-01-04 18:10:00,006] p93154 {544935498.py:43} INFO - prompt for data/raw/4/call_center_transcript_4_transcript.txt has 963 tokens\n",
      "[2024-01-04 18:10:00,007] p93154 {528272729.py:4} INFO - model_id=cohere.command-text-v14, prompt length is 4423 characters, 733 words\n",
      "[2024-01-04 18:10:05,973] p93154 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to further discuss options for the optimal cloud instance type to host our new product recommendation model. As a refresher on the requirements - this model will be query intensive, with thousands of customers hitting the prediction API simultaneously. And it relies on a large deep neural network for the recommendations. \\n\\nB: Yes, we should go through the pros and cons again of the main instance family options available. For standard instance types without GPUs, we'd likely need to go with a high CPU and memory specification to handle the computation and concurrency needs.\\n\\nC: Standard instances would be more cost-effective, but prediction latency would suffer without GPU acceleration. The neural network calculations could be 5-10x slower based on our initial benchmarks. For a customer-facing model, slow predictions could lead to poor user experience.\\n\\nA: That's a very good point. While GPU-powered instances would be more expensive, the business value of sub-second prediction latency for users is high. We want customers to get engaging, personalized recommendations immediately to drive conversions.\\n\\nB: I agree, I think GPU acceleration makes more sense despite the increased cloud costs. In addition to the deep learning performance boost, some of the other model parallelization and tuning optimizations we're doing would also run faster on GPUs.\\n\\nC: It seems like GPU instances are the way to go then as long as the total monthly cost is affordable. However, we may be able to optimize the specific type of GPU instance to find the best balance of throughput versus cost. \\n\\nA: Definitely, the major cloud providers offer an array of GPU instance types optimized for different use cases. We should benchmark performance against our workload with NVIDIA T4 GPUs, which are cost-optimized options, as well as some higher-end options like A100 GPUs.\\n\\nC: Do you think we should also explore using something like Elastic Inference GPU attachments? Those let you augment existing instances with fractional GPU access that is more cost-effective.\\n\\nB: Hmm good question. In theory that could work well for the cost-performance balance. We'd need to test compatibility with the types of GPU optimizations we're running in the model though...\\n</conversation>\",\n",
      "  \"completion\": \" Here are the action items for each speaker:\\n\\nA:\\n- Lead a discussion on the requirements of the product recommendation model\\n- Evaluate the optimal cloud instance type that can handle thousands of customers \\n- Assess the pros and cons of standard instance types without GPUs and their ability to handle computation and concurrency needs\\n\\nB:\\n- Provide information on the different instance types available and their potential impact on the model \\n- Help evaluate the option of GPU-powered instances and their potential boost to performance \\n\\nC:\\n- Outline the potential for increased prediction latency with standard instances and its impact on user experience \\n- Highlight the potential cost savings of Elastic Inference GPU attachments and test compatibility with the types of GPU optimizations being used \\n\\nWould you like me to generate any other lists of action items based on conversation transcripts? \",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 5.965457201004028,\n",
      "  \"completion_token_count\": 189,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-04 18:10:05,973] p93154 {544935498.py:76} INFO - prompt_token_count is None for cohere.command-text-v14, setting it to 963 \n",
      "[2024-01-04 18:10:05,975] p93154 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to further discuss options for the optimal cloud instance type to host our new product recommendation model. As a refresher on the requirements - this model will be query intensive, with thousands of customers hitting the prediction API simultaneously. And it relies on a large deep neural network for the recommendations. \\n\\nB: Yes, we should go through the pros and cons again of the main instance family options available. For standard instance types without GPUs, we'd likely need to go with a high CPU and memory specification to handle the computation and concurrency needs.\\n\\nC: Standard instances would be more cost-effective, but prediction latency would suffer without GPU acceleration. The neural network calculations could be 5-10x slower based on our initial benchmarks. For a customer-facing model, slow predictions could lead to poor user experience.\\n\\nA: That's a very good point. While GPU-powered instances would be more expensive, the business value of sub-second prediction latency for users is high. We want customers to get engaging, personalized recommendations immediately to drive conversions.\\n\\nB: I agree, I think GPU acceleration makes more sense despite the increased cloud costs. In addition to the deep learning performance boost, some of the other model parallelization and tuning optimizations we're doing would also run faster on GPUs.\\n\\nC: It seems like GPU instances are the way to go then as long as the total monthly cost is affordable. However, we may be able to optimize the specific type of GPU instance to find the best balance of throughput versus cost. \\n\\nA: Definitely, the major cloud providers offer an array of GPU instance types optimized for different use cases. We should benchmark performance against our workload with NVIDIA T4 GPUs, which are cost-optimized options, as well as some higher-end options like A100 GPUs.\\n\\nC: Do you think we should also explore using something like Elastic Inference GPU attachments? Those let you augment existing instances with fractional GPU access that is more cost-effective.\\n\\nB: Hmm good question. In theory that could work well for the cost-performance balance. We'd need to test compatibility with the types of GPU optimizations we're running in the model though...\\n</conversation>\",\n",
      "  \"completion\": \"Here are the action items for each speaker:\\n\\nA:\\n- Lead a discussion on the requirements of the product recommendation model\\n- Evaluate the optimal cloud instance type that can handle thousands of customers \\n- Assess the pros and cons of standard instance types without GPUs and their ability to handle computation and concurrency needs\\n\\nB:\\n- Provide information on the different instance types available and their potential impact on the model \\n- Help evaluate the option of GPU-powered instances and their potential boost to performance \\n\\nC:\\n- Outline the potential for increased prediction latency with standard instances and its impact on user experience \\n- Highlight the potential cost savings of Elastic Inference GPU attachments and test compatibility with the types of GPU optimizations being used \\n\\nWould you like me to generate any other lists of action items based on conversation transcripts?\",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 5.965457201004028,\n",
      "  \"completion_token_count\": 189,\n",
      "  \"prompt_token_count\": 963,\n",
      "  \"cost\": 0.0018225000000000001,\n",
      "  \"completion_word_count\": 142,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-04 18:10:05,977] p93154 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=anthropic_template_single_line_reason.txt, reps=3\n",
      "[2024-01-04 18:10:05,978] p93154 {544935498.py:35} INFO - going to summarize idx=2, file=data/raw/4/call_center_transcript_4_transcript.txt via anthropic.claude-instant-v1\n",
      "[2024-01-04 18:10:05,979] p93154 {544935498.py:38} INFO - read prompt template from data/prompts/anthropic_template_single_line_reason.txt\n",
      "[2024-01-04 18:10:05,985] p93154 {544935498.py:43} INFO - prompt for data/raw/4/call_center_transcript_4_transcript.txt has 950 tokens\n",
      "[2024-01-04 18:10:05,985] p93154 {528272729.py:4} INFO - model_id=anthropic.claude-instant-v1, prompt length is 4345 characters, 717 words\n",
      "[2024-01-04 18:10:08,360] p93154 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to further discuss options for the optimal cloud instance type to host our new product recommendation model. As a refresher on the requirements - this model will be query intensive, with thousands of customers hitting the prediction API simultaneously. And it relies on a large deep neural network for the recommendations. \\n\\nB: Yes, we should go through the pros and cons again of the main instance family options available. For standard instance types without GPUs, we'd likely need to go with a high CPU and memory specification to handle the computation and concurrency needs.\\n\\nC: Standard instances would be more cost-effective, but prediction latency would suffer without GPU acceleration. The neural network calculations could be 5-10x slower based on our initial benchmarks. For a customer-facing model, slow predictions could lead to poor user experience.\\n\\nA: That's a very good point. While GPU-powered instances would be more expensive, the business value of sub-second prediction latency for users is high. We want customers to get engaging, personalized recommendations immediately to drive conversions.\\n\\nB: I agree, I think GPU acceleration makes more sense despite the increased cloud costs. In addition to the deep learning performance boost, some of the other model parallelization and tuning optimizations we're doing would also run faster on GPUs.\\n\\nC: It seems like GPU instances are the way to go then as long as the total monthly cost is affordable. However, we may be able to optimize the specific type of GPU instance to find the best balance of throughput versus cost. \\n\\nA: Definitely, the major cloud providers offer an array of GPU instance types optimized for different use cases. We should benchmark performance against our workload with NVIDIA T4 GPUs, which are cost-optimized options, as well as some higher-end options like A100 GPUs.\\n\\nC: Do you think we should also explore using something like Elastic Inference GPU attachments? Those let you augment existing instances with fractional GPU access that is more cost-effective.\\n\\nB: Hmm good question. In theory that could work well for the cost-performance balance. We'd need to test compatibility with the types of GPU optimizations we're running in the model though...\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \" <output>\\nA: \\n- Benchmark performance of recommendation model against different GPU instance types from major cloud providers including NVIDIA T4 and A100 GPUs\\n- Consider exploring Elastic Inference GPU attachments and test compatibility with model optimizations\\n\\nB: \\n- Help benchmark performance against different GPU instance types\\n- Consider exploring Elastic Inference GPU attachments and provide input on compatibility with model optimizations\\n\\nC: \\n- Consider exploring Elastic Inference GPU attachments as an alternative to full GPU instances for cost-performance balance  \\n- Help benchmark performance against different GPU instance types\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 2.372044086456299,\n",
      "  \"completion_token_count\": 122,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-04 18:10:08,361] p93154 {544935498.py:76} INFO - prompt_token_count is None for anthropic.claude-instant-v1, setting it to 950 \n",
      "[2024-01-04 18:10:08,364] p93154 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to further discuss options for the optimal cloud instance type to host our new product recommendation model. As a refresher on the requirements - this model will be query intensive, with thousands of customers hitting the prediction API simultaneously. And it relies on a large deep neural network for the recommendations. \\n\\nB: Yes, we should go through the pros and cons again of the main instance family options available. For standard instance types without GPUs, we'd likely need to go with a high CPU and memory specification to handle the computation and concurrency needs.\\n\\nC: Standard instances would be more cost-effective, but prediction latency would suffer without GPU acceleration. The neural network calculations could be 5-10x slower based on our initial benchmarks. For a customer-facing model, slow predictions could lead to poor user experience.\\n\\nA: That's a very good point. While GPU-powered instances would be more expensive, the business value of sub-second prediction latency for users is high. We want customers to get engaging, personalized recommendations immediately to drive conversions.\\n\\nB: I agree, I think GPU acceleration makes more sense despite the increased cloud costs. In addition to the deep learning performance boost, some of the other model parallelization and tuning optimizations we're doing would also run faster on GPUs.\\n\\nC: It seems like GPU instances are the way to go then as long as the total monthly cost is affordable. However, we may be able to optimize the specific type of GPU instance to find the best balance of throughput versus cost. \\n\\nA: Definitely, the major cloud providers offer an array of GPU instance types optimized for different use cases. We should benchmark performance against our workload with NVIDIA T4 GPUs, which are cost-optimized options, as well as some higher-end options like A100 GPUs.\\n\\nC: Do you think we should also explore using something like Elastic Inference GPU attachments? Those let you augment existing instances with fractional GPU access that is more cost-effective.\\n\\nB: Hmm good question. In theory that could work well for the cost-performance balance. We'd need to test compatibility with the types of GPU optimizations we're running in the model though...\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \"<output>\\nA: \\n- Benchmark performance of recommendation model against different GPU instance types from major cloud providers including NVIDIA T4 and A100 GPUs\\n- Consider exploring Elastic Inference GPU attachments and test compatibility with model optimizations\\n\\nB: \\n- Help benchmark performance against different GPU instance types\\n- Consider exploring Elastic Inference GPU attachments and provide input on compatibility with model optimizations\\n\\nC: \\n- Consider exploring Elastic Inference GPU attachments as an alternative to full GPU instances for cost-performance balance  \\n- Help benchmark performance against different GPU instance types\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 2.372044086456299,\n",
      "  \"completion_token_count\": 122,\n",
      "  \"prompt_token_count\": 950,\n",
      "  \"cost\": 0.00222072,\n",
      "  \"completion_word_count\": 89,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-04 18:10:08,367] p93154 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=titan_template.txt, reps=3\n",
      "[2024-01-04 18:10:08,369] p93154 {544935498.py:35} INFO - going to summarize idx=2, file=data/raw/4/call_center_transcript_4_transcript.txt via amazon.titan-text-express-v1\n",
      "[2024-01-04 18:10:08,372] p93154 {544935498.py:38} INFO - read prompt template from data/prompts/titan_template.txt\n",
      "[2024-01-04 18:10:08,380] p93154 {544935498.py:43} INFO - prompt for data/raw/4/call_center_transcript_4_transcript.txt has 968 tokens\n",
      "[2024-01-04 18:10:08,381] p93154 {528272729.py:4} INFO - model_id=amazon.titan-text-express-v1, prompt length is 4428 characters, 734 words\n",
      "[2024-01-04 18:10:13,627] p93154 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nA: I wanted to further discuss options for the optimal cloud instance type to host our new product recommendation model. As a refresher on the requirements - this model will be query intensive, with thousands of customers hitting the prediction API simultaneously. And it relies on a large deep neural network for the recommendations. \\n\\nB: Yes, we should go through the pros and cons again of the main instance family options available. For standard instance types without GPUs, we'd likely need to go with a high CPU and memory specification to handle the computation and concurrency needs.\\n\\nC: Standard instances would be more cost-effective, but prediction latency would suffer without GPU acceleration. The neural network calculations could be 5-10x slower based on our initial benchmarks. For a customer-facing model, slow predictions could lead to poor user experience.\\n\\nA: That's a very good point. While GPU-powered instances would be more expensive, the business value of sub-second prediction latency for users is high. We want customers to get engaging, personalized recommendations immediately to drive conversions.\\n\\nB: I agree, I think GPU acceleration makes more sense despite the increased cloud costs. In addition to the deep learning performance boost, some of the other model parallelization and tuning optimizations we're doing would also run faster on GPUs.\\n\\nC: It seems like GPU instances are the way to go then as long as the total monthly cost is affordable. However, we may be able to optimize the specific type of GPU instance to find the best balance of throughput versus cost. \\n\\nA: Definitely, the major cloud providers offer an array of GPU instance types optimized for different use cases. We should benchmark performance against our workload with NVIDIA T4 GPUs, which are cost-optimized options, as well as some higher-end options like A100 GPUs.\\n\\nC: Do you think we should also explore using something like Elastic Inference GPU attachments? Those let you augment existing instances with fractional GPU access that is more cost-effective.\\n\\nB: Hmm good question. In theory that could work well for the cost-performance balance. We'd need to test compatibility with the types of GPU optimizations we're running in the model though...\\n</conversation>\",\n",
      "  \"completion\": \"\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Evaluate cost-optimized GPU instance types like NVIDIA T4 GPUs and higher-end options like A100 GPUs for benchmarking performance against workload\\n- Explore using Elastic Inference GPU attachments for cost-effective GPU access\\n- Determine compatibility with model's GPU optimizations\\n\\nB:\\n- None explicitly stated\\n\\nC:\\n- Research and compare different GPU instance types from major cloud providers\\n- Benchmark performance with NVIDIA T4 GPUs and higher-end options\\n- Explore compatibility with model's GPU optimizations\\n- Recommend optimal GPU instance type based on cost-performance analysis\\n- Prepare cost estimates and present findings to stakeholders for decision-making\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 5.244941234588623,\n",
      "  \"completion_token_count\": 163,\n",
      "  \"prompt_token_count\": 976\n",
      "}\n",
      "[2024-01-04 18:10:13,628] p93154 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nA: I wanted to further discuss options for the optimal cloud instance type to host our new product recommendation model. As a refresher on the requirements - this model will be query intensive, with thousands of customers hitting the prediction API simultaneously. And it relies on a large deep neural network for the recommendations. \\n\\nB: Yes, we should go through the pros and cons again of the main instance family options available. For standard instance types without GPUs, we'd likely need to go with a high CPU and memory specification to handle the computation and concurrency needs.\\n\\nC: Standard instances would be more cost-effective, but prediction latency would suffer without GPU acceleration. The neural network calculations could be 5-10x slower based on our initial benchmarks. For a customer-facing model, slow predictions could lead to poor user experience.\\n\\nA: That's a very good point. While GPU-powered instances would be more expensive, the business value of sub-second prediction latency for users is high. We want customers to get engaging, personalized recommendations immediately to drive conversions.\\n\\nB: I agree, I think GPU acceleration makes more sense despite the increased cloud costs. In addition to the deep learning performance boost, some of the other model parallelization and tuning optimizations we're doing would also run faster on GPUs.\\n\\nC: It seems like GPU instances are the way to go then as long as the total monthly cost is affordable. However, we may be able to optimize the specific type of GPU instance to find the best balance of throughput versus cost. \\n\\nA: Definitely, the major cloud providers offer an array of GPU instance types optimized for different use cases. We should benchmark performance against our workload with NVIDIA T4 GPUs, which are cost-optimized options, as well as some higher-end options like A100 GPUs.\\n\\nC: Do you think we should also explore using something like Elastic Inference GPU attachments? Those let you augment existing instances with fractional GPU access that is more cost-effective.\\n\\nB: Hmm good question. In theory that could work well for the cost-performance balance. We'd need to test compatibility with the types of GPU optimizations we're running in the model though...\\n</conversation>\",\n",
      "  \"completion\": \"<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Evaluate cost-optimized GPU instance types like NVIDIA T4 GPUs and higher-end options like A100 GPUs for benchmarking performance against workload\\n- Explore using Elastic Inference GPU attachments for cost-effective GPU access\\n- Determine compatibility with model's GPU optimizations\\n\\nB:\\n- None explicitly stated\\n\\nC:\\n- Research and compare different GPU instance types from major cloud providers\\n- Benchmark performance with NVIDIA T4 GPUs and higher-end options\\n- Explore compatibility with model's GPU optimizations\\n- Recommend optimal GPU instance type based on cost-performance analysis\\n- Prepare cost estimates and present findings to stakeholders for decision-making\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 5.244941234588623,\n",
      "  \"completion_token_count\": 163,\n",
      "  \"prompt_token_count\": 976,\n",
      "  \"cost\": 0.0010416,\n",
      "  \"completion_word_count\": 108,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-04 18:10:13,630] p93154 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=cohere_template.txt, reps=3\n",
      "[2024-01-04 18:10:13,631] p93154 {544935498.py:35} INFO - going to summarize idx=2, file=data/raw/4/call_center_transcript_4_transcript.txt via cohere.command-text-v14\n",
      "[2024-01-04 18:10:13,633] p93154 {544935498.py:38} INFO - read prompt template from data/prompts/cohere_template.txt\n",
      "[2024-01-04 18:10:13,637] p93154 {544935498.py:43} INFO - prompt for data/raw/4/call_center_transcript_4_transcript.txt has 963 tokens\n",
      "[2024-01-04 18:10:13,637] p93154 {528272729.py:4} INFO - model_id=cohere.command-text-v14, prompt length is 4423 characters, 733 words\n",
      "[2024-01-04 18:10:18,458] p93154 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to further discuss options for the optimal cloud instance type to host our new product recommendation model. As a refresher on the requirements - this model will be query intensive, with thousands of customers hitting the prediction API simultaneously. And it relies on a large deep neural network for the recommendations. \\n\\nB: Yes, we should go through the pros and cons again of the main instance family options available. For standard instance types without GPUs, we'd likely need to go with a high CPU and memory specification to handle the computation and concurrency needs.\\n\\nC: Standard instances would be more cost-effective, but prediction latency would suffer without GPU acceleration. The neural network calculations could be 5-10x slower based on our initial benchmarks. For a customer-facing model, slow predictions could lead to poor user experience.\\n\\nA: That's a very good point. While GPU-powered instances would be more expensive, the business value of sub-second prediction latency for users is high. We want customers to get engaging, personalized recommendations immediately to drive conversions.\\n\\nB: I agree, I think GPU acceleration makes more sense despite the increased cloud costs. In addition to the deep learning performance boost, some of the other model parallelization and tuning optimizations we're doing would also run faster on GPUs.\\n\\nC: It seems like GPU instances are the way to go then as long as the total monthly cost is affordable. However, we may be able to optimize the specific type of GPU instance to find the best balance of throughput versus cost. \\n\\nA: Definitely, the major cloud providers offer an array of GPU instance types optimized for different use cases. We should benchmark performance against our workload with NVIDIA T4 GPUs, which are cost-optimized options, as well as some higher-end options like A100 GPUs.\\n\\nC: Do you think we should also explore using something like Elastic Inference GPU attachments? Those let you augment existing instances with fractional GPU access that is more cost-effective.\\n\\nB: Hmm good question. In theory that could work well for the cost-performance balance. We'd need to test compatibility with the types of GPU optimizations we're running in the model though...\\n</conversation>\",\n",
      "  \"completion\": \" Here are some action items for each speaker:\\n\\nA:\\n- Lead a discussion on the requirements of the product recommendation model\\n- Assess the optimal cloud instance type that can handle thousands of customers \\n- Take into account the type of model used for recommendation and its requirements \\n\\nB:\\n- Provide technical expertise on the pros and cons of different instance types without GPU support\\n- Help assess the potential latency for non-GPU instances \\n\\nC:\\n-  Provide an assessment of the potential latency of different GPU instances \\n- Lead the discussion on the different types of GPU instances and attachments offered by cloud providers \\n\\nDoes this help outline some next steps?\",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 4.820083856582642,\n",
      "  \"completion_token_count\": 148,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-04 18:10:18,458] p93154 {544935498.py:76} INFO - prompt_token_count is None for cohere.command-text-v14, setting it to 963 \n",
      "[2024-01-04 18:10:18,459] p93154 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to further discuss options for the optimal cloud instance type to host our new product recommendation model. As a refresher on the requirements - this model will be query intensive, with thousands of customers hitting the prediction API simultaneously. And it relies on a large deep neural network for the recommendations. \\n\\nB: Yes, we should go through the pros and cons again of the main instance family options available. For standard instance types without GPUs, we'd likely need to go with a high CPU and memory specification to handle the computation and concurrency needs.\\n\\nC: Standard instances would be more cost-effective, but prediction latency would suffer without GPU acceleration. The neural network calculations could be 5-10x slower based on our initial benchmarks. For a customer-facing model, slow predictions could lead to poor user experience.\\n\\nA: That's a very good point. While GPU-powered instances would be more expensive, the business value of sub-second prediction latency for users is high. We want customers to get engaging, personalized recommendations immediately to drive conversions.\\n\\nB: I agree, I think GPU acceleration makes more sense despite the increased cloud costs. In addition to the deep learning performance boost, some of the other model parallelization and tuning optimizations we're doing would also run faster on GPUs.\\n\\nC: It seems like GPU instances are the way to go then as long as the total monthly cost is affordable. However, we may be able to optimize the specific type of GPU instance to find the best balance of throughput versus cost. \\n\\nA: Definitely, the major cloud providers offer an array of GPU instance types optimized for different use cases. We should benchmark performance against our workload with NVIDIA T4 GPUs, which are cost-optimized options, as well as some higher-end options like A100 GPUs.\\n\\nC: Do you think we should also explore using something like Elastic Inference GPU attachments? Those let you augment existing instances with fractional GPU access that is more cost-effective.\\n\\nB: Hmm good question. In theory that could work well for the cost-performance balance. We'd need to test compatibility with the types of GPU optimizations we're running in the model though...\\n</conversation>\",\n",
      "  \"completion\": \"Here are some action items for each speaker:\\n\\nA:\\n- Lead a discussion on the requirements of the product recommendation model\\n- Assess the optimal cloud instance type that can handle thousands of customers \\n- Take into account the type of model used for recommendation and its requirements \\n\\nB:\\n- Provide technical expertise on the pros and cons of different instance types without GPU support\\n- Help assess the potential latency for non-GPU instances \\n\\nC:\\n-  Provide an assessment of the potential latency of different GPU instances \\n- Lead the discussion on the different types of GPU instances and attachments offered by cloud providers \\n\\nDoes this help outline some next steps?\",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 4.820083856582642,\n",
      "  \"completion_token_count\": 148,\n",
      "  \"prompt_token_count\": 963,\n",
      "  \"cost\": 0.0017405,\n",
      "  \"completion_word_count\": 111,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-04 18:10:18,460] p93154 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=anthropic_template_single_line_reason.txt, reps=3\n",
      "[2024-01-04 18:10:18,460] p93154 {544935498.py:35} INFO - going to summarize idx=2, file=data/raw/4/call_center_transcript_4_transcript.txt via anthropic.claude-instant-v1\n",
      "[2024-01-04 18:10:18,461] p93154 {544935498.py:38} INFO - read prompt template from data/prompts/anthropic_template_single_line_reason.txt\n",
      "[2024-01-04 18:10:18,463] p93154 {544935498.py:43} INFO - prompt for data/raw/4/call_center_transcript_4_transcript.txt has 950 tokens\n",
      "[2024-01-04 18:10:18,463] p93154 {528272729.py:4} INFO - model_id=anthropic.claude-instant-v1, prompt length is 4345 characters, 717 words\n",
      "[2024-01-04 18:10:21,029] p93154 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to further discuss options for the optimal cloud instance type to host our new product recommendation model. As a refresher on the requirements - this model will be query intensive, with thousands of customers hitting the prediction API simultaneously. And it relies on a large deep neural network for the recommendations. \\n\\nB: Yes, we should go through the pros and cons again of the main instance family options available. For standard instance types without GPUs, we'd likely need to go with a high CPU and memory specification to handle the computation and concurrency needs.\\n\\nC: Standard instances would be more cost-effective, but prediction latency would suffer without GPU acceleration. The neural network calculations could be 5-10x slower based on our initial benchmarks. For a customer-facing model, slow predictions could lead to poor user experience.\\n\\nA: That's a very good point. While GPU-powered instances would be more expensive, the business value of sub-second prediction latency for users is high. We want customers to get engaging, personalized recommendations immediately to drive conversions.\\n\\nB: I agree, I think GPU acceleration makes more sense despite the increased cloud costs. In addition to the deep learning performance boost, some of the other model parallelization and tuning optimizations we're doing would also run faster on GPUs.\\n\\nC: It seems like GPU instances are the way to go then as long as the total monthly cost is affordable. However, we may be able to optimize the specific type of GPU instance to find the best balance of throughput versus cost. \\n\\nA: Definitely, the major cloud providers offer an array of GPU instance types optimized for different use cases. We should benchmark performance against our workload with NVIDIA T4 GPUs, which are cost-optimized options, as well as some higher-end options like A100 GPUs.\\n\\nC: Do you think we should also explore using something like Elastic Inference GPU attachments? Those let you augment existing instances with fractional GPU access that is more cost-effective.\\n\\nB: Hmm good question. In theory that could work well for the cost-performance balance. We'd need to test compatibility with the types of GPU optimizations we're running in the model though...\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \" <output>\\nA: \\n- Benchmark performance of recommendation model against different GPU instance types from major cloud providers including NVIDIA T4 and A100 GPUs\\n- Consider exploring Elastic Inference GPU attachments and test compatibility with model optimizations\\n\\nB: \\n- Help benchmark performance against different GPU instance types\\n- Consider exploring Elastic Inference GPU attachments and provide input on compatibility with model optimizations\\n\\nC: \\n- Consider exploring Elastic Inference GPU attachments as an alternative to full GPU instances for cost-performance balance  \\n- Help benchmark performance against different GPU instance types\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 2.5648391246795654,\n",
      "  \"completion_token_count\": 122,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-04 18:10:21,029] p93154 {544935498.py:76} INFO - prompt_token_count is None for anthropic.claude-instant-v1, setting it to 950 \n",
      "[2024-01-04 18:10:21,030] p93154 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to further discuss options for the optimal cloud instance type to host our new product recommendation model. As a refresher on the requirements - this model will be query intensive, with thousands of customers hitting the prediction API simultaneously. And it relies on a large deep neural network for the recommendations. \\n\\nB: Yes, we should go through the pros and cons again of the main instance family options available. For standard instance types without GPUs, we'd likely need to go with a high CPU and memory specification to handle the computation and concurrency needs.\\n\\nC: Standard instances would be more cost-effective, but prediction latency would suffer without GPU acceleration. The neural network calculations could be 5-10x slower based on our initial benchmarks. For a customer-facing model, slow predictions could lead to poor user experience.\\n\\nA: That's a very good point. While GPU-powered instances would be more expensive, the business value of sub-second prediction latency for users is high. We want customers to get engaging, personalized recommendations immediately to drive conversions.\\n\\nB: I agree, I think GPU acceleration makes more sense despite the increased cloud costs. In addition to the deep learning performance boost, some of the other model parallelization and tuning optimizations we're doing would also run faster on GPUs.\\n\\nC: It seems like GPU instances are the way to go then as long as the total monthly cost is affordable. However, we may be able to optimize the specific type of GPU instance to find the best balance of throughput versus cost. \\n\\nA: Definitely, the major cloud providers offer an array of GPU instance types optimized for different use cases. We should benchmark performance against our workload with NVIDIA T4 GPUs, which are cost-optimized options, as well as some higher-end options like A100 GPUs.\\n\\nC: Do you think we should also explore using something like Elastic Inference GPU attachments? Those let you augment existing instances with fractional GPU access that is more cost-effective.\\n\\nB: Hmm good question. In theory that could work well for the cost-performance balance. We'd need to test compatibility with the types of GPU optimizations we're running in the model though...\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \"<output>\\nA: \\n- Benchmark performance of recommendation model against different GPU instance types from major cloud providers including NVIDIA T4 and A100 GPUs\\n- Consider exploring Elastic Inference GPU attachments and test compatibility with model optimizations\\n\\nB: \\n- Help benchmark performance against different GPU instance types\\n- Consider exploring Elastic Inference GPU attachments and provide input on compatibility with model optimizations\\n\\nC: \\n- Consider exploring Elastic Inference GPU attachments as an alternative to full GPU instances for cost-performance balance  \\n- Help benchmark performance against different GPU instance types\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 2.5648391246795654,\n",
      "  \"completion_token_count\": 122,\n",
      "  \"prompt_token_count\": 950,\n",
      "  \"cost\": 0.00222072,\n",
      "  \"completion_word_count\": 89,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-04 18:10:21,032] p93154 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=titan_template.txt, reps=3\n",
      "[2024-01-04 18:10:21,032] p93154 {544935498.py:35} INFO - going to summarize idx=2, file=data/raw/4/call_center_transcript_4_transcript.txt via amazon.titan-text-express-v1\n",
      "[2024-01-04 18:10:21,033] p93154 {544935498.py:38} INFO - read prompt template from data/prompts/titan_template.txt\n",
      "[2024-01-04 18:10:21,035] p93154 {544935498.py:43} INFO - prompt for data/raw/4/call_center_transcript_4_transcript.txt has 968 tokens\n",
      "[2024-01-04 18:10:21,036] p93154 {528272729.py:4} INFO - model_id=amazon.titan-text-express-v1, prompt length is 4428 characters, 734 words\n",
      "[2024-01-04 18:10:29,958] p93154 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nA: I wanted to further discuss options for the optimal cloud instance type to host our new product recommendation model. As a refresher on the requirements - this model will be query intensive, with thousands of customers hitting the prediction API simultaneously. And it relies on a large deep neural network for the recommendations. \\n\\nB: Yes, we should go through the pros and cons again of the main instance family options available. For standard instance types without GPUs, we'd likely need to go with a high CPU and memory specification to handle the computation and concurrency needs.\\n\\nC: Standard instances would be more cost-effective, but prediction latency would suffer without GPU acceleration. The neural network calculations could be 5-10x slower based on our initial benchmarks. For a customer-facing model, slow predictions could lead to poor user experience.\\n\\nA: That's a very good point. While GPU-powered instances would be more expensive, the business value of sub-second prediction latency for users is high. We want customers to get engaging, personalized recommendations immediately to drive conversions.\\n\\nB: I agree, I think GPU acceleration makes more sense despite the increased cloud costs. In addition to the deep learning performance boost, some of the other model parallelization and tuning optimizations we're doing would also run faster on GPUs.\\n\\nC: It seems like GPU instances are the way to go then as long as the total monthly cost is affordable. However, we may be able to optimize the specific type of GPU instance to find the best balance of throughput versus cost. \\n\\nA: Definitely, the major cloud providers offer an array of GPU instance types optimized for different use cases. We should benchmark performance against our workload with NVIDIA T4 GPUs, which are cost-optimized options, as well as some higher-end options like A100 GPUs.\\n\\nC: Do you think we should also explore using something like Elastic Inference GPU attachments? Those let you augment existing instances with fractional GPU access that is more cost-effective.\\n\\nB: Hmm good question. In theory that could work well for the cost-performance balance. We'd need to test compatibility with the types of GPU optimizations we're running in the model though...\\n</conversation>\",\n",
      "  \"completion\": \"\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Evaluate the cost-performance balance of different GPU instance types (NVIDIA T4, A100, etc.) for hosting the new product recommendation model\\n- Benchmark performance against the workload with NVIDIA T4 GPUs and higher-end options\\n- Explore using Elastic Inference GPU attachments for cost-effective GPU access\\n- Determine compatibility with the model's GPU optimizations\\n\\nB:\\n- Research and evaluate the cost-effectiveness of GPU-powered instances for the specific workload\\n- Collaborate with the data science team to optimize the model for GPU acceleration\\n- Consider using Elastic Inference GPU attachments if they are compatible with the model's optimizations\\n- Provide recommendations to the leadership team on the optimal cloud instance type for hosting the product recommendation model\\n\\nC:\\n- Collaborate with the data science team to identify the specific type of GPU instance that would provide the best balance of throughput and cost for the product recommendation model\\n- Benchmark performance of different GPU instance types with the model's workload\\n- Provide recommendations to the leadership team on the optimal GPU instance type and cost-saving strategies\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 8.921688795089722,\n",
      "  \"completion_token_count\": 251,\n",
      "  \"prompt_token_count\": 976\n",
      "}\n",
      "[2024-01-04 18:10:29,960] p93154 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nA: I wanted to further discuss options for the optimal cloud instance type to host our new product recommendation model. As a refresher on the requirements - this model will be query intensive, with thousands of customers hitting the prediction API simultaneously. And it relies on a large deep neural network for the recommendations. \\n\\nB: Yes, we should go through the pros and cons again of the main instance family options available. For standard instance types without GPUs, we'd likely need to go with a high CPU and memory specification to handle the computation and concurrency needs.\\n\\nC: Standard instances would be more cost-effective, but prediction latency would suffer without GPU acceleration. The neural network calculations could be 5-10x slower based on our initial benchmarks. For a customer-facing model, slow predictions could lead to poor user experience.\\n\\nA: That's a very good point. While GPU-powered instances would be more expensive, the business value of sub-second prediction latency for users is high. We want customers to get engaging, personalized recommendations immediately to drive conversions.\\n\\nB: I agree, I think GPU acceleration makes more sense despite the increased cloud costs. In addition to the deep learning performance boost, some of the other model parallelization and tuning optimizations we're doing would also run faster on GPUs.\\n\\nC: It seems like GPU instances are the way to go then as long as the total monthly cost is affordable. However, we may be able to optimize the specific type of GPU instance to find the best balance of throughput versus cost. \\n\\nA: Definitely, the major cloud providers offer an array of GPU instance types optimized for different use cases. We should benchmark performance against our workload with NVIDIA T4 GPUs, which are cost-optimized options, as well as some higher-end options like A100 GPUs.\\n\\nC: Do you think we should also explore using something like Elastic Inference GPU attachments? Those let you augment existing instances with fractional GPU access that is more cost-effective.\\n\\nB: Hmm good question. In theory that could work well for the cost-performance balance. We'd need to test compatibility with the types of GPU optimizations we're running in the model though...\\n</conversation>\",\n",
      "  \"completion\": \"<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Evaluate the cost-performance balance of different GPU instance types (NVIDIA T4, A100, etc.) for hosting the new product recommendation model\\n- Benchmark performance against the workload with NVIDIA T4 GPUs and higher-end options\\n- Explore using Elastic Inference GPU attachments for cost-effective GPU access\\n- Determine compatibility with the model's GPU optimizations\\n\\nB:\\n- Research and evaluate the cost-effectiveness of GPU-powered instances for the specific workload\\n- Collaborate with the data science team to optimize the model for GPU acceleration\\n- Consider using Elastic Inference GPU attachments if they are compatible with the model's optimizations\\n- Provide recommendations to the leadership team on the optimal cloud instance type for hosting the product recommendation model\\n\\nC:\\n- Collaborate with the data science team to identify the specific type of GPU instance that would provide the best balance of throughput and cost for the product recommendation model\\n- Benchmark performance of different GPU instance types with the model's workload\\n- Provide recommendations to the leadership team on the optimal GPU instance type and cost-saving strategies\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 8.921688795089722,\n",
      "  \"completion_token_count\": 251,\n",
      "  \"prompt_token_count\": 976,\n",
      "  \"cost\": 0.0011824000000000001,\n",
      "  \"completion_word_count\": 187,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-04 18:10:29,962] p93154 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=cohere_template.txt, reps=3\n",
      "[2024-01-04 18:10:29,962] p93154 {544935498.py:35} INFO - going to summarize idx=2, file=data/raw/4/call_center_transcript_4_transcript.txt via cohere.command-text-v14\n",
      "[2024-01-04 18:10:29,964] p93154 {544935498.py:38} INFO - read prompt template from data/prompts/cohere_template.txt\n",
      "[2024-01-04 18:10:29,969] p93154 {544935498.py:43} INFO - prompt for data/raw/4/call_center_transcript_4_transcript.txt has 963 tokens\n",
      "[2024-01-04 18:10:29,970] p93154 {528272729.py:4} INFO - model_id=cohere.command-text-v14, prompt length is 4423 characters, 733 words\n",
      "[2024-01-04 18:10:35,472] p93154 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to further discuss options for the optimal cloud instance type to host our new product recommendation model. As a refresher on the requirements - this model will be query intensive, with thousands of customers hitting the prediction API simultaneously. And it relies on a large deep neural network for the recommendations. \\n\\nB: Yes, we should go through the pros and cons again of the main instance family options available. For standard instance types without GPUs, we'd likely need to go with a high CPU and memory specification to handle the computation and concurrency needs.\\n\\nC: Standard instances would be more cost-effective, but prediction latency would suffer without GPU acceleration. The neural network calculations could be 5-10x slower based on our initial benchmarks. For a customer-facing model, slow predictions could lead to poor user experience.\\n\\nA: That's a very good point. While GPU-powered instances would be more expensive, the business value of sub-second prediction latency for users is high. We want customers to get engaging, personalized recommendations immediately to drive conversions.\\n\\nB: I agree, I think GPU acceleration makes more sense despite the increased cloud costs. In addition to the deep learning performance boost, some of the other model parallelization and tuning optimizations we're doing would also run faster on GPUs.\\n\\nC: It seems like GPU instances are the way to go then as long as the total monthly cost is affordable. However, we may be able to optimize the specific type of GPU instance to find the best balance of throughput versus cost. \\n\\nA: Definitely, the major cloud providers offer an array of GPU instance types optimized for different use cases. We should benchmark performance against our workload with NVIDIA T4 GPUs, which are cost-optimized options, as well as some higher-end options like A100 GPUs.\\n\\nC: Do you think we should also explore using something like Elastic Inference GPU attachments? Those let you augment existing instances with fractional GPU access that is more cost-effective.\\n\\nB: Hmm good question. In theory that could work well for the cost-performance balance. We'd need to test compatibility with the types of GPU optimizations we're running in the model though...\\n</conversation>\",\n",
      "  \"completion\": \" Here are some action items for each speaker:\\n\\nA:\\n- Lead a discussion on requirements and options for the optimal cloud instance type for the new product recommendation model\\n- Highlight the need for a high CPU and memory specification to handle the computation and concurrency needs without GPU acceleration\\n\\nB:\\n- Provide technical expertise on the pros and cons of different instance family options available\\n- Confirm the potential latency implications of standard instances without GPU acceleration\\n\\nC:\\n- Highlight the potential for slower neural network calculations with standard instances \\n- Raise concerns about the potential for slower model optimizations on standard instances \\n\\nDoes this help outline some key action items for each speaker? Let me know if you would like me to clarify or expand on any of the items. \",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 5.501116037368774,\n",
      "  \"completion_token_count\": 176,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-04 18:10:35,473] p93154 {544935498.py:76} INFO - prompt_token_count is None for cohere.command-text-v14, setting it to 963 \n",
      "[2024-01-04 18:10:35,476] p93154 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to further discuss options for the optimal cloud instance type to host our new product recommendation model. As a refresher on the requirements - this model will be query intensive, with thousands of customers hitting the prediction API simultaneously. And it relies on a large deep neural network for the recommendations. \\n\\nB: Yes, we should go through the pros and cons again of the main instance family options available. For standard instance types without GPUs, we'd likely need to go with a high CPU and memory specification to handle the computation and concurrency needs.\\n\\nC: Standard instances would be more cost-effective, but prediction latency would suffer without GPU acceleration. The neural network calculations could be 5-10x slower based on our initial benchmarks. For a customer-facing model, slow predictions could lead to poor user experience.\\n\\nA: That's a very good point. While GPU-powered instances would be more expensive, the business value of sub-second prediction latency for users is high. We want customers to get engaging, personalized recommendations immediately to drive conversions.\\n\\nB: I agree, I think GPU acceleration makes more sense despite the increased cloud costs. In addition to the deep learning performance boost, some of the other model parallelization and tuning optimizations we're doing would also run faster on GPUs.\\n\\nC: It seems like GPU instances are the way to go then as long as the total monthly cost is affordable. However, we may be able to optimize the specific type of GPU instance to find the best balance of throughput versus cost. \\n\\nA: Definitely, the major cloud providers offer an array of GPU instance types optimized for different use cases. We should benchmark performance against our workload with NVIDIA T4 GPUs, which are cost-optimized options, as well as some higher-end options like A100 GPUs.\\n\\nC: Do you think we should also explore using something like Elastic Inference GPU attachments? Those let you augment existing instances with fractional GPU access that is more cost-effective.\\n\\nB: Hmm good question. In theory that could work well for the cost-performance balance. We'd need to test compatibility with the types of GPU optimizations we're running in the model though...\\n</conversation>\",\n",
      "  \"completion\": \"Here are some action items for each speaker:\\n\\nA:\\n- Lead a discussion on requirements and options for the optimal cloud instance type for the new product recommendation model\\n- Highlight the need for a high CPU and memory specification to handle the computation and concurrency needs without GPU acceleration\\n\\nB:\\n- Provide technical expertise on the pros and cons of different instance family options available\\n- Confirm the potential latency implications of standard instances without GPU acceleration\\n\\nC:\\n- Highlight the potential for slower neural network calculations with standard instances \\n- Raise concerns about the potential for slower model optimizations on standard instances \\n\\nDoes this help outline some key action items for each speaker? Let me know if you would like me to clarify or expand on any of the items.\",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 5.501116037368774,\n",
      "  \"completion_token_count\": 176,\n",
      "  \"prompt_token_count\": 963,\n",
      "  \"cost\": 0.0017965,\n",
      "  \"completion_word_count\": 132,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-04 18:10:35,481] p93154 {544935498.py:19} INFO - idx=3, tf=data/raw/3/call_center_transcript_3_transcript.txt, file_id=call_center_transcript_3, golden_summary_fpath=data/raw/0/example_prompt_transcript_golden_summary.txt\n",
      "[2024-01-04 18:10:35,483] p93154 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=anthropic_template_single_line_reason.txt, reps=3\n",
      "[2024-01-04 18:10:35,485] p93154 {544935498.py:35} INFO - going to summarize idx=3, file=data/raw/3/call_center_transcript_3_transcript.txt via anthropic.claude-instant-v1\n",
      "[2024-01-04 18:10:35,488] p93154 {544935498.py:38} INFO - read prompt template from data/prompts/anthropic_template_single_line_reason.txt\n",
      "[2024-01-04 18:10:35,500] p93154 {544935498.py:43} INFO - prompt for data/raw/3/call_center_transcript_3_transcript.txt has 880 tokens\n",
      "[2024-01-04 18:10:35,501] p93154 {528272729.py:4} INFO - model_id=anthropic.claude-instant-v1, prompt length is 3937 characters, 663 words\n",
      "[2024-01-04 18:10:37,068] p93154 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to have a broader discussion on responsible AI development principles. As we build more AI models, how do we ensure they are helpful, harmless, and aligned with human values?\\n\\nB: This is an important topic. We need to make ethical considerations a priority from the beginning of any AI project, not an afterthought. I think we should develop a review process focused on safety for all new models. \\n\\nAction item: Draft a proposal for an AI model safety review framework \\n\\nC: I agree. We should analyze potential risks like data bias and misuse upfront. Models also need to be secure - what if they were hacked?\\n\\nAction item: Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA: Valid points. Besides analyzing risks, we also need to ensure the objectives we give AI align with human values more broadly. Like being helpful to users, not just maximizing some narrow metric. \\n\\nAction item: Explore methodologies for value alignment in AI systems\\n\\nB: The objectives point connects to transparency too. Any AI decisions that impact users should be explainable. If we can't understand why an AI did something, we can't verify it's aligned.  \\n\\nAction item: Research existing XAI (explainable AI) techniques to augment our models\\n\\nC: Adding explainability makes sense. We should also discuss how to carefully test models before launch to catch additional issues. And have a plan to monitor their impacts over time.\\n\\nAction item: Develop testing and monitoring standards for AI models based on industry best practices\\n\\nA: Great suggestions all around. It seems like we have a blueprint to make responsibility, safety and ethics central to our AI efforts here. I'm optimistic if we build these considerations in from the start, we can drive real progress. Does anyone have any other thoughts before we break?\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \" <output>\\nA: \\n- No explicit action items stated\\n\\nB:  \\n- Draft a proposal for an AI model safety review framework\\n\\nC:\\n- Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA:  \\n- Explore methodologies for value alignment in AI systems \\n\\nB:\\n- Research existing XAI (explainable AI) techniques to augment our models\\n\\nC:\\n- Develop testing and monitoring standards for AI models based on industry best practices\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 1.5647940635681152,\n",
      "  \"completion_token_count\": 113,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-04 18:10:37,068] p93154 {544935498.py:76} INFO - prompt_token_count is None for anthropic.claude-instant-v1, setting it to 880 \n",
      "[2024-01-04 18:10:37,071] p93154 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to have a broader discussion on responsible AI development principles. As we build more AI models, how do we ensure they are helpful, harmless, and aligned with human values?\\n\\nB: This is an important topic. We need to make ethical considerations a priority from the beginning of any AI project, not an afterthought. I think we should develop a review process focused on safety for all new models. \\n\\nAction item: Draft a proposal for an AI model safety review framework \\n\\nC: I agree. We should analyze potential risks like data bias and misuse upfront. Models also need to be secure - what if they were hacked?\\n\\nAction item: Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA: Valid points. Besides analyzing risks, we also need to ensure the objectives we give AI align with human values more broadly. Like being helpful to users, not just maximizing some narrow metric. \\n\\nAction item: Explore methodologies for value alignment in AI systems\\n\\nB: The objectives point connects to transparency too. Any AI decisions that impact users should be explainable. If we can't understand why an AI did something, we can't verify it's aligned.  \\n\\nAction item: Research existing XAI (explainable AI) techniques to augment our models\\n\\nC: Adding explainability makes sense. We should also discuss how to carefully test models before launch to catch additional issues. And have a plan to monitor their impacts over time.\\n\\nAction item: Develop testing and monitoring standards for AI models based on industry best practices\\n\\nA: Great suggestions all around. It seems like we have a blueprint to make responsibility, safety and ethics central to our AI efforts here. I'm optimistic if we build these considerations in from the start, we can drive real progress. Does anyone have any other thoughts before we break?\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \"<output>\\nA: \\n- No explicit action items stated\\n\\nB:  \\n- Draft a proposal for an AI model safety review framework\\n\\nC:\\n- Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA:  \\n- Explore methodologies for value alignment in AI systems \\n\\nB:\\n- Research existing XAI (explainable AI) techniques to augment our models\\n\\nC:\\n- Develop testing and monitoring standards for AI models based on industry best practices\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 1.5647940635681152,\n",
      "  \"completion_token_count\": 113,\n",
      "  \"prompt_token_count\": 880,\n",
      "  \"cost\": 0.00205703,\n",
      "  \"completion_word_count\": 73,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-04 18:10:37,072] p93154 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=titan_template.txt, reps=3\n",
      "[2024-01-04 18:10:37,073] p93154 {544935498.py:35} INFO - going to summarize idx=3, file=data/raw/3/call_center_transcript_3_transcript.txt via amazon.titan-text-express-v1\n",
      "[2024-01-04 18:10:37,074] p93154 {544935498.py:38} INFO - read prompt template from data/prompts/titan_template.txt\n",
      "[2024-01-04 18:10:37,079] p93154 {544935498.py:43} INFO - prompt for data/raw/3/call_center_transcript_3_transcript.txt has 898 tokens\n",
      "[2024-01-04 18:10:37,079] p93154 {528272729.py:4} INFO - model_id=amazon.titan-text-express-v1, prompt length is 4020 characters, 680 words\n",
      "[2024-01-04 18:10:41,533] p93154 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nA: I wanted to have a broader discussion on responsible AI development principles. As we build more AI models, how do we ensure they are helpful, harmless, and aligned with human values?\\n\\nB: This is an important topic. We need to make ethical considerations a priority from the beginning of any AI project, not an afterthought. I think we should develop a review process focused on safety for all new models. \\n\\nAction item: Draft a proposal for an AI model safety review framework \\n\\nC: I agree. We should analyze potential risks like data bias and misuse upfront. Models also need to be secure - what if they were hacked?\\n\\nAction item: Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA: Valid points. Besides analyzing risks, we also need to ensure the objectives we give AI align with human values more broadly. Like being helpful to users, not just maximizing some narrow metric. \\n\\nAction item: Explore methodologies for value alignment in AI systems\\n\\nB: The objectives point connects to transparency too. Any AI decisions that impact users should be explainable. If we can't understand why an AI did something, we can't verify it's aligned.  \\n\\nAction item: Research existing XAI (explainable AI) techniques to augment our models\\n\\nC: Adding explainability makes sense. We should also discuss how to carefully test models before launch to catch additional issues. And have a plan to monitor their impacts over time.\\n\\nAction item: Develop testing and monitoring standards for AI models based on industry best practices\\n\\nA: Great suggestions all around. It seems like we have a blueprint to make responsibility, safety and ethics central to our AI efforts here. I'm optimistic if we build these considerations in from the start, we can drive real progress. Does anyone have any other thoughts before we break?\\n</conversation>\",\n",
      "  \"completion\": \"\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Draft a proposal for an AI model safety review framework\\n- Explore methodologies for value alignment in AI systems\\n\\nB:\\n- Outline additional potential safety risks to address such as data/algorithm bias and security\\n- Research existing XAI (explainable AI) techniques to augment our models\\n- Develop testing and monitoring standards for AI models based on industry best practices\\n\\nC:\\n- Add explainability to AI models\\n- Discuss how to carefully test models before launch to catch additional issues\\n- Have a plan to monitor their impacts over time\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 4.453336000442505,\n",
      "  \"completion_token_count\": 138,\n",
      "  \"prompt_token_count\": 901\n",
      "}\n",
      "[2024-01-04 18:10:41,537] p93154 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nA: I wanted to have a broader discussion on responsible AI development principles. As we build more AI models, how do we ensure they are helpful, harmless, and aligned with human values?\\n\\nB: This is an important topic. We need to make ethical considerations a priority from the beginning of any AI project, not an afterthought. I think we should develop a review process focused on safety for all new models. \\n\\nAction item: Draft a proposal for an AI model safety review framework \\n\\nC: I agree. We should analyze potential risks like data bias and misuse upfront. Models also need to be secure - what if they were hacked?\\n\\nAction item: Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA: Valid points. Besides analyzing risks, we also need to ensure the objectives we give AI align with human values more broadly. Like being helpful to users, not just maximizing some narrow metric. \\n\\nAction item: Explore methodologies for value alignment in AI systems\\n\\nB: The objectives point connects to transparency too. Any AI decisions that impact users should be explainable. If we can't understand why an AI did something, we can't verify it's aligned.  \\n\\nAction item: Research existing XAI (explainable AI) techniques to augment our models\\n\\nC: Adding explainability makes sense. We should also discuss how to carefully test models before launch to catch additional issues. And have a plan to monitor their impacts over time.\\n\\nAction item: Develop testing and monitoring standards for AI models based on industry best practices\\n\\nA: Great suggestions all around. It seems like we have a blueprint to make responsibility, safety and ethics central to our AI efforts here. I'm optimistic if we build these considerations in from the start, we can drive real progress. Does anyone have any other thoughts before we break?\\n</conversation>\",\n",
      "  \"completion\": \"<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Draft a proposal for an AI model safety review framework\\n- Explore methodologies for value alignment in AI systems\\n\\nB:\\n- Outline additional potential safety risks to address such as data/algorithm bias and security\\n- Research existing XAI (explainable AI) techniques to augment our models\\n- Develop testing and monitoring standards for AI models based on industry best practices\\n\\nC:\\n- Add explainability to AI models\\n- Discuss how to carefully test models before launch to catch additional issues\\n- Have a plan to monitor their impacts over time\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 4.453336000442505,\n",
      "  \"completion_token_count\": 138,\n",
      "  \"prompt_token_count\": 901,\n",
      "  \"cost\": 0.0009416000000000001,\n",
      "  \"completion_word_count\": 103,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-04 18:10:41,539] p93154 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=cohere_template.txt, reps=3\n",
      "[2024-01-04 18:10:41,539] p93154 {544935498.py:35} INFO - going to summarize idx=3, file=data/raw/3/call_center_transcript_3_transcript.txt via cohere.command-text-v14\n",
      "[2024-01-04 18:10:41,541] p93154 {544935498.py:38} INFO - read prompt template from data/prompts/cohere_template.txt\n",
      "[2024-01-04 18:10:41,546] p93154 {544935498.py:43} INFO - prompt for data/raw/3/call_center_transcript_3_transcript.txt has 893 tokens\n",
      "[2024-01-04 18:10:41,548] p93154 {528272729.py:4} INFO - model_id=cohere.command-text-v14, prompt length is 4015 characters, 679 words\n",
      "[2024-01-04 18:10:45,766] p93154 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to have a broader discussion on responsible AI development principles. As we build more AI models, how do we ensure they are helpful, harmless, and aligned with human values?\\n\\nB: This is an important topic. We need to make ethical considerations a priority from the beginning of any AI project, not an afterthought. I think we should develop a review process focused on safety for all new models. \\n\\nAction item: Draft a proposal for an AI model safety review framework \\n\\nC: I agree. We should analyze potential risks like data bias and misuse upfront. Models also need to be secure - what if they were hacked?\\n\\nAction item: Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA: Valid points. Besides analyzing risks, we also need to ensure the objectives we give AI align with human values more broadly. Like being helpful to users, not just maximizing some narrow metric. \\n\\nAction item: Explore methodologies for value alignment in AI systems\\n\\nB: The objectives point connects to transparency too. Any AI decisions that impact users should be explainable. If we can't understand why an AI did something, we can't verify it's aligned.  \\n\\nAction item: Research existing XAI (explainable AI) techniques to augment our models\\n\\nC: Adding explainability makes sense. We should also discuss how to carefully test models before launch to catch additional issues. And have a plan to monitor their impacts over time.\\n\\nAction item: Develop testing and monitoring standards for AI models based on industry best practices\\n\\nA: Great suggestions all around. It seems like we have a blueprint to make responsibility, safety and ethics central to our AI efforts here. I'm optimistic if we build these considerations in from the start, we can drive real progress. Does anyone have any other thoughts before we break?\\n</conversation>\",\n",
      "  \"completion\": \" <output>\\nA: \\n- Draft a proposal for an AI model safety review framework \\n- Explore methodologies for value alignment in AI systems \\n\\nB: \\n- None\\n\\nC:\\n- Outline additional safety risks \\n- Discuss how to carefully test models before launch and monitor their impacts over time \\n- Implement testing and monitoring standards for AI based on industry best practices \\n\\n</output>\\n\\nI hope these action items help ensure that the key topics and next steps from your meeting are actionable! Do you need help with anything else? \",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 4.217932224273682,\n",
      "  \"completion_token_count\": 114,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-04 18:10:45,767] p93154 {544935498.py:76} INFO - prompt_token_count is None for cohere.command-text-v14, setting it to 893 \n",
      "[2024-01-04 18:10:45,769] p93154 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to have a broader discussion on responsible AI development principles. As we build more AI models, how do we ensure they are helpful, harmless, and aligned with human values?\\n\\nB: This is an important topic. We need to make ethical considerations a priority from the beginning of any AI project, not an afterthought. I think we should develop a review process focused on safety for all new models. \\n\\nAction item: Draft a proposal for an AI model safety review framework \\n\\nC: I agree. We should analyze potential risks like data bias and misuse upfront. Models also need to be secure - what if they were hacked?\\n\\nAction item: Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA: Valid points. Besides analyzing risks, we also need to ensure the objectives we give AI align with human values more broadly. Like being helpful to users, not just maximizing some narrow metric. \\n\\nAction item: Explore methodologies for value alignment in AI systems\\n\\nB: The objectives point connects to transparency too. Any AI decisions that impact users should be explainable. If we can't understand why an AI did something, we can't verify it's aligned.  \\n\\nAction item: Research existing XAI (explainable AI) techniques to augment our models\\n\\nC: Adding explainability makes sense. We should also discuss how to carefully test models before launch to catch additional issues. And have a plan to monitor their impacts over time.\\n\\nAction item: Develop testing and monitoring standards for AI models based on industry best practices\\n\\nA: Great suggestions all around. It seems like we have a blueprint to make responsibility, safety and ethics central to our AI efforts here. I'm optimistic if we build these considerations in from the start, we can drive real progress. Does anyone have any other thoughts before we break?\\n</conversation>\",\n",
      "  \"completion\": \"<output>\\nA: \\n- Draft a proposal for an AI model safety review framework \\n- Explore methodologies for value alignment in AI systems \\n\\nB: \\n- None\\n\\nC:\\n- Outline additional safety risks \\n- Discuss how to carefully test models before launch and monitor their impacts over time \\n- Implement testing and monitoring standards for AI based on industry best practices \\n\\n</output>\\n\\nI hope these action items help ensure that the key topics and next steps from your meeting are actionable! Do you need help with anything else?\",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 4.217932224273682,\n",
      "  \"completion_token_count\": 114,\n",
      "  \"prompt_token_count\": 893,\n",
      "  \"cost\": 0.0015674999999999999,\n",
      "  \"completion_word_count\": 86,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-04 18:10:45,772] p93154 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=anthropic_template_single_line_reason.txt, reps=3\n",
      "[2024-01-04 18:10:45,773] p93154 {544935498.py:35} INFO - going to summarize idx=3, file=data/raw/3/call_center_transcript_3_transcript.txt via anthropic.claude-instant-v1\n",
      "[2024-01-04 18:10:45,775] p93154 {544935498.py:38} INFO - read prompt template from data/prompts/anthropic_template_single_line_reason.txt\n",
      "[2024-01-04 18:10:45,781] p93154 {544935498.py:43} INFO - prompt for data/raw/3/call_center_transcript_3_transcript.txt has 880 tokens\n",
      "[2024-01-04 18:10:45,783] p93154 {528272729.py:4} INFO - model_id=anthropic.claude-instant-v1, prompt length is 3937 characters, 663 words\n",
      "[2024-01-04 18:10:47,149] p93154 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to have a broader discussion on responsible AI development principles. As we build more AI models, how do we ensure they are helpful, harmless, and aligned with human values?\\n\\nB: This is an important topic. We need to make ethical considerations a priority from the beginning of any AI project, not an afterthought. I think we should develop a review process focused on safety for all new models. \\n\\nAction item: Draft a proposal for an AI model safety review framework \\n\\nC: I agree. We should analyze potential risks like data bias and misuse upfront. Models also need to be secure - what if they were hacked?\\n\\nAction item: Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA: Valid points. Besides analyzing risks, we also need to ensure the objectives we give AI align with human values more broadly. Like being helpful to users, not just maximizing some narrow metric. \\n\\nAction item: Explore methodologies for value alignment in AI systems\\n\\nB: The objectives point connects to transparency too. Any AI decisions that impact users should be explainable. If we can't understand why an AI did something, we can't verify it's aligned.  \\n\\nAction item: Research existing XAI (explainable AI) techniques to augment our models\\n\\nC: Adding explainability makes sense. We should also discuss how to carefully test models before launch to catch additional issues. And have a plan to monitor their impacts over time.\\n\\nAction item: Develop testing and monitoring standards for AI models based on industry best practices\\n\\nA: Great suggestions all around. It seems like we have a blueprint to make responsibility, safety and ethics central to our AI efforts here. I'm optimistic if we build these considerations in from the start, we can drive real progress. Does anyone have any other thoughts before we break?\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \" <output>\\nA: \\n- No explicit action items stated\\n\\nB:  \\n- Draft a proposal for an AI model safety review framework\\n\\nC:\\n- Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA:  \\n- Explore methodologies for value alignment in AI systems \\n\\nB:\\n- Research existing XAI (explainable AI) techniques to augment our models\\n\\nC:\\n- Develop testing and monitoring standards for AI models based on industry best practices\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 1.3635687828063965,\n",
      "  \"completion_token_count\": 113,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-04 18:10:47,149] p93154 {544935498.py:76} INFO - prompt_token_count is None for anthropic.claude-instant-v1, setting it to 880 \n",
      "[2024-01-04 18:10:47,151] p93154 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to have a broader discussion on responsible AI development principles. As we build more AI models, how do we ensure they are helpful, harmless, and aligned with human values?\\n\\nB: This is an important topic. We need to make ethical considerations a priority from the beginning of any AI project, not an afterthought. I think we should develop a review process focused on safety for all new models. \\n\\nAction item: Draft a proposal for an AI model safety review framework \\n\\nC: I agree. We should analyze potential risks like data bias and misuse upfront. Models also need to be secure - what if they were hacked?\\n\\nAction item: Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA: Valid points. Besides analyzing risks, we also need to ensure the objectives we give AI align with human values more broadly. Like being helpful to users, not just maximizing some narrow metric. \\n\\nAction item: Explore methodologies for value alignment in AI systems\\n\\nB: The objectives point connects to transparency too. Any AI decisions that impact users should be explainable. If we can't understand why an AI did something, we can't verify it's aligned.  \\n\\nAction item: Research existing XAI (explainable AI) techniques to augment our models\\n\\nC: Adding explainability makes sense. We should also discuss how to carefully test models before launch to catch additional issues. And have a plan to monitor their impacts over time.\\n\\nAction item: Develop testing and monitoring standards for AI models based on industry best practices\\n\\nA: Great suggestions all around. It seems like we have a blueprint to make responsibility, safety and ethics central to our AI efforts here. I'm optimistic if we build these considerations in from the start, we can drive real progress. Does anyone have any other thoughts before we break?\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \"<output>\\nA: \\n- No explicit action items stated\\n\\nB:  \\n- Draft a proposal for an AI model safety review framework\\n\\nC:\\n- Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA:  \\n- Explore methodologies for value alignment in AI systems \\n\\nB:\\n- Research existing XAI (explainable AI) techniques to augment our models\\n\\nC:\\n- Develop testing and monitoring standards for AI models based on industry best practices\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 1.3635687828063965,\n",
      "  \"completion_token_count\": 113,\n",
      "  \"prompt_token_count\": 880,\n",
      "  \"cost\": 0.00205703,\n",
      "  \"completion_word_count\": 73,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-04 18:10:47,153] p93154 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=titan_template.txt, reps=3\n",
      "[2024-01-04 18:10:47,154] p93154 {544935498.py:35} INFO - going to summarize idx=3, file=data/raw/3/call_center_transcript_3_transcript.txt via amazon.titan-text-express-v1\n",
      "[2024-01-04 18:10:47,155] p93154 {544935498.py:38} INFO - read prompt template from data/prompts/titan_template.txt\n",
      "[2024-01-04 18:10:47,160] p93154 {544935498.py:43} INFO - prompt for data/raw/3/call_center_transcript_3_transcript.txt has 898 tokens\n",
      "[2024-01-04 18:10:47,161] p93154 {528272729.py:4} INFO - model_id=amazon.titan-text-express-v1, prompt length is 4020 characters, 680 words\n",
      "[2024-01-04 18:10:51,582] p93154 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nA: I wanted to have a broader discussion on responsible AI development principles. As we build more AI models, how do we ensure they are helpful, harmless, and aligned with human values?\\n\\nB: This is an important topic. We need to make ethical considerations a priority from the beginning of any AI project, not an afterthought. I think we should develop a review process focused on safety for all new models. \\n\\nAction item: Draft a proposal for an AI model safety review framework \\n\\nC: I agree. We should analyze potential risks like data bias and misuse upfront. Models also need to be secure - what if they were hacked?\\n\\nAction item: Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA: Valid points. Besides analyzing risks, we also need to ensure the objectives we give AI align with human values more broadly. Like being helpful to users, not just maximizing some narrow metric. \\n\\nAction item: Explore methodologies for value alignment in AI systems\\n\\nB: The objectives point connects to transparency too. Any AI decisions that impact users should be explainable. If we can't understand why an AI did something, we can't verify it's aligned.  \\n\\nAction item: Research existing XAI (explainable AI) techniques to augment our models\\n\\nC: Adding explainability makes sense. We should also discuss how to carefully test models before launch to catch additional issues. And have a plan to monitor their impacts over time.\\n\\nAction item: Develop testing and monitoring standards for AI models based on industry best practices\\n\\nA: Great suggestions all around. It seems like we have a blueprint to make responsibility, safety and ethics central to our AI efforts here. I'm optimistic if we build these considerations in from the start, we can drive real progress. Does anyone have any other thoughts before we break?\\n</conversation>\",\n",
      "  \"completion\": \"\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Draft a proposal for an AI model safety review framework\\n- Explore methodologies for value alignment in AI systems\\n\\nB:\\n- Outline additional potential safety risks to address such as data/algorithm bias and security\\n- Research existing XAI (explainable AI) techniques to augment our models\\n- Develop testing and monitoring standards for AI models based on industry best practices\\n\\nC:\\n- Add explainability to AI models\\n- Discuss how to carefully test models before launch to catch additional issues\\n- Have a plan to monitor their impacts over time\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 4.4189231395721436,\n",
      "  \"completion_token_count\": 138,\n",
      "  \"prompt_token_count\": 901\n",
      "}\n",
      "[2024-01-04 18:10:51,586] p93154 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nA: I wanted to have a broader discussion on responsible AI development principles. As we build more AI models, how do we ensure they are helpful, harmless, and aligned with human values?\\n\\nB: This is an important topic. We need to make ethical considerations a priority from the beginning of any AI project, not an afterthought. I think we should develop a review process focused on safety for all new models. \\n\\nAction item: Draft a proposal for an AI model safety review framework \\n\\nC: I agree. We should analyze potential risks like data bias and misuse upfront. Models also need to be secure - what if they were hacked?\\n\\nAction item: Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA: Valid points. Besides analyzing risks, we also need to ensure the objectives we give AI align with human values more broadly. Like being helpful to users, not just maximizing some narrow metric. \\n\\nAction item: Explore methodologies for value alignment in AI systems\\n\\nB: The objectives point connects to transparency too. Any AI decisions that impact users should be explainable. If we can't understand why an AI did something, we can't verify it's aligned.  \\n\\nAction item: Research existing XAI (explainable AI) techniques to augment our models\\n\\nC: Adding explainability makes sense. We should also discuss how to carefully test models before launch to catch additional issues. And have a plan to monitor their impacts over time.\\n\\nAction item: Develop testing and monitoring standards for AI models based on industry best practices\\n\\nA: Great suggestions all around. It seems like we have a blueprint to make responsibility, safety and ethics central to our AI efforts here. I'm optimistic if we build these considerations in from the start, we can drive real progress. Does anyone have any other thoughts before we break?\\n</conversation>\",\n",
      "  \"completion\": \"<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Draft a proposal for an AI model safety review framework\\n- Explore methodologies for value alignment in AI systems\\n\\nB:\\n- Outline additional potential safety risks to address such as data/algorithm bias and security\\n- Research existing XAI (explainable AI) techniques to augment our models\\n- Develop testing and monitoring standards for AI models based on industry best practices\\n\\nC:\\n- Add explainability to AI models\\n- Discuss how to carefully test models before launch to catch additional issues\\n- Have a plan to monitor their impacts over time\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 4.4189231395721436,\n",
      "  \"completion_token_count\": 138,\n",
      "  \"prompt_token_count\": 901,\n",
      "  \"cost\": 0.0009416000000000001,\n",
      "  \"completion_word_count\": 103,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-04 18:10:51,588] p93154 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=cohere_template.txt, reps=3\n",
      "[2024-01-04 18:10:51,589] p93154 {544935498.py:35} INFO - going to summarize idx=3, file=data/raw/3/call_center_transcript_3_transcript.txt via cohere.command-text-v14\n",
      "[2024-01-04 18:10:51,591] p93154 {544935498.py:38} INFO - read prompt template from data/prompts/cohere_template.txt\n",
      "[2024-01-04 18:10:51,597] p93154 {544935498.py:43} INFO - prompt for data/raw/3/call_center_transcript_3_transcript.txt has 893 tokens\n",
      "[2024-01-04 18:10:51,598] p93154 {528272729.py:4} INFO - model_id=cohere.command-text-v14, prompt length is 4015 characters, 679 words\n",
      "[2024-01-04 18:10:55,472] p93154 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to have a broader discussion on responsible AI development principles. As we build more AI models, how do we ensure they are helpful, harmless, and aligned with human values?\\n\\nB: This is an important topic. We need to make ethical considerations a priority from the beginning of any AI project, not an afterthought. I think we should develop a review process focused on safety for all new models. \\n\\nAction item: Draft a proposal for an AI model safety review framework \\n\\nC: I agree. We should analyze potential risks like data bias and misuse upfront. Models also need to be secure - what if they were hacked?\\n\\nAction item: Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA: Valid points. Besides analyzing risks, we also need to ensure the objectives we give AI align with human values more broadly. Like being helpful to users, not just maximizing some narrow metric. \\n\\nAction item: Explore methodologies for value alignment in AI systems\\n\\nB: The objectives point connects to transparency too. Any AI decisions that impact users should be explainable. If we can't understand why an AI did something, we can't verify it's aligned.  \\n\\nAction item: Research existing XAI (explainable AI) techniques to augment our models\\n\\nC: Adding explainability makes sense. We should also discuss how to carefully test models before launch to catch additional issues. And have a plan to monitor their impacts over time.\\n\\nAction item: Develop testing and monitoring standards for AI models based on industry best practices\\n\\nA: Great suggestions all around. It seems like we have a blueprint to make responsibility, safety and ethics central to our AI efforts here. I'm optimistic if we build these considerations in from the start, we can drive real progress. Does anyone have any other thoughts before we break?\\n</conversation>\",\n",
      "  \"completion\": \" <output>\\nA: \\n- Draft a proposal for an AI model safety review framework \\n- Explore methodologies for value alignment in AI systems \\n\\nB: \\n- None\\n\\nC:\\n- Outline additional safety risks \\n- Discuss how to carefully test models before launch \\n- Develop testing and monitoring standards for AI models \\n- Follow up on the discussion to incorporate responsible AI development principles in the project\\n</output>\\n\\nDo you want me to generate action items for any other conversations? \",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 3.872436046600342,\n",
      "  \"completion_token_count\": 102,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-04 18:10:55,473] p93154 {544935498.py:76} INFO - prompt_token_count is None for cohere.command-text-v14, setting it to 893 \n",
      "[2024-01-04 18:10:55,476] p93154 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to have a broader discussion on responsible AI development principles. As we build more AI models, how do we ensure they are helpful, harmless, and aligned with human values?\\n\\nB: This is an important topic. We need to make ethical considerations a priority from the beginning of any AI project, not an afterthought. I think we should develop a review process focused on safety for all new models. \\n\\nAction item: Draft a proposal for an AI model safety review framework \\n\\nC: I agree. We should analyze potential risks like data bias and misuse upfront. Models also need to be secure - what if they were hacked?\\n\\nAction item: Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA: Valid points. Besides analyzing risks, we also need to ensure the objectives we give AI align with human values more broadly. Like being helpful to users, not just maximizing some narrow metric. \\n\\nAction item: Explore methodologies for value alignment in AI systems\\n\\nB: The objectives point connects to transparency too. Any AI decisions that impact users should be explainable. If we can't understand why an AI did something, we can't verify it's aligned.  \\n\\nAction item: Research existing XAI (explainable AI) techniques to augment our models\\n\\nC: Adding explainability makes sense. We should also discuss how to carefully test models before launch to catch additional issues. And have a plan to monitor their impacts over time.\\n\\nAction item: Develop testing and monitoring standards for AI models based on industry best practices\\n\\nA: Great suggestions all around. It seems like we have a blueprint to make responsibility, safety and ethics central to our AI efforts here. I'm optimistic if we build these considerations in from the start, we can drive real progress. Does anyone have any other thoughts before we break?\\n</conversation>\",\n",
      "  \"completion\": \"<output>\\nA: \\n- Draft a proposal for an AI model safety review framework \\n- Explore methodologies for value alignment in AI systems \\n\\nB: \\n- None\\n\\nC:\\n- Outline additional safety risks \\n- Discuss how to carefully test models before launch \\n- Develop testing and monitoring standards for AI models \\n- Follow up on the discussion to incorporate responsible AI development principles in the project\\n</output>\\n\\nDo you want me to generate action items for any other conversations?\",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 3.872436046600342,\n",
      "  \"completion_token_count\": 102,\n",
      "  \"prompt_token_count\": 893,\n",
      "  \"cost\": 0.0015435,\n",
      "  \"completion_word_count\": 77,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-04 18:10:55,482] p93154 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=anthropic_template_single_line_reason.txt, reps=3\n",
      "[2024-01-04 18:10:55,483] p93154 {544935498.py:35} INFO - going to summarize idx=3, file=data/raw/3/call_center_transcript_3_transcript.txt via anthropic.claude-instant-v1\n",
      "[2024-01-04 18:10:55,485] p93154 {544935498.py:38} INFO - read prompt template from data/prompts/anthropic_template_single_line_reason.txt\n",
      "[2024-01-04 18:10:55,493] p93154 {544935498.py:43} INFO - prompt for data/raw/3/call_center_transcript_3_transcript.txt has 880 tokens\n",
      "[2024-01-04 18:10:55,495] p93154 {528272729.py:4} INFO - model_id=anthropic.claude-instant-v1, prompt length is 3937 characters, 663 words\n",
      "[2024-01-04 18:10:56,867] p93154 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to have a broader discussion on responsible AI development principles. As we build more AI models, how do we ensure they are helpful, harmless, and aligned with human values?\\n\\nB: This is an important topic. We need to make ethical considerations a priority from the beginning of any AI project, not an afterthought. I think we should develop a review process focused on safety for all new models. \\n\\nAction item: Draft a proposal for an AI model safety review framework \\n\\nC: I agree. We should analyze potential risks like data bias and misuse upfront. Models also need to be secure - what if they were hacked?\\n\\nAction item: Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA: Valid points. Besides analyzing risks, we also need to ensure the objectives we give AI align with human values more broadly. Like being helpful to users, not just maximizing some narrow metric. \\n\\nAction item: Explore methodologies for value alignment in AI systems\\n\\nB: The objectives point connects to transparency too. Any AI decisions that impact users should be explainable. If we can't understand why an AI did something, we can't verify it's aligned.  \\n\\nAction item: Research existing XAI (explainable AI) techniques to augment our models\\n\\nC: Adding explainability makes sense. We should also discuss how to carefully test models before launch to catch additional issues. And have a plan to monitor their impacts over time.\\n\\nAction item: Develop testing and monitoring standards for AI models based on industry best practices\\n\\nA: Great suggestions all around. It seems like we have a blueprint to make responsibility, safety and ethics central to our AI efforts here. I'm optimistic if we build these considerations in from the start, we can drive real progress. Does anyone have any other thoughts before we break?\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \" <output>\\nA: \\n- No explicit action items stated\\n\\nB:  \\n- Draft a proposal for an AI model safety review framework\\n\\nC:\\n- Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA:  \\n- Explore methodologies for value alignment in AI systems \\n\\nB:\\n- Research existing XAI (explainable AI) techniques to augment our models\\n\\nC:\\n- Develop testing and monitoring standards for AI models based on industry best practices\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 1.3706200122833252,\n",
      "  \"completion_token_count\": 113,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-04 18:10:56,868] p93154 {544935498.py:76} INFO - prompt_token_count is None for anthropic.claude-instant-v1, setting it to 880 \n",
      "[2024-01-04 18:10:56,870] p93154 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to have a broader discussion on responsible AI development principles. As we build more AI models, how do we ensure they are helpful, harmless, and aligned with human values?\\n\\nB: This is an important topic. We need to make ethical considerations a priority from the beginning of any AI project, not an afterthought. I think we should develop a review process focused on safety for all new models. \\n\\nAction item: Draft a proposal for an AI model safety review framework \\n\\nC: I agree. We should analyze potential risks like data bias and misuse upfront. Models also need to be secure - what if they were hacked?\\n\\nAction item: Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA: Valid points. Besides analyzing risks, we also need to ensure the objectives we give AI align with human values more broadly. Like being helpful to users, not just maximizing some narrow metric. \\n\\nAction item: Explore methodologies for value alignment in AI systems\\n\\nB: The objectives point connects to transparency too. Any AI decisions that impact users should be explainable. If we can't understand why an AI did something, we can't verify it's aligned.  \\n\\nAction item: Research existing XAI (explainable AI) techniques to augment our models\\n\\nC: Adding explainability makes sense. We should also discuss how to carefully test models before launch to catch additional issues. And have a plan to monitor their impacts over time.\\n\\nAction item: Develop testing and monitoring standards for AI models based on industry best practices\\n\\nA: Great suggestions all around. It seems like we have a blueprint to make responsibility, safety and ethics central to our AI efforts here. I'm optimistic if we build these considerations in from the start, we can drive real progress. Does anyone have any other thoughts before we break?\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \"<output>\\nA: \\n- No explicit action items stated\\n\\nB:  \\n- Draft a proposal for an AI model safety review framework\\n\\nC:\\n- Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA:  \\n- Explore methodologies for value alignment in AI systems \\n\\nB:\\n- Research existing XAI (explainable AI) techniques to augment our models\\n\\nC:\\n- Develop testing and monitoring standards for AI models based on industry best practices\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 1.3706200122833252,\n",
      "  \"completion_token_count\": 113,\n",
      "  \"prompt_token_count\": 880,\n",
      "  \"cost\": 0.00205703,\n",
      "  \"completion_word_count\": 73,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-04 18:10:56,873] p93154 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=titan_template.txt, reps=3\n",
      "[2024-01-04 18:10:56,874] p93154 {544935498.py:35} INFO - going to summarize idx=3, file=data/raw/3/call_center_transcript_3_transcript.txt via amazon.titan-text-express-v1\n",
      "[2024-01-04 18:10:56,875] p93154 {544935498.py:38} INFO - read prompt template from data/prompts/titan_template.txt\n",
      "[2024-01-04 18:10:56,883] p93154 {544935498.py:43} INFO - prompt for data/raw/3/call_center_transcript_3_transcript.txt has 898 tokens\n",
      "[2024-01-04 18:10:56,884] p93154 {528272729.py:4} INFO - model_id=amazon.titan-text-express-v1, prompt length is 4020 characters, 680 words\n",
      "[2024-01-04 18:11:00,389] p93154 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nA: I wanted to have a broader discussion on responsible AI development principles. As we build more AI models, how do we ensure they are helpful, harmless, and aligned with human values?\\n\\nB: This is an important topic. We need to make ethical considerations a priority from the beginning of any AI project, not an afterthought. I think we should develop a review process focused on safety for all new models. \\n\\nAction item: Draft a proposal for an AI model safety review framework \\n\\nC: I agree. We should analyze potential risks like data bias and misuse upfront. Models also need to be secure - what if they were hacked?\\n\\nAction item: Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA: Valid points. Besides analyzing risks, we also need to ensure the objectives we give AI align with human values more broadly. Like being helpful to users, not just maximizing some narrow metric. \\n\\nAction item: Explore methodologies for value alignment in AI systems\\n\\nB: The objectives point connects to transparency too. Any AI decisions that impact users should be explainable. If we can't understand why an AI did something, we can't verify it's aligned.  \\n\\nAction item: Research existing XAI (explainable AI) techniques to augment our models\\n\\nC: Adding explainability makes sense. We should also discuss how to carefully test models before launch to catch additional issues. And have a plan to monitor their impacts over time.\\n\\nAction item: Develop testing and monitoring standards for AI models based on industry best practices\\n\\nA: Great suggestions all around. It seems like we have a blueprint to make responsibility, safety and ethics central to our AI efforts here. I'm optimistic if we build these considerations in from the start, we can drive real progress. Does anyone have any other thoughts before we break?\\n</conversation>\",\n",
      "  \"completion\": \"\\n<output>\\nAction item: Draft a proposal for an AI model safety review framework\\nAction item: Outline additional potential safety risks to address such as data/algorithm bias and security\\nAction item: Explore methodologies for value alignment in AI systems\\nAction item: Research existing XAI (explainable AI) techniques to augment our models\\nAction item: Develop testing and monitoring standards for AI models based on industry best practices\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 3.504056215286255,\n",
      "  \"completion_token_count\": 91,\n",
      "  \"prompt_token_count\": 901\n",
      "}\n",
      "[2024-01-04 18:11:00,390] p93154 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nA: I wanted to have a broader discussion on responsible AI development principles. As we build more AI models, how do we ensure they are helpful, harmless, and aligned with human values?\\n\\nB: This is an important topic. We need to make ethical considerations a priority from the beginning of any AI project, not an afterthought. I think we should develop a review process focused on safety for all new models. \\n\\nAction item: Draft a proposal for an AI model safety review framework \\n\\nC: I agree. We should analyze potential risks like data bias and misuse upfront. Models also need to be secure - what if they were hacked?\\n\\nAction item: Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA: Valid points. Besides analyzing risks, we also need to ensure the objectives we give AI align with human values more broadly. Like being helpful to users, not just maximizing some narrow metric. \\n\\nAction item: Explore methodologies for value alignment in AI systems\\n\\nB: The objectives point connects to transparency too. Any AI decisions that impact users should be explainable. If we can't understand why an AI did something, we can't verify it's aligned.  \\n\\nAction item: Research existing XAI (explainable AI) techniques to augment our models\\n\\nC: Adding explainability makes sense. We should also discuss how to carefully test models before launch to catch additional issues. And have a plan to monitor their impacts over time.\\n\\nAction item: Develop testing and monitoring standards for AI models based on industry best practices\\n\\nA: Great suggestions all around. It seems like we have a blueprint to make responsibility, safety and ethics central to our AI efforts here. I'm optimistic if we build these considerations in from the start, we can drive real progress. Does anyone have any other thoughts before we break?\\n</conversation>\",\n",
      "  \"completion\": \"<output>\\nAction item: Draft a proposal for an AI model safety review framework\\nAction item: Outline additional potential safety risks to address such as data/algorithm bias and security\\nAction item: Explore methodologies for value alignment in AI systems\\nAction item: Research existing XAI (explainable AI) techniques to augment our models\\nAction item: Develop testing and monitoring standards for AI models based on industry best practices\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 3.504056215286255,\n",
      "  \"completion_token_count\": 91,\n",
      "  \"prompt_token_count\": 901,\n",
      "  \"cost\": 0.0008664,\n",
      "  \"completion_word_count\": 66,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-04 18:11:00,391] p93154 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=cohere_template.txt, reps=3\n",
      "[2024-01-04 18:11:00,391] p93154 {544935498.py:35} INFO - going to summarize idx=3, file=data/raw/3/call_center_transcript_3_transcript.txt via cohere.command-text-v14\n",
      "[2024-01-04 18:11:00,392] p93154 {544935498.py:38} INFO - read prompt template from data/prompts/cohere_template.txt\n",
      "[2024-01-04 18:11:00,394] p93154 {544935498.py:43} INFO - prompt for data/raw/3/call_center_transcript_3_transcript.txt has 893 tokens\n",
      "[2024-01-04 18:11:00,395] p93154 {528272729.py:4} INFO - model_id=cohere.command-text-v14, prompt length is 4015 characters, 679 words\n",
      "[2024-01-04 18:11:04,299] p93154 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to have a broader discussion on responsible AI development principles. As we build more AI models, how do we ensure they are helpful, harmless, and aligned with human values?\\n\\nB: This is an important topic. We need to make ethical considerations a priority from the beginning of any AI project, not an afterthought. I think we should develop a review process focused on safety for all new models. \\n\\nAction item: Draft a proposal for an AI model safety review framework \\n\\nC: I agree. We should analyze potential risks like data bias and misuse upfront. Models also need to be secure - what if they were hacked?\\n\\nAction item: Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA: Valid points. Besides analyzing risks, we also need to ensure the objectives we give AI align with human values more broadly. Like being helpful to users, not just maximizing some narrow metric. \\n\\nAction item: Explore methodologies for value alignment in AI systems\\n\\nB: The objectives point connects to transparency too. Any AI decisions that impact users should be explainable. If we can't understand why an AI did something, we can't verify it's aligned.  \\n\\nAction item: Research existing XAI (explainable AI) techniques to augment our models\\n\\nC: Adding explainability makes sense. We should also discuss how to carefully test models before launch to catch additional issues. And have a plan to monitor their impacts over time.\\n\\nAction item: Develop testing and monitoring standards for AI models based on industry best practices\\n\\nA: Great suggestions all around. It seems like we have a blueprint to make responsibility, safety and ethics central to our AI efforts here. I'm optimistic if we build these considerations in from the start, we can drive real progress. Does anyone have any other thoughts before we break?\\n</conversation>\",\n",
      "  \"completion\": \" <output>\\nA: \\n- Draft a proposal for an AI model safety review framework \\n- Explore methodologies for value alignment in AI systems \\n\\nB: \\n- None\\n\\nC:\\n- Outline additional safety risks \\n- Discuss how to carefully test models before launch \\n- Develop testing and monitoring standards for AI models \\n- Follow up on the discussion to incorporate responsible AI development principles in the project\\n</output>\\n\\nDo you want me to generate action items for any other conversations? \",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 3.9031929969787598,\n",
      "  \"completion_token_count\": 102,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-04 18:11:04,300] p93154 {544935498.py:76} INFO - prompt_token_count is None for cohere.command-text-v14, setting it to 893 \n",
      "[2024-01-04 18:11:04,304] p93154 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to have a broader discussion on responsible AI development principles. As we build more AI models, how do we ensure they are helpful, harmless, and aligned with human values?\\n\\nB: This is an important topic. We need to make ethical considerations a priority from the beginning of any AI project, not an afterthought. I think we should develop a review process focused on safety for all new models. \\n\\nAction item: Draft a proposal for an AI model safety review framework \\n\\nC: I agree. We should analyze potential risks like data bias and misuse upfront. Models also need to be secure - what if they were hacked?\\n\\nAction item: Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA: Valid points. Besides analyzing risks, we also need to ensure the objectives we give AI align with human values more broadly. Like being helpful to users, not just maximizing some narrow metric. \\n\\nAction item: Explore methodologies for value alignment in AI systems\\n\\nB: The objectives point connects to transparency too. Any AI decisions that impact users should be explainable. If we can't understand why an AI did something, we can't verify it's aligned.  \\n\\nAction item: Research existing XAI (explainable AI) techniques to augment our models\\n\\nC: Adding explainability makes sense. We should also discuss how to carefully test models before launch to catch additional issues. And have a plan to monitor their impacts over time.\\n\\nAction item: Develop testing and monitoring standards for AI models based on industry best practices\\n\\nA: Great suggestions all around. It seems like we have a blueprint to make responsibility, safety and ethics central to our AI efforts here. I'm optimistic if we build these considerations in from the start, we can drive real progress. Does anyone have any other thoughts before we break?\\n</conversation>\",\n",
      "  \"completion\": \"<output>\\nA: \\n- Draft a proposal for an AI model safety review framework \\n- Explore methodologies for value alignment in AI systems \\n\\nB: \\n- None\\n\\nC:\\n- Outline additional safety risks \\n- Discuss how to carefully test models before launch \\n- Develop testing and monitoring standards for AI models \\n- Follow up on the discussion to incorporate responsible AI development principles in the project\\n</output>\\n\\nDo you want me to generate action items for any other conversations?\",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 3.9031929969787598,\n",
      "  \"completion_token_count\": 102,\n",
      "  \"prompt_token_count\": 893,\n",
      "  \"cost\": 0.0015435,\n",
      "  \"completion_word_count\": 77,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-04 18:11:04,310] p93154 {544935498.py:19} INFO - idx=4, tf=data/raw/2/call_center_transcript_2_transcript.txt, file_id=call_center_transcript_2, golden_summary_fpath=data/raw/0/example_prompt_transcript_golden_summary.txt\n",
      "[2024-01-04 18:11:04,317] p93154 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=anthropic_template_single_line_reason.txt, reps=3\n",
      "[2024-01-04 18:11:04,319] p93154 {544935498.py:35} INFO - going to summarize idx=4, file=data/raw/2/call_center_transcript_2_transcript.txt via anthropic.claude-instant-v1\n",
      "[2024-01-04 18:11:04,324] p93154 {544935498.py:38} INFO - read prompt template from data/prompts/anthropic_template_single_line_reason.txt\n",
      "[2024-01-04 18:11:04,330] p93154 {544935498.py:43} INFO - prompt for data/raw/2/call_center_transcript_2_transcript.txt has 775 tokens\n",
      "[2024-01-04 18:11:04,331] p93154 {528272729.py:4} INFO - model_id=anthropic.claude-instant-v1, prompt length is 3389 characters, 571 words\n",
      "[2024-01-04 18:11:05,639] p93154 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to discuss ideas for a new startup in the mobile gaming space. The success of companies like Angry Birds shows there is a lot of potential still untapped. \\nAction item: Research recent trends and growth in mobile gaming to identify opportunities\\n\\nB: I agree mobile gaming is hot right now. Have you thought about potential types of games we could develop? Should we try freemium or paid apps?\\nAction item: Outline pros and cons for freemium vs paid monetization models\\n\\nC: We should consider other business models too like in-game ads or sponsorships. The key is retaining users and driving high engagement.\\nAction item: Explore in-game ad networks and pricing\\nAction item: Brainstorm ideas to maximize user retention \\n\\nA: Those are good points. I also think we need to prototype game concepts quickly to validate demand before investing too heavily in development.\\nAction item: Define process for rapidly prototyping and testing game concepts  \\n\\nB: Yes, we could even use some AI tools now to auto-generate simple game artwork and mechanics. This can help speed up testing. \\nAction item: Evaluate AI-powered game prototyping tools to complement our development efforts\\n\\nC: Automating pieces through AI makes sense. Though we still need to ensure quality bar for any games we officially launch.\\n\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \" <output>\\nA: \\n- Research recent trends and growth in mobile gaming to identify opportunities\\n- Define process for rapidly prototyping and testing game concepts\\n\\nB:  \\n- Outline pros and cons for freemium vs paid monetization models\\n- Evaluate AI-powered game prototyping tools to complement our development efforts\\n\\nC:\\n- Explore in-game ad networks and pricing  \\n- Brainstorm ideas to maximize user retention\\n- Ensure quality bar for any officially launched games\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 1.3074359893798828,\n",
      "  \"completion_token_count\": 110,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-04 18:11:05,640] p93154 {544935498.py:76} INFO - prompt_token_count is None for anthropic.claude-instant-v1, setting it to 775 \n",
      "[2024-01-04 18:11:05,641] p93154 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to discuss ideas for a new startup in the mobile gaming space. The success of companies like Angry Birds shows there is a lot of potential still untapped. \\nAction item: Research recent trends and growth in mobile gaming to identify opportunities\\n\\nB: I agree mobile gaming is hot right now. Have you thought about potential types of games we could develop? Should we try freemium or paid apps?\\nAction item: Outline pros and cons for freemium vs paid monetization models\\n\\nC: We should consider other business models too like in-game ads or sponsorships. The key is retaining users and driving high engagement.\\nAction item: Explore in-game ad networks and pricing\\nAction item: Brainstorm ideas to maximize user retention \\n\\nA: Those are good points. I also think we need to prototype game concepts quickly to validate demand before investing too heavily in development.\\nAction item: Define process for rapidly prototyping and testing game concepts  \\n\\nB: Yes, we could even use some AI tools now to auto-generate simple game artwork and mechanics. This can help speed up testing. \\nAction item: Evaluate AI-powered game prototyping tools to complement our development efforts\\n\\nC: Automating pieces through AI makes sense. Though we still need to ensure quality bar for any games we officially launch.\\n\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \"<output>\\nA: \\n- Research recent trends and growth in mobile gaming to identify opportunities\\n- Define process for rapidly prototyping and testing game concepts\\n\\nB:  \\n- Outline pros and cons for freemium vs paid monetization models\\n- Evaluate AI-powered game prototyping tools to complement our development efforts\\n\\nC:\\n- Explore in-game ad networks and pricing  \\n- Brainstorm ideas to maximize user retention\\n- Ensure quality bar for any officially launched games\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 1.3074359893798828,\n",
      "  \"completion_token_count\": 110,\n",
      "  \"prompt_token_count\": 775,\n",
      "  \"cost\": 0.0018693499999999999,\n",
      "  \"completion_word_count\": 72,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-04 18:11:05,655] p93154 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=titan_template.txt, reps=3\n",
      "[2024-01-04 18:11:05,662] p93154 {544935498.py:35} INFO - going to summarize idx=4, file=data/raw/2/call_center_transcript_2_transcript.txt via amazon.titan-text-express-v1\n",
      "[2024-01-04 18:11:05,667] p93154 {544935498.py:38} INFO - read prompt template from data/prompts/titan_template.txt\n",
      "[2024-01-04 18:11:05,672] p93154 {544935498.py:43} INFO - prompt for data/raw/2/call_center_transcript_2_transcript.txt has 793 tokens\n",
      "[2024-01-04 18:11:05,679] p93154 {528272729.py:4} INFO - model_id=amazon.titan-text-express-v1, prompt length is 3472 characters, 588 words\n",
      "[2024-01-04 18:11:10,915] p93154 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nA: I wanted to discuss ideas for a new startup in the mobile gaming space. The success of companies like Angry Birds shows there is a lot of potential still untapped. \\nAction item: Research recent trends and growth in mobile gaming to identify opportunities\\n\\nB: I agree mobile gaming is hot right now. Have you thought about potential types of games we could develop? Should we try freemium or paid apps?\\nAction item: Outline pros and cons for freemium vs paid monetization models\\n\\nC: We should consider other business models too like in-game ads or sponsorships. The key is retaining users and driving high engagement.\\nAction item: Explore in-game ad networks and pricing\\nAction item: Brainstorm ideas to maximize user retention \\n\\nA: Those are good points. I also think we need to prototype game concepts quickly to validate demand before investing too heavily in development.\\nAction item: Define process for rapidly prototyping and testing game concepts  \\n\\nB: Yes, we could even use some AI tools now to auto-generate simple game artwork and mechanics. This can help speed up testing. \\nAction item: Evaluate AI-powered game prototyping tools to complement our development efforts\\n\\nC: Automating pieces through AI makes sense. Though we still need to ensure quality bar for any games we officially launch.\\n\\n</conversation>\",\n",
      "  \"completion\": \"\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Research recent trends and growth in mobile gaming to identify opportunities\\n- Outline pros and cons for freemium vs paid monetization models\\n- Explore in-game ad networks and pricing\\n- Brainstorm ideas to maximize user retention\\n- Define process for rapidly prototyping and testing game concepts\\n- Evaluate AI-powered game prototyping tools to complement our development efforts\\n\\nB:\\n- None explicitly stated\\n\\nC:\\n- Explore in-game ad networks and pricing\\n- Brainstorm ideas to maximize user retention\\n- Define process for rapidly prototyping and testing game concepts\\n- Evaluate AI-powered game prototyping tools to complement our development efforts\\n- Ensure quality bar for any games we officially launch\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 5.232640981674194,\n",
      "  \"completion_token_count\": 167,\n",
      "  \"prompt_token_count\": 793\n",
      "}\n",
      "[2024-01-04 18:11:10,917] p93154 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nA: I wanted to discuss ideas for a new startup in the mobile gaming space. The success of companies like Angry Birds shows there is a lot of potential still untapped. \\nAction item: Research recent trends and growth in mobile gaming to identify opportunities\\n\\nB: I agree mobile gaming is hot right now. Have you thought about potential types of games we could develop? Should we try freemium or paid apps?\\nAction item: Outline pros and cons for freemium vs paid monetization models\\n\\nC: We should consider other business models too like in-game ads or sponsorships. The key is retaining users and driving high engagement.\\nAction item: Explore in-game ad networks and pricing\\nAction item: Brainstorm ideas to maximize user retention \\n\\nA: Those are good points. I also think we need to prototype game concepts quickly to validate demand before investing too heavily in development.\\nAction item: Define process for rapidly prototyping and testing game concepts  \\n\\nB: Yes, we could even use some AI tools now to auto-generate simple game artwork and mechanics. This can help speed up testing. \\nAction item: Evaluate AI-powered game prototyping tools to complement our development efforts\\n\\nC: Automating pieces through AI makes sense. Though we still need to ensure quality bar for any games we officially launch.\\n\\n</conversation>\",\n",
      "  \"completion\": \"<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Research recent trends and growth in mobile gaming to identify opportunities\\n- Outline pros and cons for freemium vs paid monetization models\\n- Explore in-game ad networks and pricing\\n- Brainstorm ideas to maximize user retention\\n- Define process for rapidly prototyping and testing game concepts\\n- Evaluate AI-powered game prototyping tools to complement our development efforts\\n\\nB:\\n- None explicitly stated\\n\\nC:\\n- Explore in-game ad networks and pricing\\n- Brainstorm ideas to maximize user retention\\n- Define process for rapidly prototyping and testing game concepts\\n- Evaluate AI-powered game prototyping tools to complement our development efforts\\n- Ensure quality bar for any games we officially launch\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 5.232640981674194,\n",
      "  \"completion_token_count\": 167,\n",
      "  \"prompt_token_count\": 793,\n",
      "  \"cost\": 0.0009016,\n",
      "  \"completion_word_count\": 122,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-04 18:11:10,919] p93154 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=cohere_template.txt, reps=3\n",
      "[2024-01-04 18:11:10,919] p93154 {544935498.py:35} INFO - going to summarize idx=4, file=data/raw/2/call_center_transcript_2_transcript.txt via cohere.command-text-v14\n",
      "[2024-01-04 18:11:10,921] p93154 {544935498.py:38} INFO - read prompt template from data/prompts/cohere_template.txt\n",
      "[2024-01-04 18:11:10,925] p93154 {544935498.py:43} INFO - prompt for data/raw/2/call_center_transcript_2_transcript.txt has 788 tokens\n",
      "[2024-01-04 18:11:10,926] p93154 {528272729.py:4} INFO - model_id=cohere.command-text-v14, prompt length is 3467 characters, 587 words\n",
      "[2024-01-04 18:11:18,098] p93154 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to discuss ideas for a new startup in the mobile gaming space. The success of companies like Angry Birds shows there is a lot of potential still untapped. \\nAction item: Research recent trends and growth in mobile gaming to identify opportunities\\n\\nB: I agree mobile gaming is hot right now. Have you thought about potential types of games we could develop? Should we try freemium or paid apps?\\nAction item: Outline pros and cons for freemium vs paid monetization models\\n\\nC: We should consider other business models too like in-game ads or sponsorships. The key is retaining users and driving high engagement.\\nAction item: Explore in-game ad networks and pricing\\nAction item: Brainstorm ideas to maximize user retention \\n\\nA: Those are good points. I also think we need to prototype game concepts quickly to validate demand before investing too heavily in development.\\nAction item: Define process for rapidly prototyping and testing game concepts  \\n\\nB: Yes, we could even use some AI tools now to auto-generate simple game artwork and mechanics. This can help speed up testing. \\nAction item: Evaluate AI-powered game prototyping tools to complement our development efforts\\n\\nC: Automating pieces through AI makes sense. Though we still need to ensure quality bar for any games we officially launch.\\n\\n</conversation>\",\n",
      "  \"completion\": \" <output>\\nA: \\n- Research mobile gaming trends and identify opportunities for startup\\n- Define process for rapidly prototyping game concepts \\n- Evaluate AI game prototyping tools\\n\\nB: \\n- Outline pros and cons for freemium vs paid app monetization models\\n\\nC:\\n- Explore in-game ad networks and sponsorship opportunities\\n- Brainstorm ideas to improve user retention\\n- Evaluate AI tools for rapid game prototyping and artwork creation\\n</output>\\n\\nWhoever is responsible for creating action items out of the conversation had the responsibility of assigning action items and making sure they got assigned to the right person. In this conversation, creating action items was a collective responsibility, with each participant assigning some to themselves. The conversation also resulted in a comprehensive list of action items that covered a wide range of topics, from market research to specific next steps in the development process. It is important to make sure the action items are clear, specific, and actionable to increase the chances of follow-through and successful project implementation. \",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 7.171072006225586,\n",
      "  \"completion_token_count\": 220,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-04 18:11:18,099] p93154 {544935498.py:76} INFO - prompt_token_count is None for cohere.command-text-v14, setting it to 788 \n",
      "[2024-01-04 18:11:18,102] p93154 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to discuss ideas for a new startup in the mobile gaming space. The success of companies like Angry Birds shows there is a lot of potential still untapped. \\nAction item: Research recent trends and growth in mobile gaming to identify opportunities\\n\\nB: I agree mobile gaming is hot right now. Have you thought about potential types of games we could develop? Should we try freemium or paid apps?\\nAction item: Outline pros and cons for freemium vs paid monetization models\\n\\nC: We should consider other business models too like in-game ads or sponsorships. The key is retaining users and driving high engagement.\\nAction item: Explore in-game ad networks and pricing\\nAction item: Brainstorm ideas to maximize user retention \\n\\nA: Those are good points. I also think we need to prototype game concepts quickly to validate demand before investing too heavily in development.\\nAction item: Define process for rapidly prototyping and testing game concepts  \\n\\nB: Yes, we could even use some AI tools now to auto-generate simple game artwork and mechanics. This can help speed up testing. \\nAction item: Evaluate AI-powered game prototyping tools to complement our development efforts\\n\\nC: Automating pieces through AI makes sense. Though we still need to ensure quality bar for any games we officially launch.\\n\\n</conversation>\",\n",
      "  \"completion\": \"<output>\\nA: \\n- Research mobile gaming trends and identify opportunities for startup\\n- Define process for rapidly prototyping game concepts \\n- Evaluate AI game prototyping tools\\n\\nB: \\n- Outline pros and cons for freemium vs paid app monetization models\\n\\nC:\\n- Explore in-game ad networks and sponsorship opportunities\\n- Brainstorm ideas to improve user retention\\n- Evaluate AI tools for rapid game prototyping and artwork creation\\n</output>\\n\\nWhoever is responsible for creating action items out of the conversation had the responsibility of assigning action items and making sure they got assigned to the right person. In this conversation, creating action items was a collective responsibility, with each participant assigning some to themselves. The conversation also resulted in a comprehensive list of action items that covered a wide range of topics, from market research to specific next steps in the development process. It is important to make sure the action items are clear, specific, and actionable to increase the chances of follow-through and successful project implementation.\",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 7.171072006225586,\n",
      "  \"completion_token_count\": 220,\n",
      "  \"prompt_token_count\": 788,\n",
      "  \"cost\": 0.001622,\n",
      "  \"completion_word_count\": 165,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-04 18:11:18,104] p93154 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=anthropic_template_single_line_reason.txt, reps=3\n",
      "[2024-01-04 18:11:18,105] p93154 {544935498.py:35} INFO - going to summarize idx=4, file=data/raw/2/call_center_transcript_2_transcript.txt via anthropic.claude-instant-v1\n",
      "[2024-01-04 18:11:18,106] p93154 {544935498.py:38} INFO - read prompt template from data/prompts/anthropic_template_single_line_reason.txt\n",
      "[2024-01-04 18:11:18,111] p93154 {544935498.py:43} INFO - prompt for data/raw/2/call_center_transcript_2_transcript.txt has 775 tokens\n",
      "[2024-01-04 18:11:18,112] p93154 {528272729.py:4} INFO - model_id=anthropic.claude-instant-v1, prompt length is 3389 characters, 571 words\n",
      "[2024-01-04 18:11:19,313] p93154 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to discuss ideas for a new startup in the mobile gaming space. The success of companies like Angry Birds shows there is a lot of potential still untapped. \\nAction item: Research recent trends and growth in mobile gaming to identify opportunities\\n\\nB: I agree mobile gaming is hot right now. Have you thought about potential types of games we could develop? Should we try freemium or paid apps?\\nAction item: Outline pros and cons for freemium vs paid monetization models\\n\\nC: We should consider other business models too like in-game ads or sponsorships. The key is retaining users and driving high engagement.\\nAction item: Explore in-game ad networks and pricing\\nAction item: Brainstorm ideas to maximize user retention \\n\\nA: Those are good points. I also think we need to prototype game concepts quickly to validate demand before investing too heavily in development.\\nAction item: Define process for rapidly prototyping and testing game concepts  \\n\\nB: Yes, we could even use some AI tools now to auto-generate simple game artwork and mechanics. This can help speed up testing. \\nAction item: Evaluate AI-powered game prototyping tools to complement our development efforts\\n\\nC: Automating pieces through AI makes sense. Though we still need to ensure quality bar for any games we officially launch.\\n\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \" <output>\\nA: \\n- Research recent trends and growth in mobile gaming to identify opportunities\\n- Define process for rapidly prototyping and testing game concepts\\n\\nB:\\n- Outline pros and cons for freemium vs paid monetization models  \\n- Evaluate AI-powered game prototyping tools to complement our development efforts\\n\\nC:\\n- Explore in-game ad networks and pricing\\n- Brainstorm ideas to maximize user retention\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 1.199873924255371,\n",
      "  \"completion_token_count\": 99,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-04 18:11:19,314] p93154 {544935498.py:76} INFO - prompt_token_count is None for anthropic.claude-instant-v1, setting it to 775 \n",
      "[2024-01-04 18:11:19,316] p93154 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to discuss ideas for a new startup in the mobile gaming space. The success of companies like Angry Birds shows there is a lot of potential still untapped. \\nAction item: Research recent trends and growth in mobile gaming to identify opportunities\\n\\nB: I agree mobile gaming is hot right now. Have you thought about potential types of games we could develop? Should we try freemium or paid apps?\\nAction item: Outline pros and cons for freemium vs paid monetization models\\n\\nC: We should consider other business models too like in-game ads or sponsorships. The key is retaining users and driving high engagement.\\nAction item: Explore in-game ad networks and pricing\\nAction item: Brainstorm ideas to maximize user retention \\n\\nA: Those are good points. I also think we need to prototype game concepts quickly to validate demand before investing too heavily in development.\\nAction item: Define process for rapidly prototyping and testing game concepts  \\n\\nB: Yes, we could even use some AI tools now to auto-generate simple game artwork and mechanics. This can help speed up testing. \\nAction item: Evaluate AI-powered game prototyping tools to complement our development efforts\\n\\nC: Automating pieces through AI makes sense. Though we still need to ensure quality bar for any games we officially launch.\\n\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \"<output>\\nA: \\n- Research recent trends and growth in mobile gaming to identify opportunities\\n- Define process for rapidly prototyping and testing game concepts\\n\\nB:\\n- Outline pros and cons for freemium vs paid monetization models  \\n- Evaluate AI-powered game prototyping tools to complement our development efforts\\n\\nC:\\n- Explore in-game ad networks and pricing\\n- Brainstorm ideas to maximize user retention\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 1.199873924255371,\n",
      "  \"completion_token_count\": 99,\n",
      "  \"prompt_token_count\": 775,\n",
      "  \"cost\": 0.0018087399999999997,\n",
      "  \"completion_word_count\": 63,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-04 18:11:19,317] p93154 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=titan_template.txt, reps=3\n",
      "[2024-01-04 18:11:19,317] p93154 {544935498.py:35} INFO - going to summarize idx=4, file=data/raw/2/call_center_transcript_2_transcript.txt via amazon.titan-text-express-v1\n",
      "[2024-01-04 18:11:19,319] p93154 {544935498.py:38} INFO - read prompt template from data/prompts/titan_template.txt\n",
      "[2024-01-04 18:11:19,323] p93154 {544935498.py:43} INFO - prompt for data/raw/2/call_center_transcript_2_transcript.txt has 793 tokens\n",
      "[2024-01-04 18:11:19,323] p93154 {528272729.py:4} INFO - model_id=amazon.titan-text-express-v1, prompt length is 3472 characters, 588 words\n",
      "[2024-01-04 18:11:24,546] p93154 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nA: I wanted to discuss ideas for a new startup in the mobile gaming space. The success of companies like Angry Birds shows there is a lot of potential still untapped. \\nAction item: Research recent trends and growth in mobile gaming to identify opportunities\\n\\nB: I agree mobile gaming is hot right now. Have you thought about potential types of games we could develop? Should we try freemium or paid apps?\\nAction item: Outline pros and cons for freemium vs paid monetization models\\n\\nC: We should consider other business models too like in-game ads or sponsorships. The key is retaining users and driving high engagement.\\nAction item: Explore in-game ad networks and pricing\\nAction item: Brainstorm ideas to maximize user retention \\n\\nA: Those are good points. I also think we need to prototype game concepts quickly to validate demand before investing too heavily in development.\\nAction item: Define process for rapidly prototyping and testing game concepts  \\n\\nB: Yes, we could even use some AI tools now to auto-generate simple game artwork and mechanics. This can help speed up testing. \\nAction item: Evaluate AI-powered game prototyping tools to complement our development efforts\\n\\nC: Automating pieces through AI makes sense. Though we still need to ensure quality bar for any games we officially launch.\\n\\n</conversation>\",\n",
      "  \"completion\": \"\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Research recent trends and growth in mobile gaming to identify opportunities\\n- Outline pros and cons for freemium vs paid monetization models\\n- Explore in-game ad networks and pricing\\n- Brainstorm ideas to maximize user retention\\n- Define process for rapidly prototyping and testing game concepts\\n- Evaluate AI-powered game prototyping tools to complement our development efforts\\n\\nB:\\n- None explicitly stated\\n\\nC:\\n- Explore in-game ad networks and pricing\\n- Brainstorm ideas to maximize user retention\\n- Define process for rapidly prototyping and testing game concepts\\n- Evaluate AI-powered game prototyping tools to complement our development efforts\\n- Ensure quality bar for any games we officially launch\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 5.222831726074219,\n",
      "  \"completion_token_count\": 167,\n",
      "  \"prompt_token_count\": 793\n",
      "}\n",
      "[2024-01-04 18:11:24,549] p93154 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nA: I wanted to discuss ideas for a new startup in the mobile gaming space. The success of companies like Angry Birds shows there is a lot of potential still untapped. \\nAction item: Research recent trends and growth in mobile gaming to identify opportunities\\n\\nB: I agree mobile gaming is hot right now. Have you thought about potential types of games we could develop? Should we try freemium or paid apps?\\nAction item: Outline pros and cons for freemium vs paid monetization models\\n\\nC: We should consider other business models too like in-game ads or sponsorships. The key is retaining users and driving high engagement.\\nAction item: Explore in-game ad networks and pricing\\nAction item: Brainstorm ideas to maximize user retention \\n\\nA: Those are good points. I also think we need to prototype game concepts quickly to validate demand before investing too heavily in development.\\nAction item: Define process for rapidly prototyping and testing game concepts  \\n\\nB: Yes, we could even use some AI tools now to auto-generate simple game artwork and mechanics. This can help speed up testing. \\nAction item: Evaluate AI-powered game prototyping tools to complement our development efforts\\n\\nC: Automating pieces through AI makes sense. Though we still need to ensure quality bar for any games we officially launch.\\n\\n</conversation>\",\n",
      "  \"completion\": \"<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Research recent trends and growth in mobile gaming to identify opportunities\\n- Outline pros and cons for freemium vs paid monetization models\\n- Explore in-game ad networks and pricing\\n- Brainstorm ideas to maximize user retention\\n- Define process for rapidly prototyping and testing game concepts\\n- Evaluate AI-powered game prototyping tools to complement our development efforts\\n\\nB:\\n- None explicitly stated\\n\\nC:\\n- Explore in-game ad networks and pricing\\n- Brainstorm ideas to maximize user retention\\n- Define process for rapidly prototyping and testing game concepts\\n- Evaluate AI-powered game prototyping tools to complement our development efforts\\n- Ensure quality bar for any games we officially launch\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 5.222831726074219,\n",
      "  \"completion_token_count\": 167,\n",
      "  \"prompt_token_count\": 793,\n",
      "  \"cost\": 0.0009016,\n",
      "  \"completion_word_count\": 122,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-04 18:11:24,551] p93154 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=cohere_template.txt, reps=3\n",
      "[2024-01-04 18:11:24,551] p93154 {544935498.py:35} INFO - going to summarize idx=4, file=data/raw/2/call_center_transcript_2_transcript.txt via cohere.command-text-v14\n",
      "[2024-01-04 18:11:24,552] p93154 {544935498.py:38} INFO - read prompt template from data/prompts/cohere_template.txt\n",
      "[2024-01-04 18:11:24,557] p93154 {544935498.py:43} INFO - prompt for data/raw/2/call_center_transcript_2_transcript.txt has 788 tokens\n",
      "[2024-01-04 18:11:24,558] p93154 {528272729.py:4} INFO - model_id=cohere.command-text-v14, prompt length is 3467 characters, 587 words\n",
      "[2024-01-04 18:11:30,263] p93154 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to discuss ideas for a new startup in the mobile gaming space. The success of companies like Angry Birds shows there is a lot of potential still untapped. \\nAction item: Research recent trends and growth in mobile gaming to identify opportunities\\n\\nB: I agree mobile gaming is hot right now. Have you thought about potential types of games we could develop? Should we try freemium or paid apps?\\nAction item: Outline pros and cons for freemium vs paid monetization models\\n\\nC: We should consider other business models too like in-game ads or sponsorships. The key is retaining users and driving high engagement.\\nAction item: Explore in-game ad networks and pricing\\nAction item: Brainstorm ideas to maximize user retention \\n\\nA: Those are good points. I also think we need to prototype game concepts quickly to validate demand before investing too heavily in development.\\nAction item: Define process for rapidly prototyping and testing game concepts  \\n\\nB: Yes, we could even use some AI tools now to auto-generate simple game artwork and mechanics. This can help speed up testing. \\nAction item: Evaluate AI-powered game prototyping tools to complement our development efforts\\n\\nC: Automating pieces through AI makes sense. Though we still need to ensure quality bar for any games we officially launch.\\n\\n</conversation>\",\n",
      "  \"completion\": \" <output>\\nA: \\n- Research mobile gaming markets and trends\\n- Define a process for rapidly prototyping game concepts \\n- Evaluate AI tools for game development\\n\\nB: \\n- Outline pros and cons for different monetization models\\n\\nC:\\n- Explore in-game ad networks and sponsorship opportunities\\n- Brainstorm ideas to improve user retention\\n- Evaluate AI tools that can assist with game development \\n\\n</output>\\n\\nWhoever is responsible for taking the action items (which from the tone of the conversation could be all of A, B and C) should work to turn these items into concrete steps or to-dos with timelines or deadlines where it makes sense. \\n\\nIs there anything else I can help you with regarding action items or any other part of the conversation? \",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 5.704833030700684,\n",
      "  \"completion_token_count\": 164,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-04 18:11:30,264] p93154 {544935498.py:76} INFO - prompt_token_count is None for cohere.command-text-v14, setting it to 788 \n",
      "[2024-01-04 18:11:30,265] p93154 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to discuss ideas for a new startup in the mobile gaming space. The success of companies like Angry Birds shows there is a lot of potential still untapped. \\nAction item: Research recent trends and growth in mobile gaming to identify opportunities\\n\\nB: I agree mobile gaming is hot right now. Have you thought about potential types of games we could develop? Should we try freemium or paid apps?\\nAction item: Outline pros and cons for freemium vs paid monetization models\\n\\nC: We should consider other business models too like in-game ads or sponsorships. The key is retaining users and driving high engagement.\\nAction item: Explore in-game ad networks and pricing\\nAction item: Brainstorm ideas to maximize user retention \\n\\nA: Those are good points. I also think we need to prototype game concepts quickly to validate demand before investing too heavily in development.\\nAction item: Define process for rapidly prototyping and testing game concepts  \\n\\nB: Yes, we could even use some AI tools now to auto-generate simple game artwork and mechanics. This can help speed up testing. \\nAction item: Evaluate AI-powered game prototyping tools to complement our development efforts\\n\\nC: Automating pieces through AI makes sense. Though we still need to ensure quality bar for any games we officially launch.\\n\\n</conversation>\",\n",
      "  \"completion\": \"<output>\\nA: \\n- Research mobile gaming markets and trends\\n- Define a process for rapidly prototyping game concepts \\n- Evaluate AI tools for game development\\n\\nB: \\n- Outline pros and cons for different monetization models\\n\\nC:\\n- Explore in-game ad networks and sponsorship opportunities\\n- Brainstorm ideas to improve user retention\\n- Evaluate AI tools that can assist with game development \\n\\n</output>\\n\\nWhoever is responsible for taking the action items (which from the tone of the conversation could be all of A, B and C) should work to turn these items into concrete steps or to-dos with timelines or deadlines where it makes sense. \\n\\nIs there anything else I can help you with regarding action items or any other part of the conversation?\",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 5.704833030700684,\n",
      "  \"completion_token_count\": 164,\n",
      "  \"prompt_token_count\": 788,\n",
      "  \"cost\": 0.0015099999999999998,\n",
      "  \"completion_word_count\": 123,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-04 18:11:30,265] p93154 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=anthropic_template_single_line_reason.txt, reps=3\n",
      "[2024-01-04 18:11:30,266] p93154 {544935498.py:35} INFO - going to summarize idx=4, file=data/raw/2/call_center_transcript_2_transcript.txt via anthropic.claude-instant-v1\n",
      "[2024-01-04 18:11:30,267] p93154 {544935498.py:38} INFO - read prompt template from data/prompts/anthropic_template_single_line_reason.txt\n",
      "[2024-01-04 18:11:30,269] p93154 {544935498.py:43} INFO - prompt for data/raw/2/call_center_transcript_2_transcript.txt has 775 tokens\n",
      "[2024-01-04 18:11:30,270] p93154 {528272729.py:4} INFO - model_id=anthropic.claude-instant-v1, prompt length is 3389 characters, 571 words\n",
      "[2024-01-04 18:11:31,502] p93154 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to discuss ideas for a new startup in the mobile gaming space. The success of companies like Angry Birds shows there is a lot of potential still untapped. \\nAction item: Research recent trends and growth in mobile gaming to identify opportunities\\n\\nB: I agree mobile gaming is hot right now. Have you thought about potential types of games we could develop? Should we try freemium or paid apps?\\nAction item: Outline pros and cons for freemium vs paid monetization models\\n\\nC: We should consider other business models too like in-game ads or sponsorships. The key is retaining users and driving high engagement.\\nAction item: Explore in-game ad networks and pricing\\nAction item: Brainstorm ideas to maximize user retention \\n\\nA: Those are good points. I also think we need to prototype game concepts quickly to validate demand before investing too heavily in development.\\nAction item: Define process for rapidly prototyping and testing game concepts  \\n\\nB: Yes, we could even use some AI tools now to auto-generate simple game artwork and mechanics. This can help speed up testing. \\nAction item: Evaluate AI-powered game prototyping tools to complement our development efforts\\n\\nC: Automating pieces through AI makes sense. Though we still need to ensure quality bar for any games we officially launch.\\n\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \" <output>\\nA: \\n- Research recent trends and growth in mobile gaming to identify opportunities\\n- Define process for rapidly prototyping and testing game concepts\\n\\nB:\\n- Outline pros and cons for freemium vs paid monetization models  \\n- Evaluate AI-powered game prototyping tools to complement our development efforts\\n\\nC:\\n- Explore in-game ad networks and pricing\\n- Brainstorm ideas to maximize user retention\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 1.230583906173706,\n",
      "  \"completion_token_count\": 99,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-04 18:11:31,503] p93154 {544935498.py:76} INFO - prompt_token_count is None for anthropic.claude-instant-v1, setting it to 775 \n",
      "[2024-01-04 18:11:31,504] p93154 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to discuss ideas for a new startup in the mobile gaming space. The success of companies like Angry Birds shows there is a lot of potential still untapped. \\nAction item: Research recent trends and growth in mobile gaming to identify opportunities\\n\\nB: I agree mobile gaming is hot right now. Have you thought about potential types of games we could develop? Should we try freemium or paid apps?\\nAction item: Outline pros and cons for freemium vs paid monetization models\\n\\nC: We should consider other business models too like in-game ads or sponsorships. The key is retaining users and driving high engagement.\\nAction item: Explore in-game ad networks and pricing\\nAction item: Brainstorm ideas to maximize user retention \\n\\nA: Those are good points. I also think we need to prototype game concepts quickly to validate demand before investing too heavily in development.\\nAction item: Define process for rapidly prototyping and testing game concepts  \\n\\nB: Yes, we could even use some AI tools now to auto-generate simple game artwork and mechanics. This can help speed up testing. \\nAction item: Evaluate AI-powered game prototyping tools to complement our development efforts\\n\\nC: Automating pieces through AI makes sense. Though we still need to ensure quality bar for any games we officially launch.\\n\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \"<output>\\nA: \\n- Research recent trends and growth in mobile gaming to identify opportunities\\n- Define process for rapidly prototyping and testing game concepts\\n\\nB:\\n- Outline pros and cons for freemium vs paid monetization models  \\n- Evaluate AI-powered game prototyping tools to complement our development efforts\\n\\nC:\\n- Explore in-game ad networks and pricing\\n- Brainstorm ideas to maximize user retention\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 1.230583906173706,\n",
      "  \"completion_token_count\": 99,\n",
      "  \"prompt_token_count\": 775,\n",
      "  \"cost\": 0.0018087399999999997,\n",
      "  \"completion_word_count\": 63,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-04 18:11:31,508] p93154 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=titan_template.txt, reps=3\n",
      "[2024-01-04 18:11:31,509] p93154 {544935498.py:35} INFO - going to summarize idx=4, file=data/raw/2/call_center_transcript_2_transcript.txt via amazon.titan-text-express-v1\n",
      "[2024-01-04 18:11:31,513] p93154 {544935498.py:38} INFO - read prompt template from data/prompts/titan_template.txt\n",
      "[2024-01-04 18:11:31,521] p93154 {544935498.py:43} INFO - prompt for data/raw/2/call_center_transcript_2_transcript.txt has 793 tokens\n",
      "[2024-01-04 18:11:31,522] p93154 {528272729.py:4} INFO - model_id=amazon.titan-text-express-v1, prompt length is 3472 characters, 588 words\n",
      "[2024-01-04 18:11:36,699] p93154 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nA: I wanted to discuss ideas for a new startup in the mobile gaming space. The success of companies like Angry Birds shows there is a lot of potential still untapped. \\nAction item: Research recent trends and growth in mobile gaming to identify opportunities\\n\\nB: I agree mobile gaming is hot right now. Have you thought about potential types of games we could develop? Should we try freemium or paid apps?\\nAction item: Outline pros and cons for freemium vs paid monetization models\\n\\nC: We should consider other business models too like in-game ads or sponsorships. The key is retaining users and driving high engagement.\\nAction item: Explore in-game ad networks and pricing\\nAction item: Brainstorm ideas to maximize user retention \\n\\nA: Those are good points. I also think we need to prototype game concepts quickly to validate demand before investing too heavily in development.\\nAction item: Define process for rapidly prototyping and testing game concepts  \\n\\nB: Yes, we could even use some AI tools now to auto-generate simple game artwork and mechanics. This can help speed up testing. \\nAction item: Evaluate AI-powered game prototyping tools to complement our development efforts\\n\\nC: Automating pieces through AI makes sense. Though we still need to ensure quality bar for any games we officially launch.\\n\\n</conversation>\",\n",
      "  \"completion\": \"\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Research recent trends and growth in mobile gaming to identify opportunities\\n- Outline pros and cons for freemium vs paid monetization models\\n- Explore in-game ad networks and pricing\\n- Brainstorm ideas to maximize user retention\\n- Define process for rapidly prototyping and testing game concepts\\n- Evaluate AI-powered game prototyping tools to complement our development efforts\\n\\nB:\\n- None explicitly stated\\n\\nC:\\n- Explore in-game ad networks and pricing\\n- Brainstorm ideas to maximize user retention\\n- Define process for rapidly prototyping and testing game concepts\\n- Evaluate AI-powered game prototyping tools to complement our development efforts\\n- Ensure quality bar for any games we officially launch\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 5.175840139389038,\n",
      "  \"completion_token_count\": 167,\n",
      "  \"prompt_token_count\": 793\n",
      "}\n",
      "[2024-01-04 18:11:36,701] p93154 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nA: I wanted to discuss ideas for a new startup in the mobile gaming space. The success of companies like Angry Birds shows there is a lot of potential still untapped. \\nAction item: Research recent trends and growth in mobile gaming to identify opportunities\\n\\nB: I agree mobile gaming is hot right now. Have you thought about potential types of games we could develop? Should we try freemium or paid apps?\\nAction item: Outline pros and cons for freemium vs paid monetization models\\n\\nC: We should consider other business models too like in-game ads or sponsorships. The key is retaining users and driving high engagement.\\nAction item: Explore in-game ad networks and pricing\\nAction item: Brainstorm ideas to maximize user retention \\n\\nA: Those are good points. I also think we need to prototype game concepts quickly to validate demand before investing too heavily in development.\\nAction item: Define process for rapidly prototyping and testing game concepts  \\n\\nB: Yes, we could even use some AI tools now to auto-generate simple game artwork and mechanics. This can help speed up testing. \\nAction item: Evaluate AI-powered game prototyping tools to complement our development efforts\\n\\nC: Automating pieces through AI makes sense. Though we still need to ensure quality bar for any games we officially launch.\\n\\n</conversation>\",\n",
      "  \"completion\": \"<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Research recent trends and growth in mobile gaming to identify opportunities\\n- Outline pros and cons for freemium vs paid monetization models\\n- Explore in-game ad networks and pricing\\n- Brainstorm ideas to maximize user retention\\n- Define process for rapidly prototyping and testing game concepts\\n- Evaluate AI-powered game prototyping tools to complement our development efforts\\n\\nB:\\n- None explicitly stated\\n\\nC:\\n- Explore in-game ad networks and pricing\\n- Brainstorm ideas to maximize user retention\\n- Define process for rapidly prototyping and testing game concepts\\n- Evaluate AI-powered game prototyping tools to complement our development efforts\\n- Ensure quality bar for any games we officially launch\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 5.175840139389038,\n",
      "  \"completion_token_count\": 167,\n",
      "  \"prompt_token_count\": 793,\n",
      "  \"cost\": 0.0009016,\n",
      "  \"completion_word_count\": 122,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-04 18:11:36,703] p93154 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=cohere_template.txt, reps=3\n",
      "[2024-01-04 18:11:36,704] p93154 {544935498.py:35} INFO - going to summarize idx=4, file=data/raw/2/call_center_transcript_2_transcript.txt via cohere.command-text-v14\n",
      "[2024-01-04 18:11:36,705] p93154 {544935498.py:38} INFO - read prompt template from data/prompts/cohere_template.txt\n",
      "[2024-01-04 18:11:36,712] p93154 {544935498.py:43} INFO - prompt for data/raw/2/call_center_transcript_2_transcript.txt has 788 tokens\n",
      "[2024-01-04 18:11:36,716] p93154 {528272729.py:4} INFO - model_id=cohere.command-text-v14, prompt length is 3467 characters, 587 words\n",
      "[2024-01-04 18:11:47,283] p93154 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to discuss ideas for a new startup in the mobile gaming space. The success of companies like Angry Birds shows there is a lot of potential still untapped. \\nAction item: Research recent trends and growth in mobile gaming to identify opportunities\\n\\nB: I agree mobile gaming is hot right now. Have you thought about potential types of games we could develop? Should we try freemium or paid apps?\\nAction item: Outline pros and cons for freemium vs paid monetization models\\n\\nC: We should consider other business models too like in-game ads or sponsorships. The key is retaining users and driving high engagement.\\nAction item: Explore in-game ad networks and pricing\\nAction item: Brainstorm ideas to maximize user retention \\n\\nA: Those are good points. I also think we need to prototype game concepts quickly to validate demand before investing too heavily in development.\\nAction item: Define process for rapidly prototyping and testing game concepts  \\n\\nB: Yes, we could even use some AI tools now to auto-generate simple game artwork and mechanics. This can help speed up testing. \\nAction item: Evaluate AI-powered game prototyping tools to complement our development efforts\\n\\nC: Automating pieces through AI makes sense. Though we still need to ensure quality bar for any games we officially launch.\\n\\n</conversation>\",\n",
      "  \"completion\": \" <output>\\nA: \\n- Research mobile gaming markets to identify gaps and opportunities\\n- Define a process for rapidly prototyping and testing game concepts \\n- Evaluate AI game prototyping tools \\n\\nB: \\n- Outline pros and cons of freemium vs paid app monetization\\n\\nC:\\n- Explore in-game ad networks and sponsorship opportunities\\n- Brainstorm ideas to improve user retention\\n- Evaluate tools to automate game development processes \\n\\n</output>\\n\\nWhoever you are, it seems you had a great conversation about a potential new startup in the mobile gaming industry! I've captured some concrete action items for each of you based on the discussion. \\n\\nA, you'll be researching the mobile gaming market to find gaps and opportunities, defining a rapid prototyping process, and evaluating AI tools for game development. \\n\\nB, your action items are to outline the pros and cons of different app monetization models. \\n\\nC, you'll be exploring in-game advertising and sponsorships, brainstorming ideas to improve user retention, and evaluating development automation tools. \\n\\nBest of luck with the startup! It sounds like you have a solid plan. \",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 10.565617799758911,\n",
      "  \"completion_token_count\": 232,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-04 18:11:47,283] p93154 {544935498.py:76} INFO - prompt_token_count is None for cohere.command-text-v14, setting it to 788 \n",
      "[2024-01-04 18:11:47,286] p93154 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to discuss ideas for a new startup in the mobile gaming space. The success of companies like Angry Birds shows there is a lot of potential still untapped. \\nAction item: Research recent trends and growth in mobile gaming to identify opportunities\\n\\nB: I agree mobile gaming is hot right now. Have you thought about potential types of games we could develop? Should we try freemium or paid apps?\\nAction item: Outline pros and cons for freemium vs paid monetization models\\n\\nC: We should consider other business models too like in-game ads or sponsorships. The key is retaining users and driving high engagement.\\nAction item: Explore in-game ad networks and pricing\\nAction item: Brainstorm ideas to maximize user retention \\n\\nA: Those are good points. I also think we need to prototype game concepts quickly to validate demand before investing too heavily in development.\\nAction item: Define process for rapidly prototyping and testing game concepts  \\n\\nB: Yes, we could even use some AI tools now to auto-generate simple game artwork and mechanics. This can help speed up testing. \\nAction item: Evaluate AI-powered game prototyping tools to complement our development efforts\\n\\nC: Automating pieces through AI makes sense. Though we still need to ensure quality bar for any games we officially launch.\\n\\n</conversation>\",\n",
      "  \"completion\": \"<output>\\nA: \\n- Research mobile gaming markets to identify gaps and opportunities\\n- Define a process for rapidly prototyping and testing game concepts \\n- Evaluate AI game prototyping tools \\n\\nB: \\n- Outline pros and cons of freemium vs paid app monetization\\n\\nC:\\n- Explore in-game ad networks and sponsorship opportunities\\n- Brainstorm ideas to improve user retention\\n- Evaluate tools to automate game development processes \\n\\n</output>\\n\\nWhoever you are, it seems you had a great conversation about a potential new startup in the mobile gaming industry! I've captured some concrete action items for each of you based on the discussion. \\n\\nA, you'll be researching the mobile gaming market to find gaps and opportunities, defining a rapid prototyping process, and evaluating AI tools for game development. \\n\\nB, your action items are to outline the pros and cons of different app monetization models. \\n\\nC, you'll be exploring in-game advertising and sponsorships, brainstorming ideas to improve user retention, and evaluating development automation tools. \\n\\nBest of luck with the startup! It sounds like you have a solid plan.\",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 10.565617799758911,\n",
      "  \"completion_token_count\": 232,\n",
      "  \"prompt_token_count\": 788,\n",
      "  \"cost\": 0.001646,\n",
      "  \"completion_word_count\": 174,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from json import JSONEncoder\n",
    "import re\n",
    "from pathlib import Path\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "class CustomJSONEncoder(JSONEncoder):\n",
    "    def default(self, o):\n",
    "        if isinstance(o, Exception):\n",
    "            return {'error_type': o.__class__.__name__, 'error_message': str(o)}\n",
    "        return JSONEncoder.default(self, o)\n",
    "\n",
    "for idx, tf in enumerate(transcript_files):\n",
    "    transcript = Path(tf).read_text()\n",
    "    fname = os.path.basename(tf)\n",
    "    file_id = \"_\".join(fname.split('_')[:-1])\n",
    "    golden_summary_fpath = os.path.join(config['dir']['raw'], '0', \"example_prompt_transcript_golden_summary.txt\")\n",
    "    logger.info(f\"idx={idx}, tf={tf}, file_id={file_id}, golden_summary_fpath={golden_summary_fpath}\")\n",
    "    # for each experiment\n",
    "    for experiment in config['experiments']:\n",
    "        exp_name = experiment['name']        \n",
    "        model_list = experiment['model_list']\n",
    "        reps = experiment['reps']        \n",
    "        for rep in range(reps):\n",
    "            for model_info in model_list:\n",
    "                model_name = model_info['model']\n",
    "                prompt_template_fname = model_info['prompt_template']\n",
    "                logger.info(f\"exp_name={exp_name}, prompt_template={prompt_template_fname}, reps={reps}\")\n",
    "                model = config['bedrock_models'].get(model_name)\n",
    "                if model is None:\n",
    "                    logger.error(f\"model={model_name} not found in bedrock_models\")\n",
    "                    continue\n",
    "                model['model_id'] = model_name\n",
    "                logger.info(f\"going to summarize idx={idx}, file={tf} via {model['model_id']}\")\n",
    "                fpath = os.path.join(config['dir']['prompts'], prompt_template_fname)\n",
    "                prompt_template = Path(fpath).read_text()\n",
    "                logger.info(f\"read prompt template from {fpath}\")\n",
    "\n",
    "                prompt = prompt_template.format(transcript)\n",
    "                # print(prompt)\n",
    "                prompt_token_count = count_tokens(prompt)\n",
    "                logger.info(f\"prompt for {tf} has {prompt_token_count} tokens\")\n",
    "\n",
    "                if (prompt_token_count + 125) > model['context_length']:\n",
    "                    logger.info(f\"cannot summarize {tf} with {model['model_id']} as prompt length {prompt_token_count} > {model['context_length']}\")\n",
    "                    continue\n",
    "                very_large_prompt = prompt_token_count > config['prompt']['very_large_prompt']['threshold']\n",
    "                inference_parameters = config['inference_params'][model['inference_param_set']]\n",
    "                \n",
    "                resp = get_text_response_from_bedrock(prompt, inference_parameters, model['model_id'])\n",
    "                if resp['exception'] is not None:\n",
    "                    logger.error(f\"exception occurred for {tf}, model_id={model['model_id']}\")\n",
    "                    e = resp['exception']\n",
    "                    if e.response['Error']['Code'] == 'ThrottlingException':\n",
    "                        retries = 0\n",
    "                        while True:\n",
    "                            retries += 1\n",
    "                            if very_large_prompt is True:\n",
    "                                time.sleep(retries * config['prompt']['very_large_prompt']['sleep_time'])\n",
    "                            else:\n",
    "                                time.sleep(retries * config['prompt']['normal_prompt']['sleep_time'])\n",
    "                            logger.error(f\"going to retry for {tf}, model_id={model['model_id']}, retries={retries}\")\n",
    "                            resp = get_text_response_from_bedrock(prompt, inference_parameters, model['model_id'])\n",
    "                            if resp['exception'] is not None:\n",
    "                                logger.error(f\"exception occurred for {tf}, model_id={model['model_id']} on retry as well\")\n",
    "                                if retries >= config['max_retries']:\n",
    "                                    logger.error(f\"retries={retries} >= configured max retries={config['max_retries']}, giving up\")\n",
    "                                    break\n",
    "                            else:\n",
    "                                logger.info(f\"retry succeeded, retries={retries}\")\n",
    "                                break\n",
    "\n",
    "                if resp['exception'] is None:\n",
    "                    if resp['prompt_token_count'] is None:\n",
    "                        logger.info(f\"prompt_token_count is None for {model_name}, setting it to {prompt_token_count} \")\n",
    "                        resp['prompt_token_count'] = prompt_token_count\n",
    "                    resp['completion'] = re.sub(r\"<reason>|</reason>\", \"\", resp['completion']).strip()\n",
    "                    resp['completion'] = re.sub(r\"<reasons>|</reasons>\", \"\", resp['completion']).strip()\n",
    "                    dir_path = os.path.join(config['dir']['completions'], exp_name, file_id)\n",
    "                    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "                    fpath = os.path.join(dir_path, f\"{file_id}_{model['model_id']}_rep{rep+1}.txt\")\n",
    "                    Path(fpath).write_text(resp['completion'])\n",
    "\n",
    "                    if Path(golden_summary_fpath).is_file() is True:\n",
    "                        golden_summary = Path(golden_summary_fpath).read_text()\n",
    "                        # rouge score\n",
    "                        resp['rouge_l_f1_score'] = get_rouge_l_score(golden_summary, resp['completion'])\n",
    "                        # cosine similarity\n",
    "                        resp['cosine_similarity'] = get_cosine_similarity(golden_summary, resp['completion'])\n",
    "                    resp['cost'] = model['prompt_token_pricing_per_million'] * (resp['prompt_token_count'] / 1000000) + \\\n",
    "                        model['completion_token_pricing_per_million'] * (resp['completion_token_count'] / 1000000)\n",
    "                    \n",
    "                    resp['completion_word_count'] = len(resp['completion'].split())\n",
    "                    resp['experiment'] = exp_name\n",
    "                    \n",
    "                logger.info(json.dumps(resp, indent=2))\n",
    "                dir_path = os.path.join(config['dir']['metrics'], exp_name, file_id)\n",
    "                os.makedirs(dir_path, exist_ok=True)\n",
    "                fpath = os.path.join(dir_path, f\"{file_id}_{model['model_id']}_rep{rep+1}.json\")\n",
    "                Path(fpath).write_text(json.dumps(resp, cls=CustomJSONEncoder, indent=2))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
