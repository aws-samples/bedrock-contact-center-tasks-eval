{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "import yaml\n",
    "import time\n",
    "import glob\n",
    "import logging\n",
    "import pandas as pd\n",
    "from typing import Dict\n",
    "from pathlib import Path\n",
    "from tokenizer_utils import count_tokens\n",
    "from bedrock_utils import get_bedrock_client\n",
    "from utils import  (\n",
    "    get_rouge_l_score,\n",
    "    get_cosine_similarity,\n",
    "    parse_model_response,\n",
    "    is_amazon_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global constants\n",
    "CONFIG_FILE_PATH = \"config.yaml\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-12 13:56:22,179] p31920 {2625127137.py:5} INFO - config read from config.yaml -> {\n",
      "  \"app_name\": \"contact-center-transcript-summarization\",\n",
      "  \"aws\": {\n",
      "    \"region\": \"us-east-1\",\n",
      "    \"sagemaker_execution_role\": \"Admin\"\n",
      "  },\n",
      "  \"dir\": {\n",
      "    \"data\": \"data\",\n",
      "    \"raw\": \"data/raw\",\n",
      "    \"golden\": \"data/raw/golden\",\n",
      "    \"prompts\": \"data/prompts\",\n",
      "    \"models\": \"data/models\",\n",
      "    \"metrics\": \"data/metrics\",\n",
      "    \"completions\": \"data/completions\",\n",
      "    \"async_completions\": \"data/async_completions\"\n",
      "  },\n",
      "  \"data\": {\n",
      "    \"raw_data_file\": \"data.csv\",\n",
      "    \"golden_transcript\": \"data/raw/golden/transcript.txt\",\n",
      "    \"golden_transcript_summary\": \"data/raw/golden/summary.txt\"\n",
      "  },\n",
      "  \"prompt\": {\n",
      "    \"very_large_prompt\": {\n",
      "      \"sleep_time\": 180,\n",
      "      \"threshold\": 70000\n",
      "    },\n",
      "    \"normal_prompt\": {\n",
      "      \"sleep_time\": 60\n",
      "    }\n",
      "  },\n",
      "  \"max_retries\": 3,\n",
      "  \"desired_word_count_for_summary\": 80,\n",
      "  \"experiments\": [\n",
      "    {\n",
      "      \"name\": \"single-line-reason\",\n",
      "      \"prompt_template\": null,\n",
      "      \"reps\": 3,\n",
      "      \"model_list\": [\n",
      "        {\n",
      "          \"model\": \"amazon.titan-text-express-v1\",\n",
      "          \"prompt_template\": \"titan_template.txt\",\n",
      "          \"concurrency_levels\": [\n",
      "            1,\n",
      "            2,\n",
      "            3\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"model\": \"anthropic.claude-instant-v1\",\n",
      "          \"prompt_template\": \"anthropic_template_single_line_reason.txt\",\n",
      "          \"concurrency_levels\": [\n",
      "            1,\n",
      "            2,\n",
      "            3\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"model\": \"cohere.command-text-v14\",\n",
      "          \"prompt_template\": \"cohere_template.txt\",\n",
      "          \"concurrency_levels\": [\n",
      "            1,\n",
      "            2,\n",
      "            3\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"bedrock_models\": {\n",
      "    \"cohere.command-text-v14\": {\n",
      "      \"context_length\": 4000,\n",
      "      \"prompt_token_pricing_per_million\": 1.5,\n",
      "      \"completion_token_pricing_per_million\": 2.0,\n",
      "      \"inference_param_set\": \"cohere\"\n",
      "    },\n",
      "    \"amazon.titan-text-express-v1\": {\n",
      "      \"context_length\": 8000,\n",
      "      \"prompt_token_pricing_per_million\": 0.8,\n",
      "      \"completion_token_pricing_per_million\": 1.6,\n",
      "      \"inference_param_set\": \"titan\"\n",
      "    },\n",
      "    \"anthropic.claude-v2:1\": {\n",
      "      \"context_length\": 100000,\n",
      "      \"prompt_token_pricing_per_million\": 8,\n",
      "      \"completion_token_pricing_per_million\": 24,\n",
      "      \"inference_param_set\": \"claude\"\n",
      "    },\n",
      "    \"anthropic.claude-instant-v1\": {\n",
      "      \"context_length\": 9000,\n",
      "      \"prompt_token_pricing_per_million\": 1.63,\n",
      "      \"completion_token_pricing_per_million\": 5.51,\n",
      "      \"inference_param_set\": \"claude\"\n",
      "    }\n",
      "  },\n",
      "  \"inference_params\": {\n",
      "    \"claude\": {\n",
      "      \"max_tokens_to_sample\": 512,\n",
      "      \"temperature\": 0.1,\n",
      "      \"top_k\": 250,\n",
      "      \"top_p\": 0.5,\n",
      "      \"stop_sequences\": [],\n",
      "      \"anthropic_version\": \"bedrock-2023-05-31\"\n",
      "    },\n",
      "    \"titan\": {\n",
      "      \"maxTokenCount\": 512,\n",
      "      \"stopSequences\": [],\n",
      "      \"temperature\": 0.1,\n",
      "      \"topP\": 0.9\n",
      "    },\n",
      "    \"cohere\": {\n",
      "      \"max_tokens\": 512,\n",
      "      \"temperature\": 0.1,\n",
      "      \"p\": 0.9,\n",
      "      \"k\": 0\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# read the config yaml file\n",
    "fpath = CONFIG_FILE_PATH\n",
    "with open(fpath, 'r') as yaml_in:\n",
    "    config = yaml.safe_load(yaml_in)\n",
    "logger.info(f\"config read from {fpath} -> {json.dumps(config, indent=2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-12 13:56:23,043] p31920 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new client\n",
      "  Using region: None\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock-runtime(https://bedrock-runtime.us-east-1.amazonaws.com)\n"
     ]
    }
   ],
   "source": [
    "bedrock_client = get_bedrock_client()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-12 13:56:23,670] p31920 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new client\n",
      "  Using region: None\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock(https://bedrock.us-east-1.amazonaws.com)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelArn</th>\n",
       "      <th>modelId</th>\n",
       "      <th>modelName</th>\n",
       "      <th>providerName</th>\n",
       "      <th>inputModalities</th>\n",
       "      <th>outputModalities</th>\n",
       "      <th>responseStreamingSupported</th>\n",
       "      <th>customizationsSupported</th>\n",
       "      <th>inferenceTypesSupported</th>\n",
       "      <th>modelLifecycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-tg1-large</td>\n",
       "      <td>Titan Text Large</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-e1t-medium</td>\n",
       "      <td>Titan Text Embeddings</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[EMBEDDING]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'LEGACY'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-image-generator-v1:0</td>\n",
       "      <td>Titan Image Generator G1</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT, IMAGE]</td>\n",
       "      <td>[IMAGE]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[FINE_TUNING]</td>\n",
       "      <td>[ON_DEMAND, PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-image-generator-v1</td>\n",
       "      <td>Titan Image Generator G1</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT, IMAGE]</td>\n",
       "      <td>[IMAGE]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-embed-g1-text-02</td>\n",
       "      <td>Titan Text Embeddings v2</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[EMBEDDING]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-text-lite-v1:0:4k</td>\n",
       "      <td>Titan Text G1 - Lite</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[FINE_TUNING, CONTINUED_PRE_TRAINING]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-text-lite-v1</td>\n",
       "      <td>Titan Text G1 - Lite</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-text-express-v1:0:8k</td>\n",
       "      <td>Titan Text G1 - Express</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[FINE_TUNING, CONTINUED_PRE_TRAINING]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-text-express-v1</td>\n",
       "      <td>Titan Text G1 - Express</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-embed-text-v1:2:8k</td>\n",
       "      <td>Titan Embeddings G1 - Text</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[EMBEDDING]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-embed-text-v1</td>\n",
       "      <td>Titan Embeddings G1 - Text</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[EMBEDDING]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-embed-image-v1:0</td>\n",
       "      <td>Titan Multimodal Embeddings G1</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT, IMAGE]</td>\n",
       "      <td>[EMBEDDING]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[FINE_TUNING]</td>\n",
       "      <td>[ON_DEMAND, PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-embed-image-v1</td>\n",
       "      <td>Titan Multimodal Embeddings G1</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT, IMAGE]</td>\n",
       "      <td>[EMBEDDING]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/st...</td>\n",
       "      <td>stability.stable-diffusion-xl</td>\n",
       "      <td>SDXL 0.8</td>\n",
       "      <td>Stability AI</td>\n",
       "      <td>[TEXT, IMAGE]</td>\n",
       "      <td>[IMAGE]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/st...</td>\n",
       "      <td>stability.stable-diffusion-xl-v0</td>\n",
       "      <td>SDXL 0.8</td>\n",
       "      <td>Stability AI</td>\n",
       "      <td>[TEXT, IMAGE]</td>\n",
       "      <td>[IMAGE]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/st...</td>\n",
       "      <td>stability.stable-diffusion-xl-v1:0</td>\n",
       "      <td>SDXL 1.0</td>\n",
       "      <td>Stability AI</td>\n",
       "      <td>[TEXT, IMAGE]</td>\n",
       "      <td>[IMAGE]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/st...</td>\n",
       "      <td>stability.stable-diffusion-xl-v1</td>\n",
       "      <td>SDXL 1.0</td>\n",
       "      <td>Stability AI</td>\n",
       "      <td>[TEXT, IMAGE]</td>\n",
       "      <td>[IMAGE]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/ai...</td>\n",
       "      <td>ai21.j2-grande-instruct</td>\n",
       "      <td>J2 Grande Instruct</td>\n",
       "      <td>AI21 Labs</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/ai...</td>\n",
       "      <td>ai21.j2-jumbo-instruct</td>\n",
       "      <td>J2 Jumbo Instruct</td>\n",
       "      <td>AI21 Labs</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/ai...</td>\n",
       "      <td>ai21.j2-mid</td>\n",
       "      <td>Jurassic-2 Mid</td>\n",
       "      <td>AI21 Labs</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/ai...</td>\n",
       "      <td>ai21.j2-mid-v1</td>\n",
       "      <td>Jurassic-2 Mid</td>\n",
       "      <td>AI21 Labs</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/ai...</td>\n",
       "      <td>ai21.j2-ultra</td>\n",
       "      <td>Jurassic-2 Ultra</td>\n",
       "      <td>AI21 Labs</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/ai...</td>\n",
       "      <td>ai21.j2-ultra-v1</td>\n",
       "      <td>Jurassic-2 Ultra</td>\n",
       "      <td>AI21 Labs</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/an...</td>\n",
       "      <td>anthropic.claude-instant-v1:2:100k</td>\n",
       "      <td>Claude Instant</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/an...</td>\n",
       "      <td>anthropic.claude-instant-v1</td>\n",
       "      <td>Claude Instant</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/an...</td>\n",
       "      <td>anthropic.claude-v1</td>\n",
       "      <td>Claude</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'LEGACY'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/an...</td>\n",
       "      <td>anthropic.claude-v2:0:18k</td>\n",
       "      <td>Claude</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/an...</td>\n",
       "      <td>anthropic.claude-v2:0:100k</td>\n",
       "      <td>Claude</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/an...</td>\n",
       "      <td>anthropic.claude-v2:1:18k</td>\n",
       "      <td>Claude</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/an...</td>\n",
       "      <td>anthropic.claude-v2:1:200k</td>\n",
       "      <td>Claude</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/an...</td>\n",
       "      <td>anthropic.claude-v2:1</td>\n",
       "      <td>Claude</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/an...</td>\n",
       "      <td>anthropic.claude-v2</td>\n",
       "      <td>Claude</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/co...</td>\n",
       "      <td>cohere.command-text-v14:7:4k</td>\n",
       "      <td>Command</td>\n",
       "      <td>Cohere</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[FINE_TUNING]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/co...</td>\n",
       "      <td>cohere.command-text-v14</td>\n",
       "      <td>Command</td>\n",
       "      <td>Cohere</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/co...</td>\n",
       "      <td>cohere.command-light-text-v14:7:4k</td>\n",
       "      <td>Command Light</td>\n",
       "      <td>Cohere</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[FINE_TUNING]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/co...</td>\n",
       "      <td>cohere.command-light-text-v14</td>\n",
       "      <td>Command Light</td>\n",
       "      <td>Cohere</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/co...</td>\n",
       "      <td>cohere.embed-english-v3</td>\n",
       "      <td>Embed English</td>\n",
       "      <td>Cohere</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[EMBEDDING]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/co...</td>\n",
       "      <td>cohere.embed-multilingual-v3</td>\n",
       "      <td>Embed Multilingual</td>\n",
       "      <td>Cohere</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[EMBEDDING]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/me...</td>\n",
       "      <td>meta.llama2-13b-chat-v1:0:4k</td>\n",
       "      <td>Llama 2 Chat 13B</td>\n",
       "      <td>Meta</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/me...</td>\n",
       "      <td>meta.llama2-13b-chat-v1</td>\n",
       "      <td>Llama 2 Chat 13B</td>\n",
       "      <td>Meta</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/me...</td>\n",
       "      <td>meta.llama2-70b-chat-v1:0:4k</td>\n",
       "      <td>Llama 2 Chat 70B</td>\n",
       "      <td>Meta</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/me...</td>\n",
       "      <td>meta.llama2-70b-chat-v1</td>\n",
       "      <td>Llama 2 Chat 70B</td>\n",
       "      <td>Meta</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/me...</td>\n",
       "      <td>meta.llama2-13b-v1:0:4k</td>\n",
       "      <td>Llama 2 13B</td>\n",
       "      <td>Meta</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[FINE_TUNING]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/me...</td>\n",
       "      <td>meta.llama2-13b-v1</td>\n",
       "      <td>Llama 2 13B</td>\n",
       "      <td>Meta</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/me...</td>\n",
       "      <td>meta.llama2-70b-v1:0:4k</td>\n",
       "      <td>Llama 2 70B</td>\n",
       "      <td>Meta</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[FINE_TUNING]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/me...</td>\n",
       "      <td>meta.llama2-70b-v1</td>\n",
       "      <td>Llama 2 70B</td>\n",
       "      <td>Meta</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             modelArn  \\\n",
       "0   arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "1   arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "2   arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "3   arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "4   arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "5   arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "6   arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "7   arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "8   arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "9   arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "10  arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "11  arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "12  arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "13  arn:aws:bedrock:us-east-1::foundation-model/st...   \n",
       "14  arn:aws:bedrock:us-east-1::foundation-model/st...   \n",
       "15  arn:aws:bedrock:us-east-1::foundation-model/st...   \n",
       "16  arn:aws:bedrock:us-east-1::foundation-model/st...   \n",
       "17  arn:aws:bedrock:us-east-1::foundation-model/ai...   \n",
       "18  arn:aws:bedrock:us-east-1::foundation-model/ai...   \n",
       "19  arn:aws:bedrock:us-east-1::foundation-model/ai...   \n",
       "20  arn:aws:bedrock:us-east-1::foundation-model/ai...   \n",
       "21  arn:aws:bedrock:us-east-1::foundation-model/ai...   \n",
       "22  arn:aws:bedrock:us-east-1::foundation-model/ai...   \n",
       "23  arn:aws:bedrock:us-east-1::foundation-model/an...   \n",
       "24  arn:aws:bedrock:us-east-1::foundation-model/an...   \n",
       "25  arn:aws:bedrock:us-east-1::foundation-model/an...   \n",
       "26  arn:aws:bedrock:us-east-1::foundation-model/an...   \n",
       "27  arn:aws:bedrock:us-east-1::foundation-model/an...   \n",
       "28  arn:aws:bedrock:us-east-1::foundation-model/an...   \n",
       "29  arn:aws:bedrock:us-east-1::foundation-model/an...   \n",
       "30  arn:aws:bedrock:us-east-1::foundation-model/an...   \n",
       "31  arn:aws:bedrock:us-east-1::foundation-model/an...   \n",
       "32  arn:aws:bedrock:us-east-1::foundation-model/co...   \n",
       "33  arn:aws:bedrock:us-east-1::foundation-model/co...   \n",
       "34  arn:aws:bedrock:us-east-1::foundation-model/co...   \n",
       "35  arn:aws:bedrock:us-east-1::foundation-model/co...   \n",
       "36  arn:aws:bedrock:us-east-1::foundation-model/co...   \n",
       "37  arn:aws:bedrock:us-east-1::foundation-model/co...   \n",
       "38  arn:aws:bedrock:us-east-1::foundation-model/me...   \n",
       "39  arn:aws:bedrock:us-east-1::foundation-model/me...   \n",
       "40  arn:aws:bedrock:us-east-1::foundation-model/me...   \n",
       "41  arn:aws:bedrock:us-east-1::foundation-model/me...   \n",
       "42  arn:aws:bedrock:us-east-1::foundation-model/me...   \n",
       "43  arn:aws:bedrock:us-east-1::foundation-model/me...   \n",
       "44  arn:aws:bedrock:us-east-1::foundation-model/me...   \n",
       "45  arn:aws:bedrock:us-east-1::foundation-model/me...   \n",
       "\n",
       "                               modelId                       modelName  \\\n",
       "0               amazon.titan-tg1-large                Titan Text Large   \n",
       "1              amazon.titan-e1t-medium           Titan Text Embeddings   \n",
       "2    amazon.titan-image-generator-v1:0        Titan Image Generator G1   \n",
       "3      amazon.titan-image-generator-v1        Titan Image Generator G1   \n",
       "4        amazon.titan-embed-g1-text-02        Titan Text Embeddings v2   \n",
       "5       amazon.titan-text-lite-v1:0:4k            Titan Text G1 - Lite   \n",
       "6            amazon.titan-text-lite-v1            Titan Text G1 - Lite   \n",
       "7    amazon.titan-text-express-v1:0:8k         Titan Text G1 - Express   \n",
       "8         amazon.titan-text-express-v1         Titan Text G1 - Express   \n",
       "9      amazon.titan-embed-text-v1:2:8k      Titan Embeddings G1 - Text   \n",
       "10          amazon.titan-embed-text-v1      Titan Embeddings G1 - Text   \n",
       "11       amazon.titan-embed-image-v1:0  Titan Multimodal Embeddings G1   \n",
       "12         amazon.titan-embed-image-v1  Titan Multimodal Embeddings G1   \n",
       "13       stability.stable-diffusion-xl                        SDXL 0.8   \n",
       "14    stability.stable-diffusion-xl-v0                        SDXL 0.8   \n",
       "15  stability.stable-diffusion-xl-v1:0                        SDXL 1.0   \n",
       "16    stability.stable-diffusion-xl-v1                        SDXL 1.0   \n",
       "17             ai21.j2-grande-instruct              J2 Grande Instruct   \n",
       "18              ai21.j2-jumbo-instruct               J2 Jumbo Instruct   \n",
       "19                         ai21.j2-mid                  Jurassic-2 Mid   \n",
       "20                      ai21.j2-mid-v1                  Jurassic-2 Mid   \n",
       "21                       ai21.j2-ultra                Jurassic-2 Ultra   \n",
       "22                    ai21.j2-ultra-v1                Jurassic-2 Ultra   \n",
       "23  anthropic.claude-instant-v1:2:100k                  Claude Instant   \n",
       "24         anthropic.claude-instant-v1                  Claude Instant   \n",
       "25                 anthropic.claude-v1                          Claude   \n",
       "26           anthropic.claude-v2:0:18k                          Claude   \n",
       "27          anthropic.claude-v2:0:100k                          Claude   \n",
       "28           anthropic.claude-v2:1:18k                          Claude   \n",
       "29          anthropic.claude-v2:1:200k                          Claude   \n",
       "30               anthropic.claude-v2:1                          Claude   \n",
       "31                 anthropic.claude-v2                          Claude   \n",
       "32        cohere.command-text-v14:7:4k                         Command   \n",
       "33             cohere.command-text-v14                         Command   \n",
       "34  cohere.command-light-text-v14:7:4k                   Command Light   \n",
       "35       cohere.command-light-text-v14                   Command Light   \n",
       "36             cohere.embed-english-v3                   Embed English   \n",
       "37        cohere.embed-multilingual-v3              Embed Multilingual   \n",
       "38        meta.llama2-13b-chat-v1:0:4k                Llama 2 Chat 13B   \n",
       "39             meta.llama2-13b-chat-v1                Llama 2 Chat 13B   \n",
       "40        meta.llama2-70b-chat-v1:0:4k                Llama 2 Chat 70B   \n",
       "41             meta.llama2-70b-chat-v1                Llama 2 Chat 70B   \n",
       "42             meta.llama2-13b-v1:0:4k                     Llama 2 13B   \n",
       "43                  meta.llama2-13b-v1                     Llama 2 13B   \n",
       "44             meta.llama2-70b-v1:0:4k                     Llama 2 70B   \n",
       "45                  meta.llama2-70b-v1                     Llama 2 70B   \n",
       "\n",
       "    providerName inputModalities outputModalities responseStreamingSupported  \\\n",
       "0         Amazon          [TEXT]           [TEXT]                       True   \n",
       "1         Amazon          [TEXT]      [EMBEDDING]                        NaN   \n",
       "2         Amazon   [TEXT, IMAGE]          [IMAGE]                        NaN   \n",
       "3         Amazon   [TEXT, IMAGE]          [IMAGE]                        NaN   \n",
       "4         Amazon          [TEXT]      [EMBEDDING]                        NaN   \n",
       "5         Amazon          [TEXT]           [TEXT]                       True   \n",
       "6         Amazon          [TEXT]           [TEXT]                       True   \n",
       "7         Amazon          [TEXT]           [TEXT]                       True   \n",
       "8         Amazon          [TEXT]           [TEXT]                       True   \n",
       "9         Amazon          [TEXT]      [EMBEDDING]                      False   \n",
       "10        Amazon          [TEXT]      [EMBEDDING]                      False   \n",
       "11        Amazon   [TEXT, IMAGE]      [EMBEDDING]                        NaN   \n",
       "12        Amazon   [TEXT, IMAGE]      [EMBEDDING]                        NaN   \n",
       "13  Stability AI   [TEXT, IMAGE]          [IMAGE]                        NaN   \n",
       "14  Stability AI   [TEXT, IMAGE]          [IMAGE]                        NaN   \n",
       "15  Stability AI   [TEXT, IMAGE]          [IMAGE]                        NaN   \n",
       "16  Stability AI   [TEXT, IMAGE]          [IMAGE]                        NaN   \n",
       "17     AI21 Labs          [TEXT]           [TEXT]                      False   \n",
       "18     AI21 Labs          [TEXT]           [TEXT]                      False   \n",
       "19     AI21 Labs          [TEXT]           [TEXT]                      False   \n",
       "20     AI21 Labs          [TEXT]           [TEXT]                      False   \n",
       "21     AI21 Labs          [TEXT]           [TEXT]                      False   \n",
       "22     AI21 Labs          [TEXT]           [TEXT]                      False   \n",
       "23     Anthropic          [TEXT]           [TEXT]                       True   \n",
       "24     Anthropic          [TEXT]           [TEXT]                       True   \n",
       "25     Anthropic          [TEXT]           [TEXT]                       True   \n",
       "26     Anthropic          [TEXT]           [TEXT]                       True   \n",
       "27     Anthropic          [TEXT]           [TEXT]                       True   \n",
       "28     Anthropic          [TEXT]           [TEXT]                       True   \n",
       "29     Anthropic          [TEXT]           [TEXT]                       True   \n",
       "30     Anthropic          [TEXT]           [TEXT]                       True   \n",
       "31     Anthropic          [TEXT]           [TEXT]                       True   \n",
       "32        Cohere          [TEXT]           [TEXT]                       True   \n",
       "33        Cohere          [TEXT]           [TEXT]                       True   \n",
       "34        Cohere          [TEXT]           [TEXT]                       True   \n",
       "35        Cohere          [TEXT]           [TEXT]                       True   \n",
       "36        Cohere          [TEXT]      [EMBEDDING]                      False   \n",
       "37        Cohere          [TEXT]      [EMBEDDING]                      False   \n",
       "38          Meta          [TEXT]           [TEXT]                       True   \n",
       "39          Meta          [TEXT]           [TEXT]                       True   \n",
       "40          Meta          [TEXT]           [TEXT]                       True   \n",
       "41          Meta          [TEXT]           [TEXT]                       True   \n",
       "42          Meta          [TEXT]           [TEXT]                       True   \n",
       "43          Meta          [TEXT]           [TEXT]                       True   \n",
       "44          Meta          [TEXT]           [TEXT]                       True   \n",
       "45          Meta          [TEXT]           [TEXT]                       True   \n",
       "\n",
       "                  customizationsSupported   inferenceTypesSupported  \\\n",
       "0                                      []               [ON_DEMAND]   \n",
       "1                                      []               [ON_DEMAND]   \n",
       "2                           [FINE_TUNING]  [ON_DEMAND, PROVISIONED]   \n",
       "3                                      []               [ON_DEMAND]   \n",
       "4                                      []               [ON_DEMAND]   \n",
       "5   [FINE_TUNING, CONTINUED_PRE_TRAINING]             [PROVISIONED]   \n",
       "6                                      []               [ON_DEMAND]   \n",
       "7   [FINE_TUNING, CONTINUED_PRE_TRAINING]             [PROVISIONED]   \n",
       "8                                      []               [ON_DEMAND]   \n",
       "9                                      []             [PROVISIONED]   \n",
       "10                                     []               [ON_DEMAND]   \n",
       "11                          [FINE_TUNING]  [ON_DEMAND, PROVISIONED]   \n",
       "12                                     []               [ON_DEMAND]   \n",
       "13                                     []               [ON_DEMAND]   \n",
       "14                                     []               [ON_DEMAND]   \n",
       "15                                     []             [PROVISIONED]   \n",
       "16                                     []               [ON_DEMAND]   \n",
       "17                                     []               [ON_DEMAND]   \n",
       "18                                     []               [ON_DEMAND]   \n",
       "19                                     []               [ON_DEMAND]   \n",
       "20                                     []               [ON_DEMAND]   \n",
       "21                                     []               [ON_DEMAND]   \n",
       "22                                     []               [ON_DEMAND]   \n",
       "23                                     []             [PROVISIONED]   \n",
       "24                                     []               [ON_DEMAND]   \n",
       "25                                     []               [ON_DEMAND]   \n",
       "26                                     []             [PROVISIONED]   \n",
       "27                                     []             [PROVISIONED]   \n",
       "28                                     []             [PROVISIONED]   \n",
       "29                                     []             [PROVISIONED]   \n",
       "30                                     []               [ON_DEMAND]   \n",
       "31                                     []               [ON_DEMAND]   \n",
       "32                          [FINE_TUNING]             [PROVISIONED]   \n",
       "33                                     []               [ON_DEMAND]   \n",
       "34                          [FINE_TUNING]             [PROVISIONED]   \n",
       "35                                     []               [ON_DEMAND]   \n",
       "36                                     []               [ON_DEMAND]   \n",
       "37                                     []               [ON_DEMAND]   \n",
       "38                                     []             [PROVISIONED]   \n",
       "39                                     []               [ON_DEMAND]   \n",
       "40                                     []                        []   \n",
       "41                                     []               [ON_DEMAND]   \n",
       "42                          [FINE_TUNING]                        []   \n",
       "43                                     []                        []   \n",
       "44                          [FINE_TUNING]                        []   \n",
       "45                                     []                        []   \n",
       "\n",
       "          modelLifecycle  \n",
       "0   {'status': 'ACTIVE'}  \n",
       "1   {'status': 'LEGACY'}  \n",
       "2   {'status': 'ACTIVE'}  \n",
       "3   {'status': 'ACTIVE'}  \n",
       "4   {'status': 'ACTIVE'}  \n",
       "5   {'status': 'ACTIVE'}  \n",
       "6   {'status': 'ACTIVE'}  \n",
       "7   {'status': 'ACTIVE'}  \n",
       "8   {'status': 'ACTIVE'}  \n",
       "9   {'status': 'ACTIVE'}  \n",
       "10  {'status': 'ACTIVE'}  \n",
       "11  {'status': 'ACTIVE'}  \n",
       "12  {'status': 'ACTIVE'}  \n",
       "13  {'status': 'ACTIVE'}  \n",
       "14  {'status': 'ACTIVE'}  \n",
       "15  {'status': 'ACTIVE'}  \n",
       "16  {'status': 'ACTIVE'}  \n",
       "17  {'status': 'ACTIVE'}  \n",
       "18  {'status': 'ACTIVE'}  \n",
       "19  {'status': 'ACTIVE'}  \n",
       "20  {'status': 'ACTIVE'}  \n",
       "21  {'status': 'ACTIVE'}  \n",
       "22  {'status': 'ACTIVE'}  \n",
       "23  {'status': 'ACTIVE'}  \n",
       "24  {'status': 'ACTIVE'}  \n",
       "25  {'status': 'LEGACY'}  \n",
       "26  {'status': 'ACTIVE'}  \n",
       "27  {'status': 'ACTIVE'}  \n",
       "28  {'status': 'ACTIVE'}  \n",
       "29  {'status': 'ACTIVE'}  \n",
       "30  {'status': 'ACTIVE'}  \n",
       "31  {'status': 'ACTIVE'}  \n",
       "32  {'status': 'ACTIVE'}  \n",
       "33  {'status': 'ACTIVE'}  \n",
       "34  {'status': 'ACTIVE'}  \n",
       "35  {'status': 'ACTIVE'}  \n",
       "36  {'status': 'ACTIVE'}  \n",
       "37  {'status': 'ACTIVE'}  \n",
       "38  {'status': 'ACTIVE'}  \n",
       "39  {'status': 'ACTIVE'}  \n",
       "40  {'status': 'ACTIVE'}  \n",
       "41  {'status': 'ACTIVE'}  \n",
       "42  {'status': 'ACTIVE'}  \n",
       "43  {'status': 'ACTIVE'}  \n",
       "44  {'status': 'ACTIVE'}  \n",
       "45  {'status': 'ACTIVE'}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "boto3_bedrock = get_bedrock_client(runtime=False)\n",
    "fm_list_response = boto3_bedrock.list_foundation_models()\n",
    "fm_list = fm_list_response['modelSummaries']\n",
    "df_fm = pd.DataFrame(fm_list)\n",
    "display(df_fm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-12 13:56:24,387] p31920 {3189124487.py:2} INFO - found 5 transcript_files ->\n",
      "['data/raw/0/call_center_transcript_1_transcript.txt', 'data/raw/1/call_center_transcript_0_transcript.txt', 'data/raw/4/call_center_transcript_4_transcript.txt', 'data/raw/3/call_center_transcript_3_transcript.txt', 'data/raw/2/call_center_transcript_2_transcript.txt']\n"
     ]
    }
   ],
   "source": [
    "transcript_files = glob.glob(os.path.join(config['dir']['raw'], \"*\", \"*transcript.txt\"))\n",
    "logger.info(f\"found {len(transcript_files)} transcript_files ->\\n{transcript_files}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to encapsulate call to any Bedrock model for text generation\n",
    "def get_text_response_from_bedrock(prompt: str, inference_parameters: Dict, model_id: str) -> Dict:\n",
    "\n",
    "    logger.info(f\"model_id={model_id}, prompt length is {len(prompt)} characters, {len(prompt.split())} words\")      \n",
    "    # initialize the response dict\n",
    "    ret = dict(exception = None,\n",
    "               prompt = prompt,\n",
    "               completion = None,\n",
    "               model_id = model_id,\n",
    "               time_taken_in_seconds = None,\n",
    "               completion_token_count = None,\n",
    "               prompt_token_count=None)\n",
    "    \n",
    "    if is_amazon_model(model_id) is False:\n",
    "        body = dict(prompt=prompt) | inference_parameters\n",
    "    else:\n",
    "        body = dict(inputText=prompt, textGenerationConfig=inference_parameters)\n",
    "\n",
    "    body_bytes = json.dumps(body).encode('utf-8')\n",
    "\n",
    "    # invoke the bedrock API for inferences\n",
    "    st = time.time()\n",
    "    try:\n",
    "        response = bedrock_client.invoke_model(\n",
    "                        modelId=model_id,\n",
    "                        contentType=\"application/json\",\n",
    "                        accept=\"*/*\",\n",
    "                        body=body_bytes,\n",
    "                    )\n",
    "    except Exception as e:\n",
    "        logger.error(f\"exception when calling invoke_model, model_id={model_id}, exception={e}\")\n",
    "        ret['exception'] = e\n",
    "        return ret\n",
    "    \n",
    "    ret['time_taken_in_seconds'] = time.time() - st\n",
    "    # response is a Boto3 object, read it to convert into bytes\n",
    "    resp_body = json.loads(response[\"body\"].read().decode('utf-8'))\n",
    "    \n",
    "    parsed_response = parse_model_response(model_id, resp_body)\n",
    "    ret.update(parsed_response)\n",
    "    logger.info(json.dumps(ret, indent=2))\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-12 13:56:25,436] p31920 {544935498.py:19} INFO - idx=0, tf=data/raw/0/call_center_transcript_1_transcript.txt, file_id=call_center_transcript_1, golden_summary_fpath=data/raw/0/example_prompt_transcript_golden_summary.txt\n",
      "[2024-01-12 13:56:25,436] p31920 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=titan_template.txt, reps=3\n",
      "[2024-01-12 13:56:25,436] p31920 {544935498.py:35} INFO - going to summarize idx=0, file=data/raw/0/call_center_transcript_1_transcript.txt via amazon.titan-text-express-v1\n",
      "[2024-01-12 13:56:25,437] p31920 {544935498.py:38} INFO - read prompt template from data/prompts/titan_template.txt\n",
      "[2024-01-12 13:56:25,523] p31920 {544935498.py:43} INFO - prompt for data/raw/0/call_center_transcript_1_transcript.txt has 796 tokens\n",
      "[2024-01-12 13:56:25,523] p31920 {528272729.py:4} INFO - model_id=amazon.titan-text-express-v1, prompt length is 3569 characters, 601 words\n",
      "[2024-01-12 13:56:29,335] p31920 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nA: I wanted to discuss our strategy around generative AI and how we should approach this emerging technology. As you know, several applications have captured a lot of attention recently. \\nAction item: Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n\\nB: Yes, generative AI is definitely a hot topic right now. All the major tech companies seem to be investing heavily in this space.\\nAction item: Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nA: Exactly. I think we need to have a plan here too or risk falling behind. What kind of applications do you see for generative AI in our products? Could it be used to automate certain processes or enhance our users' experience?\\nAction item: Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nC: There's certainly potential, but we'd need to proceed cautiously. While the capabilities are impressive, the technology still has problems with accuracy and bias that could negatively impact customers if we don't validate it thoroughly before rolling anything out.\\nAction item: Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nB: I agree. We'll want to set clear guidelines for what generative AI should and\\n</conversation>\",\n",
      "  \"completion\": \"\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n- Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nB:\\n- Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nC:\\n- None explicitly stated\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 3.8113789558410645,\n",
      "  \"completion_token_count\": 100,\n",
      "  \"prompt_token_count\": 798\n",
      "}\n",
      "[2024-01-12 13:56:29,338] p31920 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nA: I wanted to discuss our strategy around generative AI and how we should approach this emerging technology. As you know, several applications have captured a lot of attention recently. \\nAction item: Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n\\nB: Yes, generative AI is definitely a hot topic right now. All the major tech companies seem to be investing heavily in this space.\\nAction item: Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nA: Exactly. I think we need to have a plan here too or risk falling behind. What kind of applications do you see for generative AI in our products? Could it be used to automate certain processes or enhance our users' experience?\\nAction item: Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nC: There's certainly potential, but we'd need to proceed cautiously. While the capabilities are impressive, the technology still has problems with accuracy and bias that could negatively impact customers if we don't validate it thoroughly before rolling anything out.\\nAction item: Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nB: I agree. We'll want to set clear guidelines for what generative AI should and\\n</conversation>\",\n",
      "  \"completion\": \"<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n- Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nB:\\n- Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nC:\\n- None explicitly stated\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 3.8113789558410645,\n",
      "  \"completion_token_count\": 100,\n",
      "  \"prompt_token_count\": 798,\n",
      "  \"cost\": 0.0007984,\n",
      "  \"completion_word_count\": 72,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-12 13:56:29,340] p31920 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=anthropic_template_single_line_reason.txt, reps=3\n",
      "[2024-01-12 13:56:29,341] p31920 {544935498.py:35} INFO - going to summarize idx=0, file=data/raw/0/call_center_transcript_1_transcript.txt via anthropic.claude-instant-v1\n",
      "[2024-01-12 13:56:29,343] p31920 {544935498.py:38} INFO - read prompt template from data/prompts/anthropic_template_single_line_reason.txt\n",
      "[2024-01-12 13:56:29,347] p31920 {544935498.py:43} INFO - prompt for data/raw/0/call_center_transcript_1_transcript.txt has 778 tokens\n",
      "[2024-01-12 13:56:29,353] p31920 {528272729.py:4} INFO - model_id=anthropic.claude-instant-v1, prompt length is 3486 characters, 584 words\n",
      "[2024-01-12 13:56:31,008] p31920 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to discuss our strategy around generative AI and how we should approach this emerging technology. As you know, several applications have captured a lot of attention recently. \\nAction item: Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n\\nB: Yes, generative AI is definitely a hot topic right now. All the major tech companies seem to be investing heavily in this space.\\nAction item: Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nA: Exactly. I think we need to have a plan here too or risk falling behind. What kind of applications do you see for generative AI in our products? Could it be used to automate certain processes or enhance our users' experience?\\nAction item: Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nC: There's certainly potential, but we'd need to proceed cautiously. While the capabilities are impressive, the technology still has problems with accuracy and bias that could negatively impact customers if we don't validate it thoroughly before rolling anything out.\\nAction item: Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nB: I agree. We'll want to set clear guidelines for what generative AI should and\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \" <output>\\nA: \\n- Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n- Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nB:\\n- Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nC: \\n- Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 1.6461660861968994,\n",
      "  \"completion_token_count\": 107,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-12 13:56:31,009] p31920 {544935498.py:76} INFO - prompt_token_count is None for anthropic.claude-instant-v1, setting it to 778 \n",
      "[2024-01-12 13:56:31,011] p31920 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to discuss our strategy around generative AI and how we should approach this emerging technology. As you know, several applications have captured a lot of attention recently. \\nAction item: Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n\\nB: Yes, generative AI is definitely a hot topic right now. All the major tech companies seem to be investing heavily in this space.\\nAction item: Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nA: Exactly. I think we need to have a plan here too or risk falling behind. What kind of applications do you see for generative AI in our products? Could it be used to automate certain processes or enhance our users' experience?\\nAction item: Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nC: There's certainly potential, but we'd need to proceed cautiously. While the capabilities are impressive, the technology still has problems with accuracy and bias that could negatively impact customers if we don't validate it thoroughly before rolling anything out.\\nAction item: Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nB: I agree. We'll want to set clear guidelines for what generative AI should and\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \"<output>\\nA: \\n- Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n- Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nB:\\n- Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nC: \\n- Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 1.6461660861968994,\n",
      "  \"completion_token_count\": 107,\n",
      "  \"prompt_token_count\": 778,\n",
      "  \"cost\": 0.00185771,\n",
      "  \"completion_word_count\": 76,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-12 13:56:31,012] p31920 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=cohere_template.txt, reps=3\n",
      "[2024-01-12 13:56:31,013] p31920 {544935498.py:35} INFO - going to summarize idx=0, file=data/raw/0/call_center_transcript_1_transcript.txt via cohere.command-text-v14\n",
      "[2024-01-12 13:56:31,014] p31920 {544935498.py:38} INFO - read prompt template from data/prompts/cohere_template.txt\n",
      "[2024-01-12 13:56:31,018] p31920 {544935498.py:43} INFO - prompt for data/raw/0/call_center_transcript_1_transcript.txt has 791 tokens\n",
      "[2024-01-12 13:56:31,019] p31920 {528272729.py:4} INFO - model_id=cohere.command-text-v14, prompt length is 3564 characters, 600 words\n",
      "[2024-01-12 13:56:38,598] p31920 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to discuss our strategy around generative AI and how we should approach this emerging technology. As you know, several applications have captured a lot of attention recently. \\nAction item: Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n\\nB: Yes, generative AI is definitely a hot topic right now. All the major tech companies seem to be investing heavily in this space.\\nAction item: Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nA: Exactly. I think we need to have a plan here too or risk falling behind. What kind of applications do you see for generative AI in our products? Could it be used to automate certain processes or enhance our users' experience?\\nAction item: Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nC: There's certainly potential, but we'd need to proceed cautiously. While the capabilities are impressive, the technology still has problems with accuracy and bias that could negatively impact customers if we don't validate it thoroughly before rolling anything out.\\nAction item: Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nB: I agree. We'll want to set clear guidelines for what generative AI should and\\n</conversation>\",\n",
      "  \"completion\": \" <output>\\nA: \\n- Follow up on the generative AI idea and set up a meeting to brainstorm ideas \\n- Participate in the brainstorming session to contribute ideas for applying generative AI in company products\\n\\nB:\\n- Research tech company initiatives in generative AI to understand the competitive landscape \\n- Compare and contrast these initiatives to company products to identify gaps \\n\\nC:\\n- Outline ideas for applying generative AI that would enhance user experience and automation\\n- Communicate these ideas to relevant stakeholders \\n\\n</output>\",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 7.57765793800354,\n",
      "  \"completion_token_count\": 110,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-12 13:56:38,599] p31920 {544935498.py:76} INFO - prompt_token_count is None for cohere.command-text-v14, setting it to 791 \n",
      "[2024-01-12 13:56:38,601] p31920 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to discuss our strategy around generative AI and how we should approach this emerging technology. As you know, several applications have captured a lot of attention recently. \\nAction item: Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n\\nB: Yes, generative AI is definitely a hot topic right now. All the major tech companies seem to be investing heavily in this space.\\nAction item: Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nA: Exactly. I think we need to have a plan here too or risk falling behind. What kind of applications do you see for generative AI in our products? Could it be used to automate certain processes or enhance our users' experience?\\nAction item: Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nC: There's certainly potential, but we'd need to proceed cautiously. While the capabilities are impressive, the technology still has problems with accuracy and bias that could negatively impact customers if we don't validate it thoroughly before rolling anything out.\\nAction item: Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nB: I agree. We'll want to set clear guidelines for what generative AI should and\\n</conversation>\",\n",
      "  \"completion\": \"<output>\\nA: \\n- Follow up on the generative AI idea and set up a meeting to brainstorm ideas \\n- Participate in the brainstorming session to contribute ideas for applying generative AI in company products\\n\\nB:\\n- Research tech company initiatives in generative AI to understand the competitive landscape \\n- Compare and contrast these initiatives to company products to identify gaps \\n\\nC:\\n- Outline ideas for applying generative AI that would enhance user experience and automation\\n- Communicate these ideas to relevant stakeholders \\n\\n</output>\",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 7.57765793800354,\n",
      "  \"completion_token_count\": 110,\n",
      "  \"prompt_token_count\": 791,\n",
      "  \"cost\": 0.0014065,\n",
      "  \"completion_word_count\": 83,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-12 13:56:38,603] p31920 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=titan_template.txt, reps=3\n",
      "[2024-01-12 13:56:38,603] p31920 {544935498.py:35} INFO - going to summarize idx=0, file=data/raw/0/call_center_transcript_1_transcript.txt via amazon.titan-text-express-v1\n",
      "[2024-01-12 13:56:38,605] p31920 {544935498.py:38} INFO - read prompt template from data/prompts/titan_template.txt\n",
      "[2024-01-12 13:56:38,609] p31920 {544935498.py:43} INFO - prompt for data/raw/0/call_center_transcript_1_transcript.txt has 796 tokens\n",
      "[2024-01-12 13:56:38,610] p31920 {528272729.py:4} INFO - model_id=amazon.titan-text-express-v1, prompt length is 3569 characters, 601 words\n",
      "[2024-01-12 13:56:42,263] p31920 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nA: I wanted to discuss our strategy around generative AI and how we should approach this emerging technology. As you know, several applications have captured a lot of attention recently. \\nAction item: Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n\\nB: Yes, generative AI is definitely a hot topic right now. All the major tech companies seem to be investing heavily in this space.\\nAction item: Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nA: Exactly. I think we need to have a plan here too or risk falling behind. What kind of applications do you see for generative AI in our products? Could it be used to automate certain processes or enhance our users' experience?\\nAction item: Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nC: There's certainly potential, but we'd need to proceed cautiously. While the capabilities are impressive, the technology still has problems with accuracy and bias that could negatively impact customers if we don't validate it thoroughly before rolling anything out.\\nAction item: Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nB: I agree. We'll want to set clear guidelines for what generative AI should and\\n</conversation>\",\n",
      "  \"completion\": \"\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n- Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nB:\\n- Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nC:\\n- None explicitly stated\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 3.652935028076172,\n",
      "  \"completion_token_count\": 100,\n",
      "  \"prompt_token_count\": 798\n",
      "}\n",
      "[2024-01-12 13:56:42,264] p31920 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nA: I wanted to discuss our strategy around generative AI and how we should approach this emerging technology. As you know, several applications have captured a lot of attention recently. \\nAction item: Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n\\nB: Yes, generative AI is definitely a hot topic right now. All the major tech companies seem to be investing heavily in this space.\\nAction item: Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nA: Exactly. I think we need to have a plan here too or risk falling behind. What kind of applications do you see for generative AI in our products? Could it be used to automate certain processes or enhance our users' experience?\\nAction item: Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nC: There's certainly potential, but we'd need to proceed cautiously. While the capabilities are impressive, the technology still has problems with accuracy and bias that could negatively impact customers if we don't validate it thoroughly before rolling anything out.\\nAction item: Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nB: I agree. We'll want to set clear guidelines for what generative AI should and\\n</conversation>\",\n",
      "  \"completion\": \"<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n- Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nB:\\n- Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nC:\\n- None explicitly stated\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 3.652935028076172,\n",
      "  \"completion_token_count\": 100,\n",
      "  \"prompt_token_count\": 798,\n",
      "  \"cost\": 0.0007984,\n",
      "  \"completion_word_count\": 72,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-12 13:56:42,265] p31920 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=anthropic_template_single_line_reason.txt, reps=3\n",
      "[2024-01-12 13:56:42,266] p31920 {544935498.py:35} INFO - going to summarize idx=0, file=data/raw/0/call_center_transcript_1_transcript.txt via anthropic.claude-instant-v1\n",
      "[2024-01-12 13:56:42,268] p31920 {544935498.py:38} INFO - read prompt template from data/prompts/anthropic_template_single_line_reason.txt\n",
      "[2024-01-12 13:56:42,271] p31920 {544935498.py:43} INFO - prompt for data/raw/0/call_center_transcript_1_transcript.txt has 778 tokens\n",
      "[2024-01-12 13:56:42,272] p31920 {528272729.py:4} INFO - model_id=anthropic.claude-instant-v1, prompt length is 3486 characters, 584 words\n",
      "[2024-01-12 13:56:44,047] p31920 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to discuss our strategy around generative AI and how we should approach this emerging technology. As you know, several applications have captured a lot of attention recently. \\nAction item: Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n\\nB: Yes, generative AI is definitely a hot topic right now. All the major tech companies seem to be investing heavily in this space.\\nAction item: Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nA: Exactly. I think we need to have a plan here too or risk falling behind. What kind of applications do you see for generative AI in our products? Could it be used to automate certain processes or enhance our users' experience?\\nAction item: Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nC: There's certainly potential, but we'd need to proceed cautiously. While the capabilities are impressive, the technology still has problems with accuracy and bias that could negatively impact customers if we don't validate it thoroughly before rolling anything out.\\nAction item: Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nB: I agree. We'll want to set clear guidelines for what generative AI should and\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \" <output>\\nA: \\n- Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n- Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nB:\\n- Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nC: \\n- Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 1.7724688053131104,\n",
      "  \"completion_token_count\": 107,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-12 13:56:44,048] p31920 {544935498.py:76} INFO - prompt_token_count is None for anthropic.claude-instant-v1, setting it to 778 \n",
      "[2024-01-12 13:56:44,050] p31920 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to discuss our strategy around generative AI and how we should approach this emerging technology. As you know, several applications have captured a lot of attention recently. \\nAction item: Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n\\nB: Yes, generative AI is definitely a hot topic right now. All the major tech companies seem to be investing heavily in this space.\\nAction item: Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nA: Exactly. I think we need to have a plan here too or risk falling behind. What kind of applications do you see for generative AI in our products? Could it be used to automate certain processes or enhance our users' experience?\\nAction item: Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nC: There's certainly potential, but we'd need to proceed cautiously. While the capabilities are impressive, the technology still has problems with accuracy and bias that could negatively impact customers if we don't validate it thoroughly before rolling anything out.\\nAction item: Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nB: I agree. We'll want to set clear guidelines for what generative AI should and\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \"<output>\\nA: \\n- Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n- Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nB:\\n- Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nC: \\n- Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 1.7724688053131104,\n",
      "  \"completion_token_count\": 107,\n",
      "  \"prompt_token_count\": 778,\n",
      "  \"cost\": 0.00185771,\n",
      "  \"completion_word_count\": 76,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-12 13:56:44,053] p31920 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=cohere_template.txt, reps=3\n",
      "[2024-01-12 13:56:44,054] p31920 {544935498.py:35} INFO - going to summarize idx=0, file=data/raw/0/call_center_transcript_1_transcript.txt via cohere.command-text-v14\n",
      "[2024-01-12 13:56:44,056] p31920 {544935498.py:38} INFO - read prompt template from data/prompts/cohere_template.txt\n",
      "[2024-01-12 13:56:44,062] p31920 {544935498.py:43} INFO - prompt for data/raw/0/call_center_transcript_1_transcript.txt has 791 tokens\n",
      "[2024-01-12 13:56:44,064] p31920 {528272729.py:4} INFO - model_id=cohere.command-text-v14, prompt length is 3564 characters, 600 words\n",
      "[2024-01-12 13:56:51,199] p31920 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to discuss our strategy around generative AI and how we should approach this emerging technology. As you know, several applications have captured a lot of attention recently. \\nAction item: Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n\\nB: Yes, generative AI is definitely a hot topic right now. All the major tech companies seem to be investing heavily in this space.\\nAction item: Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nA: Exactly. I think we need to have a plan here too or risk falling behind. What kind of applications do you see for generative AI in our products? Could it be used to automate certain processes or enhance our users' experience?\\nAction item: Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nC: There's certainly potential, but we'd need to proceed cautiously. While the capabilities are impressive, the technology still has problems with accuracy and bias that could negatively impact customers if we don't validate it thoroughly before rolling anything out.\\nAction item: Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nB: I agree. We'll want to set clear guidelines for what generative AI should and\\n</conversation>\",\n",
      "  \"completion\": \" <output>\\nA: \\n- Follow up on the generative AI idea and set up a meeting to brainstorm ideas \\n- Participate in the brainstorming session to contribute ideas for AI applicability \\n- Review ideas from the meeting and identify top opportunities for applying AI \\n\\nB: \\n- Research tech company initiatives in generative AI to inform competitive landscape understanding \\n- Share research findings and analysis with the team \\n\\nC:\\n- Outline the potential risks of generative AI and propose a validation framework to assess accuracy and ethics \\n- Collaborate with relevant teams to develop the framework and ensure thorough testing of all AI initiatives \\n\\n</output>\\n\\nWhoever is responsible for taking notes during meetings or following up afterwards should compile the list of action items and ensure each member is aware of their deliverables and deadlines to ensure efficient execution. This list can also be used to track progress on the discussed topics and ensure the team follows up on the generative AI discussion. \",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 7.133544921875,\n",
      "  \"completion_token_count\": 214,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-12 13:56:51,200] p31920 {544935498.py:76} INFO - prompt_token_count is None for cohere.command-text-v14, setting it to 791 \n",
      "[2024-01-12 13:56:51,203] p31920 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to discuss our strategy around generative AI and how we should approach this emerging technology. As you know, several applications have captured a lot of attention recently. \\nAction item: Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n\\nB: Yes, generative AI is definitely a hot topic right now. All the major tech companies seem to be investing heavily in this space.\\nAction item: Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nA: Exactly. I think we need to have a plan here too or risk falling behind. What kind of applications do you see for generative AI in our products? Could it be used to automate certain processes or enhance our users' experience?\\nAction item: Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nC: There's certainly potential, but we'd need to proceed cautiously. While the capabilities are impressive, the technology still has problems with accuracy and bias that could negatively impact customers if we don't validate it thoroughly before rolling anything out.\\nAction item: Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nB: I agree. We'll want to set clear guidelines for what generative AI should and\\n</conversation>\",\n",
      "  \"completion\": \"<output>\\nA: \\n- Follow up on the generative AI idea and set up a meeting to brainstorm ideas \\n- Participate in the brainstorming session to contribute ideas for AI applicability \\n- Review ideas from the meeting and identify top opportunities for applying AI \\n\\nB: \\n- Research tech company initiatives in generative AI to inform competitive landscape understanding \\n- Share research findings and analysis with the team \\n\\nC:\\n- Outline the potential risks of generative AI and propose a validation framework to assess accuracy and ethics \\n- Collaborate with relevant teams to develop the framework and ensure thorough testing of all AI initiatives \\n\\n</output>\\n\\nWhoever is responsible for taking notes during meetings or following up afterwards should compile the list of action items and ensure each member is aware of their deliverables and deadlines to ensure efficient execution. This list can also be used to track progress on the discussed topics and ensure the team follows up on the generative AI discussion.\",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 7.133544921875,\n",
      "  \"completion_token_count\": 214,\n",
      "  \"prompt_token_count\": 791,\n",
      "  \"cost\": 0.0016145,\n",
      "  \"completion_word_count\": 161,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-12 13:56:51,205] p31920 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=titan_template.txt, reps=3\n",
      "[2024-01-12 13:56:51,206] p31920 {544935498.py:35} INFO - going to summarize idx=0, file=data/raw/0/call_center_transcript_1_transcript.txt via amazon.titan-text-express-v1\n",
      "[2024-01-12 13:56:51,208] p31920 {544935498.py:38} INFO - read prompt template from data/prompts/titan_template.txt\n",
      "[2024-01-12 13:56:51,213] p31920 {544935498.py:43} INFO - prompt for data/raw/0/call_center_transcript_1_transcript.txt has 796 tokens\n",
      "[2024-01-12 13:56:51,214] p31920 {528272729.py:4} INFO - model_id=amazon.titan-text-express-v1, prompt length is 3569 characters, 601 words\n",
      "[2024-01-12 13:56:54,799] p31920 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nA: I wanted to discuss our strategy around generative AI and how we should approach this emerging technology. As you know, several applications have captured a lot of attention recently. \\nAction item: Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n\\nB: Yes, generative AI is definitely a hot topic right now. All the major tech companies seem to be investing heavily in this space.\\nAction item: Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nA: Exactly. I think we need to have a plan here too or risk falling behind. What kind of applications do you see for generative AI in our products? Could it be used to automate certain processes or enhance our users' experience?\\nAction item: Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nC: There's certainly potential, but we'd need to proceed cautiously. While the capabilities are impressive, the technology still has problems with accuracy and bias that could negatively impact customers if we don't validate it thoroughly before rolling anything out.\\nAction item: Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nB: I agree. We'll want to set clear guidelines for what generative AI should and\\n</conversation>\",\n",
      "  \"completion\": \"\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n- Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nB:\\n- Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nC:\\n- None explicitly stated\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 3.5830130577087402,\n",
      "  \"completion_token_count\": 100,\n",
      "  \"prompt_token_count\": 798\n",
      "}\n",
      "[2024-01-12 13:56:54,802] p31920 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nA: I wanted to discuss our strategy around generative AI and how we should approach this emerging technology. As you know, several applications have captured a lot of attention recently. \\nAction item: Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n\\nB: Yes, generative AI is definitely a hot topic right now. All the major tech companies seem to be investing heavily in this space.\\nAction item: Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nA: Exactly. I think we need to have a plan here too or risk falling behind. What kind of applications do you see for generative AI in our products? Could it be used to automate certain processes or enhance our users' experience?\\nAction item: Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nC: There's certainly potential, but we'd need to proceed cautiously. While the capabilities are impressive, the technology still has problems with accuracy and bias that could negatively impact customers if we don't validate it thoroughly before rolling anything out.\\nAction item: Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nB: I agree. We'll want to set clear guidelines for what generative AI should and\\n</conversation>\",\n",
      "  \"completion\": \"<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n- Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nB:\\n- Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nC:\\n- None explicitly stated\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 3.5830130577087402,\n",
      "  \"completion_token_count\": 100,\n",
      "  \"prompt_token_count\": 798,\n",
      "  \"cost\": 0.0007984,\n",
      "  \"completion_word_count\": 72,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-12 13:56:54,805] p31920 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=anthropic_template_single_line_reason.txt, reps=3\n",
      "[2024-01-12 13:56:54,805] p31920 {544935498.py:35} INFO - going to summarize idx=0, file=data/raw/0/call_center_transcript_1_transcript.txt via anthropic.claude-instant-v1\n",
      "[2024-01-12 13:56:54,807] p31920 {544935498.py:38} INFO - read prompt template from data/prompts/anthropic_template_single_line_reason.txt\n",
      "[2024-01-12 13:56:54,813] p31920 {544935498.py:43} INFO - prompt for data/raw/0/call_center_transcript_1_transcript.txt has 778 tokens\n",
      "[2024-01-12 13:56:54,814] p31920 {528272729.py:4} INFO - model_id=anthropic.claude-instant-v1, prompt length is 3486 characters, 584 words\n",
      "[2024-01-12 13:56:56,212] p31920 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to discuss our strategy around generative AI and how we should approach this emerging technology. As you know, several applications have captured a lot of attention recently. \\nAction item: Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n\\nB: Yes, generative AI is definitely a hot topic right now. All the major tech companies seem to be investing heavily in this space.\\nAction item: Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nA: Exactly. I think we need to have a plan here too or risk falling behind. What kind of applications do you see for generative AI in our products? Could it be used to automate certain processes or enhance our users' experience?\\nAction item: Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nC: There's certainly potential, but we'd need to proceed cautiously. While the capabilities are impressive, the technology still has problems with accuracy and bias that could negatively impact customers if we don't validate it thoroughly before rolling anything out.\\nAction item: Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nB: I agree. We'll want to set clear guidelines for what generative AI should and\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \" <output>\\nA: \\n- Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n- Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nB:\\n- Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nC: \\n- Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 1.3967249393463135,\n",
      "  \"completion_token_count\": 107,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-12 13:56:56,213] p31920 {544935498.py:76} INFO - prompt_token_count is None for anthropic.claude-instant-v1, setting it to 778 \n",
      "[2024-01-12 13:56:56,215] p31920 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to discuss our strategy around generative AI and how we should approach this emerging technology. As you know, several applications have captured a lot of attention recently. \\nAction item: Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n\\nB: Yes, generative AI is definitely a hot topic right now. All the major tech companies seem to be investing heavily in this space.\\nAction item: Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nA: Exactly. I think we need to have a plan here too or risk falling behind. What kind of applications do you see for generative AI in our products? Could it be used to automate certain processes or enhance our users' experience?\\nAction item: Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nC: There's certainly potential, but we'd need to proceed cautiously. While the capabilities are impressive, the technology still has problems with accuracy and bias that could negatively impact customers if we don't validate it thoroughly before rolling anything out.\\nAction item: Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nB: I agree. We'll want to set clear guidelines for what generative AI should and\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \"<output>\\nA: \\n- Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n- Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nB:\\n- Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nC: \\n- Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 1.3967249393463135,\n",
      "  \"completion_token_count\": 107,\n",
      "  \"prompt_token_count\": 778,\n",
      "  \"cost\": 0.00185771,\n",
      "  \"completion_word_count\": 76,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-12 13:56:56,217] p31920 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=cohere_template.txt, reps=3\n",
      "[2024-01-12 13:56:56,218] p31920 {544935498.py:35} INFO - going to summarize idx=0, file=data/raw/0/call_center_transcript_1_transcript.txt via cohere.command-text-v14\n",
      "[2024-01-12 13:56:56,220] p31920 {544935498.py:38} INFO - read prompt template from data/prompts/cohere_template.txt\n",
      "[2024-01-12 13:56:56,226] p31920 {544935498.py:43} INFO - prompt for data/raw/0/call_center_transcript_1_transcript.txt has 791 tokens\n",
      "[2024-01-12 13:56:56,228] p31920 {528272729.py:4} INFO - model_id=cohere.command-text-v14, prompt length is 3564 characters, 600 words\n",
      "[2024-01-12 13:57:03,497] p31920 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to discuss our strategy around generative AI and how we should approach this emerging technology. As you know, several applications have captured a lot of attention recently. \\nAction item: Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n\\nB: Yes, generative AI is definitely a hot topic right now. All the major tech companies seem to be investing heavily in this space.\\nAction item: Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nA: Exactly. I think we need to have a plan here too or risk falling behind. What kind of applications do you see for generative AI in our products? Could it be used to automate certain processes or enhance our users' experience?\\nAction item: Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nC: There's certainly potential, but we'd need to proceed cautiously. While the capabilities are impressive, the technology still has problems with accuracy and bias that could negatively impact customers if we don't validate it thoroughly before rolling anything out.\\nAction item: Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nB: I agree. We'll want to set clear guidelines for what generative AI should and\\n</conversation>\",\n",
      "  \"completion\": \" <output>\\nA: \\n- Follow up on the generative AI idea and set up a meeting to brainstorm ideas \\n- Participate in the brainstorming session to contribute ideas for AI applicability \\n- Review ideas from the meeting and identify top opportunities for applying AI \\n\\nB: \\n- Research tech company initiatives in generative AI to inform competitive landscape understanding \\n- Share findings from this research and discuss key insights and considerations with the team \\n\\nC:\\n- Outline the potential risks of generative AI and enhance user experience in our products \\n- Develop a validation framework to ensure accuracy and ethics of generative AI applications before rollout \\n\\n</output>\\n\\nPlease note that the action items are based on the conversation transcript provided. If the conversation were to continue, the action items might change. \\n\\nWould you like help with anything else? \",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 7.267714738845825,\n",
      "  \"completion_token_count\": 181,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-12 13:57:03,499] p31920 {544935498.py:76} INFO - prompt_token_count is None for cohere.command-text-v14, setting it to 791 \n",
      "[2024-01-12 13:57:03,505] p31920 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to discuss our strategy around generative AI and how we should approach this emerging technology. As you know, several applications have captured a lot of attention recently. \\nAction item: Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n\\nB: Yes, generative AI is definitely a hot topic right now. All the major tech companies seem to be investing heavily in this space.\\nAction item: Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nA: Exactly. I think we need to have a plan here too or risk falling behind. What kind of applications do you see for generative AI in our products? Could it be used to automate certain processes or enhance our users' experience?\\nAction item: Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nC: There's certainly potential, but we'd need to proceed cautiously. While the capabilities are impressive, the technology still has problems with accuracy and bias that could negatively impact customers if we don't validate it thoroughly before rolling anything out.\\nAction item: Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nB: I agree. We'll want to set clear guidelines for what generative AI should and\\n</conversation>\",\n",
      "  \"completion\": \"<output>\\nA: \\n- Follow up on the generative AI idea and set up a meeting to brainstorm ideas \\n- Participate in the brainstorming session to contribute ideas for AI applicability \\n- Review ideas from the meeting and identify top opportunities for applying AI \\n\\nB: \\n- Research tech company initiatives in generative AI to inform competitive landscape understanding \\n- Share findings from this research and discuss key insights and considerations with the team \\n\\nC:\\n- Outline the potential risks of generative AI and enhance user experience in our products \\n- Develop a validation framework to ensure accuracy and ethics of generative AI applications before rollout \\n\\n</output>\\n\\nPlease note that the action items are based on the conversation transcript provided. If the conversation were to continue, the action items might change. \\n\\nWould you like help with anything else?\",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 7.267714738845825,\n",
      "  \"completion_token_count\": 181,\n",
      "  \"prompt_token_count\": 791,\n",
      "  \"cost\": 0.0015485,\n",
      "  \"completion_word_count\": 136,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-12 13:57:03,519] p31920 {544935498.py:19} INFO - idx=1, tf=data/raw/1/call_center_transcript_0_transcript.txt, file_id=call_center_transcript_0, golden_summary_fpath=data/raw/0/example_prompt_transcript_golden_summary.txt\n",
      "[2024-01-12 13:57:03,525] p31920 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=titan_template.txt, reps=3\n",
      "[2024-01-12 13:57:03,565] p31920 {544935498.py:35} INFO - going to summarize idx=1, file=data/raw/1/call_center_transcript_0_transcript.txt via amazon.titan-text-express-v1\n",
      "[2024-01-12 13:57:03,567] p31920 {544935498.py:38} INFO - read prompt template from data/prompts/titan_template.txt\n",
      "[2024-01-12 13:57:03,570] p31920 {544935498.py:43} INFO - prompt for data/raw/1/call_center_transcript_0_transcript.txt has 746 tokens\n",
      "[2024-01-12 13:57:03,571] p31920 {528272729.py:4} INFO - model_id=amazon.titan-text-express-v1, prompt length is 3087 characters, 560 words\n",
      "[2024-01-12 13:57:08,323] p31920 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nMeeting transcript: \\nA: Hi B, I want to discuss the workstream for our new product launch\\nB: Sure A, is there anything in particular you want to discuss?\\nA: Yes, I want to talk about how users enter into the product.  \\nB: Ok, in that case let me add in C.\\nC: Hey everyone\\nB: Hi C, A wants to discuss how users enter into the product.\\nA: its too complicated and we should remove friction.  for example, why do I need to fill out additional forms? I also find it difficult to find where to access the product when I first land on the landing page.  \\nB: I would also add that I think there are too many steps.\\nC: Ok, I can work on the landing page to make the product more discoverable but B can you work on the additonal forms?\\nB: Yes but I would need to work with James from another team as he needs to unblock the sign up workflow. A can you document any other concerns so that I can discuss with James only once?\\nA: Sure.\\n</conversation>\",\n",
      "  \"completion\": \"\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Document any other concerns related to user entry into the product so that they can be discussed with James from another team\\n- Work with C to make the product more discoverable on the landing page\\n\\nB:\\n- Work with James from another team to unblock the sign up workflow\\n- Work with C to make the product more discoverable on the landing page\\n\\nC:\\n- Work on the landing page to make the product more discoverable\\n- Work with B to remove friction from the additional forms\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 4.750519037246704,\n",
      "  \"completion_token_count\": 128,\n",
      "  \"prompt_token_count\": 750\n",
      "}\n",
      "[2024-01-12 13:57:08,328] p31920 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nMeeting transcript: \\nA: Hi B, I want to discuss the workstream for our new product launch\\nB: Sure A, is there anything in particular you want to discuss?\\nA: Yes, I want to talk about how users enter into the product.  \\nB: Ok, in that case let me add in C.\\nC: Hey everyone\\nB: Hi C, A wants to discuss how users enter into the product.\\nA: its too complicated and we should remove friction.  for example, why do I need to fill out additional forms? I also find it difficult to find where to access the product when I first land on the landing page.  \\nB: I would also add that I think there are too many steps.\\nC: Ok, I can work on the landing page to make the product more discoverable but B can you work on the additonal forms?\\nB: Yes but I would need to work with James from another team as he needs to unblock the sign up workflow. A can you document any other concerns so that I can discuss with James only once?\\nA: Sure.\\n</conversation>\",\n",
      "  \"completion\": \"<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Document any other concerns related to user entry into the product so that they can be discussed with James from another team\\n- Work with C to make the product more discoverable on the landing page\\n\\nB:\\n- Work with James from another team to unblock the sign up workflow\\n- Work with C to make the product more discoverable on the landing page\\n\\nC:\\n- Work on the landing page to make the product more discoverable\\n- Work with B to remove friction from the additional forms\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 4.750519037246704,\n",
      "  \"completion_token_count\": 128,\n",
      "  \"prompt_token_count\": 750,\n",
      "  \"cost\": 0.0008048,\n",
      "  \"completion_word_count\": 102,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-12 13:57:08,331] p31920 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=anthropic_template_single_line_reason.txt, reps=3\n",
      "[2024-01-12 13:57:08,332] p31920 {544935498.py:35} INFO - going to summarize idx=1, file=data/raw/1/call_center_transcript_0_transcript.txt via anthropic.claude-instant-v1\n",
      "[2024-01-12 13:57:08,334] p31920 {544935498.py:38} INFO - read prompt template from data/prompts/anthropic_template_single_line_reason.txt\n",
      "[2024-01-12 13:57:08,340] p31920 {544935498.py:43} INFO - prompt for data/raw/1/call_center_transcript_0_transcript.txt has 728 tokens\n",
      "[2024-01-12 13:57:08,342] p31920 {528272729.py:4} INFO - model_id=anthropic.claude-instant-v1, prompt length is 3004 characters, 543 words\n",
      "[2024-01-12 13:57:09,848] p31920 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nMeeting transcript: \\nA: Hi B, I want to discuss the workstream for our new product launch\\nB: Sure A, is there anything in particular you want to discuss?\\nA: Yes, I want to talk about how users enter into the product.  \\nB: Ok, in that case let me add in C.\\nC: Hey everyone\\nB: Hi C, A wants to discuss how users enter into the product.\\nA: its too complicated and we should remove friction.  for example, why do I need to fill out additional forms? I also find it difficult to find where to access the product when I first land on the landing page.  \\nB: I would also add that I think there are too many steps.\\nC: Ok, I can work on the landing page to make the product more discoverable but B can you work on the additonal forms?\\nB: Yes but I would need to work with James from another team as he needs to unblock the sign up workflow. A can you document any other concerns so that I can discuss with James only once?\\nA: Sure.\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \" <output>\\nA: \\n- Document any other concerns with the user entry process to discuss with James\\n\\nB:\\n- Work with James from another team to streamline the additional forms in the signup workflow  \\n- Discuss concerns documented by A with James\\n\\nC: \\n- Work on improving the landing page to make the product more discoverable for new users\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 1.5035860538482666,\n",
      "  \"completion_token_count\": 82,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-12 13:57:09,850] p31920 {544935498.py:76} INFO - prompt_token_count is None for anthropic.claude-instant-v1, setting it to 728 \n",
      "[2024-01-12 13:57:09,853] p31920 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nMeeting transcript: \\nA: Hi B, I want to discuss the workstream for our new product launch\\nB: Sure A, is there anything in particular you want to discuss?\\nA: Yes, I want to talk about how users enter into the product.  \\nB: Ok, in that case let me add in C.\\nC: Hey everyone\\nB: Hi C, A wants to discuss how users enter into the product.\\nA: its too complicated and we should remove friction.  for example, why do I need to fill out additional forms? I also find it difficult to find where to access the product when I first land on the landing page.  \\nB: I would also add that I think there are too many steps.\\nC: Ok, I can work on the landing page to make the product more discoverable but B can you work on the additonal forms?\\nB: Yes but I would need to work with James from another team as he needs to unblock the sign up workflow. A can you document any other concerns so that I can discuss with James only once?\\nA: Sure.\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \"<output>\\nA: \\n- Document any other concerns with the user entry process to discuss with James\\n\\nB:\\n- Work with James from another team to streamline the additional forms in the signup workflow  \\n- Discuss concerns documented by A with James\\n\\nC: \\n- Work on improving the landing page to make the product more discoverable for new users\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 1.5035860538482666,\n",
      "  \"completion_token_count\": 82,\n",
      "  \"prompt_token_count\": 728,\n",
      "  \"cost\": 0.0016384599999999998,\n",
      "  \"completion_word_count\": 59,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-12 13:57:09,856] p31920 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=cohere_template.txt, reps=3\n",
      "[2024-01-12 13:57:09,857] p31920 {544935498.py:35} INFO - going to summarize idx=1, file=data/raw/1/call_center_transcript_0_transcript.txt via cohere.command-text-v14\n",
      "[2024-01-12 13:57:09,859] p31920 {544935498.py:38} INFO - read prompt template from data/prompts/cohere_template.txt\n",
      "[2024-01-12 13:57:09,865] p31920 {544935498.py:43} INFO - prompt for data/raw/1/call_center_transcript_0_transcript.txt has 741 tokens\n",
      "[2024-01-12 13:57:09,866] p31920 {528272729.py:4} INFO - model_id=cohere.command-text-v14, prompt length is 3082 characters, 559 words\n",
      "[2024-01-12 13:57:16,742] p31920 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nMeeting transcript: \\nA: Hi B, I want to discuss the workstream for our new product launch\\nB: Sure A, is there anything in particular you want to discuss?\\nA: Yes, I want to talk about how users enter into the product.  \\nB: Ok, in that case let me add in C.\\nC: Hey everyone\\nB: Hi C, A wants to discuss how users enter into the product.\\nA: its too complicated and we should remove friction.  for example, why do I need to fill out additional forms? I also find it difficult to find where to access the product when I first land on the landing page.  \\nB: I would also add that I think there are too many steps.\\nC: Ok, I can work on the landing page to make the product more discoverable but B can you work on the additonal forms?\\nB: Yes but I would need to work with James from another team as he needs to unblock the sign up workflow. A can you document any other concerns so that I can discuss with James only once?\\nA: Sure.\\n</conversation>\",\n",
      "  \"completion\": \" <output>\\nHere are the action items for each speaker based on the conversation:\\n\\nA:\\n- Document specific concerns about the sign-up workflow to simplify user entry\\n- Collaborate with B and James to streamline the forms and questions asked during user sign-up \\n\\nB:\\n- Work with James to unblock the sign-up workflow and simplify the process\\n- Take lead on further simplifying user entry by consolidating sign-up steps and making the product more accessible and discoverable\\n\\nC:\\n- Optimize the landing page to make the product more discoverable for new users\\n</output>\\n\\nDo these action items seem reasonable based on the conversation? \",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 6.874992847442627,\n",
      "  \"completion_token_count\": 136,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-12 13:57:16,744] p31920 {544935498.py:76} INFO - prompt_token_count is None for cohere.command-text-v14, setting it to 741 \n",
      "[2024-01-12 13:57:16,746] p31920 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nMeeting transcript: \\nA: Hi B, I want to discuss the workstream for our new product launch\\nB: Sure A, is there anything in particular you want to discuss?\\nA: Yes, I want to talk about how users enter into the product.  \\nB: Ok, in that case let me add in C.\\nC: Hey everyone\\nB: Hi C, A wants to discuss how users enter into the product.\\nA: its too complicated and we should remove friction.  for example, why do I need to fill out additional forms? I also find it difficult to find where to access the product when I first land on the landing page.  \\nB: I would also add that I think there are too many steps.\\nC: Ok, I can work on the landing page to make the product more discoverable but B can you work on the additonal forms?\\nB: Yes but I would need to work with James from another team as he needs to unblock the sign up workflow. A can you document any other concerns so that I can discuss with James only once?\\nA: Sure.\\n</conversation>\",\n",
      "  \"completion\": \"<output>\\nHere are the action items for each speaker based on the conversation:\\n\\nA:\\n- Document specific concerns about the sign-up workflow to simplify user entry\\n- Collaborate with B and James to streamline the forms and questions asked during user sign-up \\n\\nB:\\n- Work with James to unblock the sign-up workflow and simplify the process\\n- Take lead on further simplifying user entry by consolidating sign-up steps and making the product more accessible and discoverable\\n\\nC:\\n- Optimize the landing page to make the product more discoverable for new users\\n</output>\\n\\nDo these action items seem reasonable based on the conversation?\",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 6.874992847442627,\n",
      "  \"completion_token_count\": 136,\n",
      "  \"prompt_token_count\": 741,\n",
      "  \"cost\": 0.0013835000000000002,\n",
      "  \"completion_word_count\": 102,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-12 13:57:16,749] p31920 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=titan_template.txt, reps=3\n",
      "[2024-01-12 13:57:16,750] p31920 {544935498.py:35} INFO - going to summarize idx=1, file=data/raw/1/call_center_transcript_0_transcript.txt via amazon.titan-text-express-v1\n",
      "[2024-01-12 13:57:16,752] p31920 {544935498.py:38} INFO - read prompt template from data/prompts/titan_template.txt\n",
      "[2024-01-12 13:57:16,758] p31920 {544935498.py:43} INFO - prompt for data/raw/1/call_center_transcript_0_transcript.txt has 746 tokens\n",
      "[2024-01-12 13:57:16,759] p31920 {528272729.py:4} INFO - model_id=amazon.titan-text-express-v1, prompt length is 3087 characters, 560 words\n",
      "[2024-01-12 13:57:21,137] p31920 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nMeeting transcript: \\nA: Hi B, I want to discuss the workstream for our new product launch\\nB: Sure A, is there anything in particular you want to discuss?\\nA: Yes, I want to talk about how users enter into the product.  \\nB: Ok, in that case let me add in C.\\nC: Hey everyone\\nB: Hi C, A wants to discuss how users enter into the product.\\nA: its too complicated and we should remove friction.  for example, why do I need to fill out additional forms? I also find it difficult to find where to access the product when I first land on the landing page.  \\nB: I would also add that I think there are too many steps.\\nC: Ok, I can work on the landing page to make the product more discoverable but B can you work on the additonal forms?\\nB: Yes but I would need to work with James from another team as he needs to unblock the sign up workflow. A can you document any other concerns so that I can discuss with James only once?\\nA: Sure.\\n</conversation>\",\n",
      "  \"completion\": \"\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Document any other concerns related to user entry into the product so that they can be discussed with James from another team\\n- Work with C to make the product more discoverable on the landing page\\n\\nB:\\n- Work with James from another team to unblock the sign up workflow\\n- Work with C to make the product more discoverable on the landing page\\n\\nC:\\n- Work on the landing page to make the product more discoverable\\n- Work with B to remove friction from the additional forms\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 4.3771257400512695,\n",
      "  \"completion_token_count\": 128,\n",
      "  \"prompt_token_count\": 750\n",
      "}\n",
      "[2024-01-12 13:57:21,141] p31920 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nMeeting transcript: \\nA: Hi B, I want to discuss the workstream for our new product launch\\nB: Sure A, is there anything in particular you want to discuss?\\nA: Yes, I want to talk about how users enter into the product.  \\nB: Ok, in that case let me add in C.\\nC: Hey everyone\\nB: Hi C, A wants to discuss how users enter into the product.\\nA: its too complicated and we should remove friction.  for example, why do I need to fill out additional forms? I also find it difficult to find where to access the product when I first land on the landing page.  \\nB: I would also add that I think there are too many steps.\\nC: Ok, I can work on the landing page to make the product more discoverable but B can you work on the additonal forms?\\nB: Yes but I would need to work with James from another team as he needs to unblock the sign up workflow. A can you document any other concerns so that I can discuss with James only once?\\nA: Sure.\\n</conversation>\",\n",
      "  \"completion\": \"<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Document any other concerns related to user entry into the product so that they can be discussed with James from another team\\n- Work with C to make the product more discoverable on the landing page\\n\\nB:\\n- Work with James from another team to unblock the sign up workflow\\n- Work with C to make the product more discoverable on the landing page\\n\\nC:\\n- Work on the landing page to make the product more discoverable\\n- Work with B to remove friction from the additional forms\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 4.3771257400512695,\n",
      "  \"completion_token_count\": 128,\n",
      "  \"prompt_token_count\": 750,\n",
      "  \"cost\": 0.0008048,\n",
      "  \"completion_word_count\": 102,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-12 13:57:21,143] p31920 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=anthropic_template_single_line_reason.txt, reps=3\n",
      "[2024-01-12 13:57:21,144] p31920 {544935498.py:35} INFO - going to summarize idx=1, file=data/raw/1/call_center_transcript_0_transcript.txt via anthropic.claude-instant-v1\n",
      "[2024-01-12 13:57:21,147] p31920 {544935498.py:38} INFO - read prompt template from data/prompts/anthropic_template_single_line_reason.txt\n",
      "[2024-01-12 13:57:21,153] p31920 {544935498.py:43} INFO - prompt for data/raw/1/call_center_transcript_0_transcript.txt has 728 tokens\n",
      "[2024-01-12 13:57:21,154] p31920 {528272729.py:4} INFO - model_id=anthropic.claude-instant-v1, prompt length is 3004 characters, 543 words\n",
      "[2024-01-12 13:57:22,782] p31920 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nMeeting transcript: \\nA: Hi B, I want to discuss the workstream for our new product launch\\nB: Sure A, is there anything in particular you want to discuss?\\nA: Yes, I want to talk about how users enter into the product.  \\nB: Ok, in that case let me add in C.\\nC: Hey everyone\\nB: Hi C, A wants to discuss how users enter into the product.\\nA: its too complicated and we should remove friction.  for example, why do I need to fill out additional forms? I also find it difficult to find where to access the product when I first land on the landing page.  \\nB: I would also add that I think there are too many steps.\\nC: Ok, I can work on the landing page to make the product more discoverable but B can you work on the additonal forms?\\nB: Yes but I would need to work with James from another team as he needs to unblock the sign up workflow. A can you document any other concerns so that I can discuss with James only once?\\nA: Sure.\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \" <output>\\nA: \\n- Document any other concerns with the user entry process to discuss with James\\n\\nB:\\n- Work with James from another team to streamline the additional forms in the signup workflow  \\n- Discuss concerns documented by A with James\\n\\nC: \\n- Work on improving the landing page to make the product more discoverable for new users\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 1.6254148483276367,\n",
      "  \"completion_token_count\": 82,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-12 13:57:22,784] p31920 {544935498.py:76} INFO - prompt_token_count is None for anthropic.claude-instant-v1, setting it to 728 \n",
      "[2024-01-12 13:57:22,787] p31920 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nMeeting transcript: \\nA: Hi B, I want to discuss the workstream for our new product launch\\nB: Sure A, is there anything in particular you want to discuss?\\nA: Yes, I want to talk about how users enter into the product.  \\nB: Ok, in that case let me add in C.\\nC: Hey everyone\\nB: Hi C, A wants to discuss how users enter into the product.\\nA: its too complicated and we should remove friction.  for example, why do I need to fill out additional forms? I also find it difficult to find where to access the product when I first land on the landing page.  \\nB: I would also add that I think there are too many steps.\\nC: Ok, I can work on the landing page to make the product more discoverable but B can you work on the additonal forms?\\nB: Yes but I would need to work with James from another team as he needs to unblock the sign up workflow. A can you document any other concerns so that I can discuss with James only once?\\nA: Sure.\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \"<output>\\nA: \\n- Document any other concerns with the user entry process to discuss with James\\n\\nB:\\n- Work with James from another team to streamline the additional forms in the signup workflow  \\n- Discuss concerns documented by A with James\\n\\nC: \\n- Work on improving the landing page to make the product more discoverable for new users\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 1.6254148483276367,\n",
      "  \"completion_token_count\": 82,\n",
      "  \"prompt_token_count\": 728,\n",
      "  \"cost\": 0.0016384599999999998,\n",
      "  \"completion_word_count\": 59,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-12 13:57:22,791] p31920 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=cohere_template.txt, reps=3\n",
      "[2024-01-12 13:57:22,791] p31920 {544935498.py:35} INFO - going to summarize idx=1, file=data/raw/1/call_center_transcript_0_transcript.txt via cohere.command-text-v14\n",
      "[2024-01-12 13:57:22,794] p31920 {544935498.py:38} INFO - read prompt template from data/prompts/cohere_template.txt\n",
      "[2024-01-12 13:57:22,800] p31920 {544935498.py:43} INFO - prompt for data/raw/1/call_center_transcript_0_transcript.txt has 741 tokens\n",
      "[2024-01-12 13:57:22,801] p31920 {528272729.py:4} INFO - model_id=cohere.command-text-v14, prompt length is 3082 characters, 559 words\n",
      "[2024-01-12 13:57:30,924] p31920 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nMeeting transcript: \\nA: Hi B, I want to discuss the workstream for our new product launch\\nB: Sure A, is there anything in particular you want to discuss?\\nA: Yes, I want to talk about how users enter into the product.  \\nB: Ok, in that case let me add in C.\\nC: Hey everyone\\nB: Hi C, A wants to discuss how users enter into the product.\\nA: its too complicated and we should remove friction.  for example, why do I need to fill out additional forms? I also find it difficult to find where to access the product when I first land on the landing page.  \\nB: I would also add that I think there are too many steps.\\nC: Ok, I can work on the landing page to make the product more discoverable but B can you work on the additonal forms?\\nB: Yes but I would need to work with James from another team as he needs to unblock the sign up workflow. A can you document any other concerns so that I can discuss with James only once?\\nA: Sure.\\n</conversation>\",\n",
      "  \"completion\": \" <output>\\nHere are the action items for each speaker based on the conversation:\\n\\nA:\\n- Document specific concerns about the sign-up workflow to simplify user entry\\n- Collaborate with B and James to streamline the forms and questions asked during user sign-up \\n\\nB:\\n- Work with James to unblock the sign-up workflow and simplify the process\\n- Take lead on further simplifying user entry by consolidating sign-up steps and making the product more accessible on the landing page \\n\\nC:\\n- Focus on improving the discoverability of the product on the landing page\\n</output>\\n\\nDo these action items seem reasonable based on the conversation? Is there anything else I can help you with? \",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 8.120730876922607,\n",
      "  \"completion_token_count\": 149,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-12 13:57:30,926] p31920 {544935498.py:76} INFO - prompt_token_count is None for cohere.command-text-v14, setting it to 741 \n",
      "[2024-01-12 13:57:30,928] p31920 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nMeeting transcript: \\nA: Hi B, I want to discuss the workstream for our new product launch\\nB: Sure A, is there anything in particular you want to discuss?\\nA: Yes, I want to talk about how users enter into the product.  \\nB: Ok, in that case let me add in C.\\nC: Hey everyone\\nB: Hi C, A wants to discuss how users enter into the product.\\nA: its too complicated and we should remove friction.  for example, why do I need to fill out additional forms? I also find it difficult to find where to access the product when I first land on the landing page.  \\nB: I would also add that I think there are too many steps.\\nC: Ok, I can work on the landing page to make the product more discoverable but B can you work on the additonal forms?\\nB: Yes but I would need to work with James from another team as he needs to unblock the sign up workflow. A can you document any other concerns so that I can discuss with James only once?\\nA: Sure.\\n</conversation>\",\n",
      "  \"completion\": \"<output>\\nHere are the action items for each speaker based on the conversation:\\n\\nA:\\n- Document specific concerns about the sign-up workflow to simplify user entry\\n- Collaborate with B and James to streamline the forms and questions asked during user sign-up \\n\\nB:\\n- Work with James to unblock the sign-up workflow and simplify the process\\n- Take lead on further simplifying user entry by consolidating sign-up steps and making the product more accessible on the landing page \\n\\nC:\\n- Focus on improving the discoverability of the product on the landing page\\n</output>\\n\\nDo these action items seem reasonable based on the conversation? Is there anything else I can help you with?\",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 8.120730876922607,\n",
      "  \"completion_token_count\": 149,\n",
      "  \"prompt_token_count\": 741,\n",
      "  \"cost\": 0.0014095000000000002,\n",
      "  \"completion_word_count\": 112,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-12 13:57:30,931] p31920 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=titan_template.txt, reps=3\n",
      "[2024-01-12 13:57:30,932] p31920 {544935498.py:35} INFO - going to summarize idx=1, file=data/raw/1/call_center_transcript_0_transcript.txt via amazon.titan-text-express-v1\n",
      "[2024-01-12 13:57:30,934] p31920 {544935498.py:38} INFO - read prompt template from data/prompts/titan_template.txt\n",
      "[2024-01-12 13:57:30,940] p31920 {544935498.py:43} INFO - prompt for data/raw/1/call_center_transcript_0_transcript.txt has 746 tokens\n",
      "[2024-01-12 13:57:30,941] p31920 {528272729.py:4} INFO - model_id=amazon.titan-text-express-v1, prompt length is 3087 characters, 560 words\n",
      "[2024-01-12 13:57:34,378] p31920 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nMeeting transcript: \\nA: Hi B, I want to discuss the workstream for our new product launch\\nB: Sure A, is there anything in particular you want to discuss?\\nA: Yes, I want to talk about how users enter into the product.  \\nB: Ok, in that case let me add in C.\\nC: Hey everyone\\nB: Hi C, A wants to discuss how users enter into the product.\\nA: its too complicated and we should remove friction.  for example, why do I need to fill out additional forms? I also find it difficult to find where to access the product when I first land on the landing page.  \\nB: I would also add that I think there are too many steps.\\nC: Ok, I can work on the landing page to make the product more discoverable but B can you work on the additonal forms?\\nB: Yes but I would need to work with James from another team as he needs to unblock the sign up workflow. A can you document any other concerns so that I can discuss with James only once?\\nA: Sure.\\n</conversation>\",\n",
      "  \"completion\": \"\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Document any other concerns about the product launch workstream so that B can discuss with James only once\\n\\nB:\\n- Work with James from another team to unblock the sign up workflow\\n- Work on the landing page to make the product more discoverable\\n\\nC:\\n- Work on the landing page to make the product more discoverable\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 3.4354701042175293,\n",
      "  \"completion_token_count\": 95,\n",
      "  \"prompt_token_count\": 750\n",
      "}\n",
      "[2024-01-12 13:57:34,381] p31920 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nMeeting transcript: \\nA: Hi B, I want to discuss the workstream for our new product launch\\nB: Sure A, is there anything in particular you want to discuss?\\nA: Yes, I want to talk about how users enter into the product.  \\nB: Ok, in that case let me add in C.\\nC: Hey everyone\\nB: Hi C, A wants to discuss how users enter into the product.\\nA: its too complicated and we should remove friction.  for example, why do I need to fill out additional forms? I also find it difficult to find where to access the product when I first land on the landing page.  \\nB: I would also add that I think there are too many steps.\\nC: Ok, I can work on the landing page to make the product more discoverable but B can you work on the additonal forms?\\nB: Yes but I would need to work with James from another team as he needs to unblock the sign up workflow. A can you document any other concerns so that I can discuss with James only once?\\nA: Sure.\\n</conversation>\",\n",
      "  \"completion\": \"<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Document any other concerns about the product launch workstream so that B can discuss with James only once\\n\\nB:\\n- Work with James from another team to unblock the sign up workflow\\n- Work on the landing page to make the product more discoverable\\n\\nC:\\n- Work on the landing page to make the product more discoverable\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 3.4354701042175293,\n",
      "  \"completion_token_count\": 95,\n",
      "  \"prompt_token_count\": 750,\n",
      "  \"cost\": 0.0007520000000000001,\n",
      "  \"completion_word_count\": 71,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-12 13:57:34,382] p31920 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=anthropic_template_single_line_reason.txt, reps=3\n",
      "[2024-01-12 13:57:34,383] p31920 {544935498.py:35} INFO - going to summarize idx=1, file=data/raw/1/call_center_transcript_0_transcript.txt via anthropic.claude-instant-v1\n",
      "[2024-01-12 13:57:34,385] p31920 {544935498.py:38} INFO - read prompt template from data/prompts/anthropic_template_single_line_reason.txt\n",
      "[2024-01-12 13:57:34,391] p31920 {544935498.py:43} INFO - prompt for data/raw/1/call_center_transcript_0_transcript.txt has 728 tokens\n",
      "[2024-01-12 13:57:34,392] p31920 {528272729.py:4} INFO - model_id=anthropic.claude-instant-v1, prompt length is 3004 characters, 543 words\n",
      "[2024-01-12 13:57:36,226] p31920 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nMeeting transcript: \\nA: Hi B, I want to discuss the workstream for our new product launch\\nB: Sure A, is there anything in particular you want to discuss?\\nA: Yes, I want to talk about how users enter into the product.  \\nB: Ok, in that case let me add in C.\\nC: Hey everyone\\nB: Hi C, A wants to discuss how users enter into the product.\\nA: its too complicated and we should remove friction.  for example, why do I need to fill out additional forms? I also find it difficult to find where to access the product when I first land on the landing page.  \\nB: I would also add that I think there are too many steps.\\nC: Ok, I can work on the landing page to make the product more discoverable but B can you work on the additonal forms?\\nB: Yes but I would need to work with James from another team as he needs to unblock the sign up workflow. A can you document any other concerns so that I can discuss with James only once?\\nA: Sure.\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \" <output>\\nA: \\n- Document any other concerns with the user entry process to discuss with James\\n\\nB:\\n- Work with James from another team to streamline the additional forms in the signup workflow  \\n- Discuss concerns documented by A with James\\n\\nC: \\n- Work on improving the landing page to make the product more discoverable for new users\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 1.830963134765625,\n",
      "  \"completion_token_count\": 82,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-12 13:57:36,228] p31920 {544935498.py:76} INFO - prompt_token_count is None for anthropic.claude-instant-v1, setting it to 728 \n",
      "[2024-01-12 13:57:36,231] p31920 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nMeeting transcript: \\nA: Hi B, I want to discuss the workstream for our new product launch\\nB: Sure A, is there anything in particular you want to discuss?\\nA: Yes, I want to talk about how users enter into the product.  \\nB: Ok, in that case let me add in C.\\nC: Hey everyone\\nB: Hi C, A wants to discuss how users enter into the product.\\nA: its too complicated and we should remove friction.  for example, why do I need to fill out additional forms? I also find it difficult to find where to access the product when I first land on the landing page.  \\nB: I would also add that I think there are too many steps.\\nC: Ok, I can work on the landing page to make the product more discoverable but B can you work on the additonal forms?\\nB: Yes but I would need to work with James from another team as he needs to unblock the sign up workflow. A can you document any other concerns so that I can discuss with James only once?\\nA: Sure.\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \"<output>\\nA: \\n- Document any other concerns with the user entry process to discuss with James\\n\\nB:\\n- Work with James from another team to streamline the additional forms in the signup workflow  \\n- Discuss concerns documented by A with James\\n\\nC: \\n- Work on improving the landing page to make the product more discoverable for new users\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 1.830963134765625,\n",
      "  \"completion_token_count\": 82,\n",
      "  \"prompt_token_count\": 728,\n",
      "  \"cost\": 0.0016384599999999998,\n",
      "  \"completion_word_count\": 59,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-12 13:57:36,236] p31920 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=cohere_template.txt, reps=3\n",
      "[2024-01-12 13:57:36,237] p31920 {544935498.py:35} INFO - going to summarize idx=1, file=data/raw/1/call_center_transcript_0_transcript.txt via cohere.command-text-v14\n",
      "[2024-01-12 13:57:36,240] p31920 {544935498.py:38} INFO - read prompt template from data/prompts/cohere_template.txt\n",
      "[2024-01-12 13:57:36,245] p31920 {544935498.py:43} INFO - prompt for data/raw/1/call_center_transcript_0_transcript.txt has 741 tokens\n",
      "[2024-01-12 13:57:36,247] p31920 {528272729.py:4} INFO - model_id=cohere.command-text-v14, prompt length is 3082 characters, 559 words\n",
      "[2024-01-12 13:57:41,268] p31920 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nMeeting transcript: \\nA: Hi B, I want to discuss the workstream for our new product launch\\nB: Sure A, is there anything in particular you want to discuss?\\nA: Yes, I want to talk about how users enter into the product.  \\nB: Ok, in that case let me add in C.\\nC: Hey everyone\\nB: Hi C, A wants to discuss how users enter into the product.\\nA: its too complicated and we should remove friction.  for example, why do I need to fill out additional forms? I also find it difficult to find where to access the product when I first land on the landing page.  \\nB: I would also add that I think there are too many steps.\\nC: Ok, I can work on the landing page to make the product more discoverable but B can you work on the additonal forms?\\nB: Yes but I would need to work with James from another team as he needs to unblock the sign up workflow. A can you document any other concerns so that I can discuss with James only once?\\nA: Sure.\\n</conversation>\",\n",
      "  \"completion\": \" <output>\\nHere are the action items for each speaker based on the conversation:\\n\\nA:\\n- Document specific concerns about the sign-up workflow to simplify user entrance to the product \\n- Collaborate with B and James to simplify the forms during the sign-up process \\n\\nB:\\n- Unblock the sign-up workflow by working with James \\n- Delegate A's concerns to James \\n\\nC: \\n- Work on the landing page to make the product more discoverable \\n\\nIf there are any other action items resulting from this conversation, please provide additional information or details from the conversation. I will be happy to update the list of action items.</output> \",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 5.019920110702515,\n",
      "  \"completion_token_count\": 137,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-12 13:57:41,270] p31920 {544935498.py:76} INFO - prompt_token_count is None for cohere.command-text-v14, setting it to 741 \n",
      "[2024-01-12 13:57:41,274] p31920 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nMeeting transcript: \\nA: Hi B, I want to discuss the workstream for our new product launch\\nB: Sure A, is there anything in particular you want to discuss?\\nA: Yes, I want to talk about how users enter into the product.  \\nB: Ok, in that case let me add in C.\\nC: Hey everyone\\nB: Hi C, A wants to discuss how users enter into the product.\\nA: its too complicated and we should remove friction.  for example, why do I need to fill out additional forms? I also find it difficult to find where to access the product when I first land on the landing page.  \\nB: I would also add that I think there are too many steps.\\nC: Ok, I can work on the landing page to make the product more discoverable but B can you work on the additonal forms?\\nB: Yes but I would need to work with James from another team as he needs to unblock the sign up workflow. A can you document any other concerns so that I can discuss with James only once?\\nA: Sure.\\n</conversation>\",\n",
      "  \"completion\": \"<output>\\nHere are the action items for each speaker based on the conversation:\\n\\nA:\\n- Document specific concerns about the sign-up workflow to simplify user entrance to the product \\n- Collaborate with B and James to simplify the forms during the sign-up process \\n\\nB:\\n- Unblock the sign-up workflow by working with James \\n- Delegate A's concerns to James \\n\\nC: \\n- Work on the landing page to make the product more discoverable \\n\\nIf there are any other action items resulting from this conversation, please provide additional information or details from the conversation. I will be happy to update the list of action items.</output>\",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 5.019920110702515,\n",
      "  \"completion_token_count\": 137,\n",
      "  \"prompt_token_count\": 741,\n",
      "  \"cost\": 0.0013855,\n",
      "  \"completion_word_count\": 103,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-12 13:57:41,277] p31920 {544935498.py:19} INFO - idx=2, tf=data/raw/4/call_center_transcript_4_transcript.txt, file_id=call_center_transcript_4, golden_summary_fpath=data/raw/0/example_prompt_transcript_golden_summary.txt\n",
      "[2024-01-12 13:57:41,279] p31920 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=titan_template.txt, reps=3\n",
      "[2024-01-12 13:57:41,280] p31920 {544935498.py:35} INFO - going to summarize idx=2, file=data/raw/4/call_center_transcript_4_transcript.txt via amazon.titan-text-express-v1\n",
      "[2024-01-12 13:57:41,282] p31920 {544935498.py:38} INFO - read prompt template from data/prompts/titan_template.txt\n",
      "[2024-01-12 13:57:41,290] p31920 {544935498.py:43} INFO - prompt for data/raw/4/call_center_transcript_4_transcript.txt has 968 tokens\n",
      "[2024-01-12 13:57:41,291] p31920 {528272729.py:4} INFO - model_id=amazon.titan-text-express-v1, prompt length is 4428 characters, 734 words\n",
      "[2024-01-12 13:57:49,333] p31920 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nA: I wanted to further discuss options for the optimal cloud instance type to host our new product recommendation model. As a refresher on the requirements - this model will be query intensive, with thousands of customers hitting the prediction API simultaneously. And it relies on a large deep neural network for the recommendations. \\n\\nB: Yes, we should go through the pros and cons again of the main instance family options available. For standard instance types without GPUs, we'd likely need to go with a high CPU and memory specification to handle the computation and concurrency needs.\\n\\nC: Standard instances would be more cost-effective, but prediction latency would suffer without GPU acceleration. The neural network calculations could be 5-10x slower based on our initial benchmarks. For a customer-facing model, slow predictions could lead to poor user experience.\\n\\nA: That's a very good point. While GPU-powered instances would be more expensive, the business value of sub-second prediction latency for users is high. We want customers to get engaging, personalized recommendations immediately to drive conversions.\\n\\nB: I agree, I think GPU acceleration makes more sense despite the increased cloud costs. In addition to the deep learning performance boost, some of the other model parallelization and tuning optimizations we're doing would also run faster on GPUs.\\n\\nC: It seems like GPU instances are the way to go then as long as the total monthly cost is affordable. However, we may be able to optimize the specific type of GPU instance to find the best balance of throughput versus cost. \\n\\nA: Definitely, the major cloud providers offer an array of GPU instance types optimized for different use cases. We should benchmark performance against our workload with NVIDIA T4 GPUs, which are cost-optimized options, as well as some higher-end options like A100 GPUs.\\n\\nC: Do you think we should also explore using something like Elastic Inference GPU attachments? Those let you augment existing instances with fractional GPU access that is more cost-effective.\\n\\nB: Hmm good question. In theory that could work well for the cost-performance balance. We'd need to test compatibility with the types of GPU optimizations we're running in the model though...\\n</conversation>\",\n",
      "  \"completion\": \"\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Evaluate the performance of NVIDIA T4 GPUs and higher-end options like A100 GPUs for the product recommendation model workload\\n- Explore using Elastic Inference GPU attachments for cost-effective GPU access\\n- Determine compatibility with GPU optimizations in the model\\n- Recommend the optimal cloud instance type based on performance, cost, and requirements\\n\\nB:\\n- Benchmark performance of NVIDIA T4 GPUs and higher-end options like A100 GPUs for the product recommendation model workload\\n- Explore using Elastic Inference GPU attachments for cost-effective GPU access\\n- Determine compatibility with GPU optimizations in the model\\n- Provide input on the optimal cloud instance type based on performance, cost, and requirements\\n\\nC:\\n- Benchmark performance of NVIDIA T4 GPUs and higher-end options like A100 GPUs for the product recommendation model workload\\n- Explore using Elastic Inference GPU attachments for cost-effective GPU access\\n- Determine compatibility with GPU optimizations in the model\\n- Provide input on the optimal cloud instance type based on performance, cost, and requirements\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 8.040509939193726,\n",
      "  \"completion_token_count\": 250,\n",
      "  \"prompt_token_count\": 976\n",
      "}\n",
      "[2024-01-12 13:57:49,337] p31920 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nA: I wanted to further discuss options for the optimal cloud instance type to host our new product recommendation model. As a refresher on the requirements - this model will be query intensive, with thousands of customers hitting the prediction API simultaneously. And it relies on a large deep neural network for the recommendations. \\n\\nB: Yes, we should go through the pros and cons again of the main instance family options available. For standard instance types without GPUs, we'd likely need to go with a high CPU and memory specification to handle the computation and concurrency needs.\\n\\nC: Standard instances would be more cost-effective, but prediction latency would suffer without GPU acceleration. The neural network calculations could be 5-10x slower based on our initial benchmarks. For a customer-facing model, slow predictions could lead to poor user experience.\\n\\nA: That's a very good point. While GPU-powered instances would be more expensive, the business value of sub-second prediction latency for users is high. We want customers to get engaging, personalized recommendations immediately to drive conversions.\\n\\nB: I agree, I think GPU acceleration makes more sense despite the increased cloud costs. In addition to the deep learning performance boost, some of the other model parallelization and tuning optimizations we're doing would also run faster on GPUs.\\n\\nC: It seems like GPU instances are the way to go then as long as the total monthly cost is affordable. However, we may be able to optimize the specific type of GPU instance to find the best balance of throughput versus cost. \\n\\nA: Definitely, the major cloud providers offer an array of GPU instance types optimized for different use cases. We should benchmark performance against our workload with NVIDIA T4 GPUs, which are cost-optimized options, as well as some higher-end options like A100 GPUs.\\n\\nC: Do you think we should also explore using something like Elastic Inference GPU attachments? Those let you augment existing instances with fractional GPU access that is more cost-effective.\\n\\nB: Hmm good question. In theory that could work well for the cost-performance balance. We'd need to test compatibility with the types of GPU optimizations we're running in the model though...\\n</conversation>\",\n",
      "  \"completion\": \"<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Evaluate the performance of NVIDIA T4 GPUs and higher-end options like A100 GPUs for the product recommendation model workload\\n- Explore using Elastic Inference GPU attachments for cost-effective GPU access\\n- Determine compatibility with GPU optimizations in the model\\n- Recommend the optimal cloud instance type based on performance, cost, and requirements\\n\\nB:\\n- Benchmark performance of NVIDIA T4 GPUs and higher-end options like A100 GPUs for the product recommendation model workload\\n- Explore using Elastic Inference GPU attachments for cost-effective GPU access\\n- Determine compatibility with GPU optimizations in the model\\n- Provide input on the optimal cloud instance type based on performance, cost, and requirements\\n\\nC:\\n- Benchmark performance of NVIDIA T4 GPUs and higher-end options like A100 GPUs for the product recommendation model workload\\n- Explore using Elastic Inference GPU attachments for cost-effective GPU access\\n- Determine compatibility with GPU optimizations in the model\\n- Provide input on the optimal cloud instance type based on performance, cost, and requirements\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 8.040509939193726,\n",
      "  \"completion_token_count\": 250,\n",
      "  \"prompt_token_count\": 976,\n",
      "  \"cost\": 0.0011808,\n",
      "  \"completion_word_count\": 176,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-12 13:57:49,341] p31920 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=anthropic_template_single_line_reason.txt, reps=3\n",
      "[2024-01-12 13:57:49,342] p31920 {544935498.py:35} INFO - going to summarize idx=2, file=data/raw/4/call_center_transcript_4_transcript.txt via anthropic.claude-instant-v1\n",
      "[2024-01-12 13:57:49,345] p31920 {544935498.py:38} INFO - read prompt template from data/prompts/anthropic_template_single_line_reason.txt\n",
      "[2024-01-12 13:57:49,352] p31920 {544935498.py:43} INFO - prompt for data/raw/4/call_center_transcript_4_transcript.txt has 950 tokens\n",
      "[2024-01-12 13:57:49,354] p31920 {528272729.py:4} INFO - model_id=anthropic.claude-instant-v1, prompt length is 4345 characters, 717 words\n",
      "[2024-01-12 13:57:52,288] p31920 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to further discuss options for the optimal cloud instance type to host our new product recommendation model. As a refresher on the requirements - this model will be query intensive, with thousands of customers hitting the prediction API simultaneously. And it relies on a large deep neural network for the recommendations. \\n\\nB: Yes, we should go through the pros and cons again of the main instance family options available. For standard instance types without GPUs, we'd likely need to go with a high CPU and memory specification to handle the computation and concurrency needs.\\n\\nC: Standard instances would be more cost-effective, but prediction latency would suffer without GPU acceleration. The neural network calculations could be 5-10x slower based on our initial benchmarks. For a customer-facing model, slow predictions could lead to poor user experience.\\n\\nA: That's a very good point. While GPU-powered instances would be more expensive, the business value of sub-second prediction latency for users is high. We want customers to get engaging, personalized recommendations immediately to drive conversions.\\n\\nB: I agree, I think GPU acceleration makes more sense despite the increased cloud costs. In addition to the deep learning performance boost, some of the other model parallelization and tuning optimizations we're doing would also run faster on GPUs.\\n\\nC: It seems like GPU instances are the way to go then as long as the total monthly cost is affordable. However, we may be able to optimize the specific type of GPU instance to find the best balance of throughput versus cost. \\n\\nA: Definitely, the major cloud providers offer an array of GPU instance types optimized for different use cases. We should benchmark performance against our workload with NVIDIA T4 GPUs, which are cost-optimized options, as well as some higher-end options like A100 GPUs.\\n\\nC: Do you think we should also explore using something like Elastic Inference GPU attachments? Those let you augment existing instances with fractional GPU access that is more cost-effective.\\n\\nB: Hmm good question. In theory that could work well for the cost-performance balance. We'd need to test compatibility with the types of GPU optimizations we're running in the model though...\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \" <output>\\nA: \\n- Benchmark performance of recommendation model against different GPU instance types from major cloud providers including NVIDIA T4 and A100 GPUs\\n- Consider exploring Elastic Inference GPU attachments and test compatibility with model optimizations\\n\\nB: \\n- Help benchmark performance against different GPU instance types\\n- Consider exploring Elastic Inference GPU attachments and provide input on compatibility with model optimizations\\n\\nC: \\n- Consider exploring Elastic Inference GPU attachments as an alternative to full GPU instances for cost-performance balance  \\n- Help benchmark performance against different GPU instance types\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 2.930567741394043,\n",
      "  \"completion_token_count\": 122,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-12 13:57:52,289] p31920 {544935498.py:76} INFO - prompt_token_count is None for anthropic.claude-instant-v1, setting it to 950 \n",
      "[2024-01-12 13:57:52,293] p31920 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to further discuss options for the optimal cloud instance type to host our new product recommendation model. As a refresher on the requirements - this model will be query intensive, with thousands of customers hitting the prediction API simultaneously. And it relies on a large deep neural network for the recommendations. \\n\\nB: Yes, we should go through the pros and cons again of the main instance family options available. For standard instance types without GPUs, we'd likely need to go with a high CPU and memory specification to handle the computation and concurrency needs.\\n\\nC: Standard instances would be more cost-effective, but prediction latency would suffer without GPU acceleration. The neural network calculations could be 5-10x slower based on our initial benchmarks. For a customer-facing model, slow predictions could lead to poor user experience.\\n\\nA: That's a very good point. While GPU-powered instances would be more expensive, the business value of sub-second prediction latency for users is high. We want customers to get engaging, personalized recommendations immediately to drive conversions.\\n\\nB: I agree, I think GPU acceleration makes more sense despite the increased cloud costs. In addition to the deep learning performance boost, some of the other model parallelization and tuning optimizations we're doing would also run faster on GPUs.\\n\\nC: It seems like GPU instances are the way to go then as long as the total monthly cost is affordable. However, we may be able to optimize the specific type of GPU instance to find the best balance of throughput versus cost. \\n\\nA: Definitely, the major cloud providers offer an array of GPU instance types optimized for different use cases. We should benchmark performance against our workload with NVIDIA T4 GPUs, which are cost-optimized options, as well as some higher-end options like A100 GPUs.\\n\\nC: Do you think we should also explore using something like Elastic Inference GPU attachments? Those let you augment existing instances with fractional GPU access that is more cost-effective.\\n\\nB: Hmm good question. In theory that could work well for the cost-performance balance. We'd need to test compatibility with the types of GPU optimizations we're running in the model though...\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \"<output>\\nA: \\n- Benchmark performance of recommendation model against different GPU instance types from major cloud providers including NVIDIA T4 and A100 GPUs\\n- Consider exploring Elastic Inference GPU attachments and test compatibility with model optimizations\\n\\nB: \\n- Help benchmark performance against different GPU instance types\\n- Consider exploring Elastic Inference GPU attachments and provide input on compatibility with model optimizations\\n\\nC: \\n- Consider exploring Elastic Inference GPU attachments as an alternative to full GPU instances for cost-performance balance  \\n- Help benchmark performance against different GPU instance types\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 2.930567741394043,\n",
      "  \"completion_token_count\": 122,\n",
      "  \"prompt_token_count\": 950,\n",
      "  \"cost\": 0.00222072,\n",
      "  \"completion_word_count\": 89,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-12 13:57:52,298] p31920 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=cohere_template.txt, reps=3\n",
      "[2024-01-12 13:57:52,299] p31920 {544935498.py:35} INFO - going to summarize idx=2, file=data/raw/4/call_center_transcript_4_transcript.txt via cohere.command-text-v14\n",
      "[2024-01-12 13:57:52,300] p31920 {544935498.py:38} INFO - read prompt template from data/prompts/cohere_template.txt\n",
      "[2024-01-12 13:57:52,308] p31920 {544935498.py:43} INFO - prompt for data/raw/4/call_center_transcript_4_transcript.txt has 963 tokens\n",
      "[2024-01-12 13:57:52,309] p31920 {528272729.py:4} INFO - model_id=cohere.command-text-v14, prompt length is 4423 characters, 733 words\n",
      "[2024-01-12 13:58:01,701] p31920 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to further discuss options for the optimal cloud instance type to host our new product recommendation model. As a refresher on the requirements - this model will be query intensive, with thousands of customers hitting the prediction API simultaneously. And it relies on a large deep neural network for the recommendations. \\n\\nB: Yes, we should go through the pros and cons again of the main instance family options available. For standard instance types without GPUs, we'd likely need to go with a high CPU and memory specification to handle the computation and concurrency needs.\\n\\nC: Standard instances would be more cost-effective, but prediction latency would suffer without GPU acceleration. The neural network calculations could be 5-10x slower based on our initial benchmarks. For a customer-facing model, slow predictions could lead to poor user experience.\\n\\nA: That's a very good point. While GPU-powered instances would be more expensive, the business value of sub-second prediction latency for users is high. We want customers to get engaging, personalized recommendations immediately to drive conversions.\\n\\nB: I agree, I think GPU acceleration makes more sense despite the increased cloud costs. In addition to the deep learning performance boost, some of the other model parallelization and tuning optimizations we're doing would also run faster on GPUs.\\n\\nC: It seems like GPU instances are the way to go then as long as the total monthly cost is affordable. However, we may be able to optimize the specific type of GPU instance to find the best balance of throughput versus cost. \\n\\nA: Definitely, the major cloud providers offer an array of GPU instance types optimized for different use cases. We should benchmark performance against our workload with NVIDIA T4 GPUs, which are cost-optimized options, as well as some higher-end options like A100 GPUs.\\n\\nC: Do you think we should also explore using something like Elastic Inference GPU attachments? Those let you augment existing instances with fractional GPU access that is more cost-effective.\\n\\nB: Hmm good question. In theory that could work well for the cost-performance balance. We'd need to test compatibility with the types of GPU optimizations we're running in the model though...\\n</conversation>\",\n",
      "  \"completion\": \" Here are some action items for each speaker:\\n\\nA:\\n- Lead a discussion on the requirements of the product recommendation model\\n- Assess the potential of different cloud instance types to host the model (including standard vs GPU-powered instances)\\n- Take into account the cost-effectiveness and performance of each option \\n- Suggest possible options for benchmarking, based on the requirements and needs of the model\\n\\nB:\\n- Provide technical expertise on the potential pros and cons of different cloud instance options\\n- Offer insights on how different instance types could optimize or hinder model performance \\n- Collaborate on assessing the business implications of model performance versus cost implications\\n\\nC:\\n- Highlight the potential drawbacks of different options (such as the increased latency of standard instances without GPU acceleration) \\n- Offer to contribute to any benchmarking tests proposed by A \\n- Lead any subsequent discussions on possible ways to optimize different options\\n\\n\\nWould you like me to elaborate on any of these action items? \",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 9.390348196029663,\n",
      "  \"completion_token_count\": 217,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-12 13:58:01,702] p31920 {544935498.py:76} INFO - prompt_token_count is None for cohere.command-text-v14, setting it to 963 \n",
      "[2024-01-12 13:58:01,705] p31920 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to further discuss options for the optimal cloud instance type to host our new product recommendation model. As a refresher on the requirements - this model will be query intensive, with thousands of customers hitting the prediction API simultaneously. And it relies on a large deep neural network for the recommendations. \\n\\nB: Yes, we should go through the pros and cons again of the main instance family options available. For standard instance types without GPUs, we'd likely need to go with a high CPU and memory specification to handle the computation and concurrency needs.\\n\\nC: Standard instances would be more cost-effective, but prediction latency would suffer without GPU acceleration. The neural network calculations could be 5-10x slower based on our initial benchmarks. For a customer-facing model, slow predictions could lead to poor user experience.\\n\\nA: That's a very good point. While GPU-powered instances would be more expensive, the business value of sub-second prediction latency for users is high. We want customers to get engaging, personalized recommendations immediately to drive conversions.\\n\\nB: I agree, I think GPU acceleration makes more sense despite the increased cloud costs. In addition to the deep learning performance boost, some of the other model parallelization and tuning optimizations we're doing would also run faster on GPUs.\\n\\nC: It seems like GPU instances are the way to go then as long as the total monthly cost is affordable. However, we may be able to optimize the specific type of GPU instance to find the best balance of throughput versus cost. \\n\\nA: Definitely, the major cloud providers offer an array of GPU instance types optimized for different use cases. We should benchmark performance against our workload with NVIDIA T4 GPUs, which are cost-optimized options, as well as some higher-end options like A100 GPUs.\\n\\nC: Do you think we should also explore using something like Elastic Inference GPU attachments? Those let you augment existing instances with fractional GPU access that is more cost-effective.\\n\\nB: Hmm good question. In theory that could work well for the cost-performance balance. We'd need to test compatibility with the types of GPU optimizations we're running in the model though...\\n</conversation>\",\n",
      "  \"completion\": \"Here are some action items for each speaker:\\n\\nA:\\n- Lead a discussion on the requirements of the product recommendation model\\n- Assess the potential of different cloud instance types to host the model (including standard vs GPU-powered instances)\\n- Take into account the cost-effectiveness and performance of each option \\n- Suggest possible options for benchmarking, based on the requirements and needs of the model\\n\\nB:\\n- Provide technical expertise on the potential pros and cons of different cloud instance options\\n- Offer insights on how different instance types could optimize or hinder model performance \\n- Collaborate on assessing the business implications of model performance versus cost implications\\n\\nC:\\n- Highlight the potential drawbacks of different options (such as the increased latency of standard instances without GPU acceleration) \\n- Offer to contribute to any benchmarking tests proposed by A \\n- Lead any subsequent discussions on possible ways to optimize different options\\n\\n\\nWould you like me to elaborate on any of these action items?\",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 9.390348196029663,\n",
      "  \"completion_token_count\": 217,\n",
      "  \"prompt_token_count\": 963,\n",
      "  \"cost\": 0.0018785,\n",
      "  \"completion_word_count\": 163,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-12 13:58:01,708] p31920 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=titan_template.txt, reps=3\n",
      "[2024-01-12 13:58:01,709] p31920 {544935498.py:35} INFO - going to summarize idx=2, file=data/raw/4/call_center_transcript_4_transcript.txt via amazon.titan-text-express-v1\n",
      "[2024-01-12 13:58:01,722] p31920 {544935498.py:38} INFO - read prompt template from data/prompts/titan_template.txt\n",
      "[2024-01-12 13:58:01,729] p31920 {544935498.py:43} INFO - prompt for data/raw/4/call_center_transcript_4_transcript.txt has 968 tokens\n",
      "[2024-01-12 13:58:01,736] p31920 {528272729.py:4} INFO - model_id=amazon.titan-text-express-v1, prompt length is 4428 characters, 734 words\n",
      "[2024-01-12 13:58:07,837] p31920 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nA: I wanted to further discuss options for the optimal cloud instance type to host our new product recommendation model. As a refresher on the requirements - this model will be query intensive, with thousands of customers hitting the prediction API simultaneously. And it relies on a large deep neural network for the recommendations. \\n\\nB: Yes, we should go through the pros and cons again of the main instance family options available. For standard instance types without GPUs, we'd likely need to go with a high CPU and memory specification to handle the computation and concurrency needs.\\n\\nC: Standard instances would be more cost-effective, but prediction latency would suffer without GPU acceleration. The neural network calculations could be 5-10x slower based on our initial benchmarks. For a customer-facing model, slow predictions could lead to poor user experience.\\n\\nA: That's a very good point. While GPU-powered instances would be more expensive, the business value of sub-second prediction latency for users is high. We want customers to get engaging, personalized recommendations immediately to drive conversions.\\n\\nB: I agree, I think GPU acceleration makes more sense despite the increased cloud costs. In addition to the deep learning performance boost, some of the other model parallelization and tuning optimizations we're doing would also run faster on GPUs.\\n\\nC: It seems like GPU instances are the way to go then as long as the total monthly cost is affordable. However, we may be able to optimize the specific type of GPU instance to find the best balance of throughput versus cost. \\n\\nA: Definitely, the major cloud providers offer an array of GPU instance types optimized for different use cases. We should benchmark performance against our workload with NVIDIA T4 GPUs, which are cost-optimized options, as well as some higher-end options like A100 GPUs.\\n\\nC: Do you think we should also explore using something like Elastic Inference GPU attachments? Those let you augment existing instances with fractional GPU access that is more cost-effective.\\n\\nB: Hmm good question. In theory that could work well for the cost-performance balance. We'd need to test compatibility with the types of GPU optimizations we're running in the model though...\\n</conversation>\",\n",
      "  \"completion\": \"\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Evaluate cost-optimized GPU instance types like NVIDIA T4 GPUs and higher-end options like A100 GPUs for benchmarking performance against workload\\n- Explore using Elastic Inference GPU attachments for cost-effective GPU access\\n- Determine compatibility with model's GPU optimizations\\n\\nB:\\n- None explicitly stated\\n\\nC:\\n- Research and evaluate cost-optimized GPU instance types like NVIDIA T4 GPUs and higher-end options like A100 GPUs for benchmarking performance against workload\\n- Explore using Elastic Inference GPU attachments for cost-effective GPU access\\n- Determine compatibility with model's GPU optimizations\\n- Recommend the optimal cloud instance type based on cost, performance, and compatibility requirements\\n- Prepare cost estimates and present findings to stakeholders for decision-making\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 6.09889817237854,\n",
      "  \"completion_token_count\": 189,\n",
      "  \"prompt_token_count\": 976\n",
      "}\n",
      "[2024-01-12 13:58:07,839] p31920 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nA: I wanted to further discuss options for the optimal cloud instance type to host our new product recommendation model. As a refresher on the requirements - this model will be query intensive, with thousands of customers hitting the prediction API simultaneously. And it relies on a large deep neural network for the recommendations. \\n\\nB: Yes, we should go through the pros and cons again of the main instance family options available. For standard instance types without GPUs, we'd likely need to go with a high CPU and memory specification to handle the computation and concurrency needs.\\n\\nC: Standard instances would be more cost-effective, but prediction latency would suffer without GPU acceleration. The neural network calculations could be 5-10x slower based on our initial benchmarks. For a customer-facing model, slow predictions could lead to poor user experience.\\n\\nA: That's a very good point. While GPU-powered instances would be more expensive, the business value of sub-second prediction latency for users is high. We want customers to get engaging, personalized recommendations immediately to drive conversions.\\n\\nB: I agree, I think GPU acceleration makes more sense despite the increased cloud costs. In addition to the deep learning performance boost, some of the other model parallelization and tuning optimizations we're doing would also run faster on GPUs.\\n\\nC: It seems like GPU instances are the way to go then as long as the total monthly cost is affordable. However, we may be able to optimize the specific type of GPU instance to find the best balance of throughput versus cost. \\n\\nA: Definitely, the major cloud providers offer an array of GPU instance types optimized for different use cases. We should benchmark performance against our workload with NVIDIA T4 GPUs, which are cost-optimized options, as well as some higher-end options like A100 GPUs.\\n\\nC: Do you think we should also explore using something like Elastic Inference GPU attachments? Those let you augment existing instances with fractional GPU access that is more cost-effective.\\n\\nB: Hmm good question. In theory that could work well for the cost-performance balance. We'd need to test compatibility with the types of GPU optimizations we're running in the model though...\\n</conversation>\",\n",
      "  \"completion\": \"<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Evaluate cost-optimized GPU instance types like NVIDIA T4 GPUs and higher-end options like A100 GPUs for benchmarking performance against workload\\n- Explore using Elastic Inference GPU attachments for cost-effective GPU access\\n- Determine compatibility with model's GPU optimizations\\n\\nB:\\n- None explicitly stated\\n\\nC:\\n- Research and evaluate cost-optimized GPU instance types like NVIDIA T4 GPUs and higher-end options like A100 GPUs for benchmarking performance against workload\\n- Explore using Elastic Inference GPU attachments for cost-effective GPU access\\n- Determine compatibility with model's GPU optimizations\\n- Recommend the optimal cloud instance type based on cost, performance, and compatibility requirements\\n- Prepare cost estimates and present findings to stakeholders for decision-making\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 6.09889817237854,\n",
      "  \"completion_token_count\": 189,\n",
      "  \"prompt_token_count\": 976,\n",
      "  \"cost\": 0.0010832,\n",
      "  \"completion_word_count\": 124,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-12 13:58:07,841] p31920 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=anthropic_template_single_line_reason.txt, reps=3\n",
      "[2024-01-12 13:58:07,842] p31920 {544935498.py:35} INFO - going to summarize idx=2, file=data/raw/4/call_center_transcript_4_transcript.txt via anthropic.claude-instant-v1\n",
      "[2024-01-12 13:58:07,844] p31920 {544935498.py:38} INFO - read prompt template from data/prompts/anthropic_template_single_line_reason.txt\n",
      "[2024-01-12 13:58:07,851] p31920 {544935498.py:43} INFO - prompt for data/raw/4/call_center_transcript_4_transcript.txt has 950 tokens\n",
      "[2024-01-12 13:58:07,854] p31920 {528272729.py:4} INFO - model_id=anthropic.claude-instant-v1, prompt length is 4345 characters, 717 words\n",
      "[2024-01-12 13:58:09,975] p31920 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to further discuss options for the optimal cloud instance type to host our new product recommendation model. As a refresher on the requirements - this model will be query intensive, with thousands of customers hitting the prediction API simultaneously. And it relies on a large deep neural network for the recommendations. \\n\\nB: Yes, we should go through the pros and cons again of the main instance family options available. For standard instance types without GPUs, we'd likely need to go with a high CPU and memory specification to handle the computation and concurrency needs.\\n\\nC: Standard instances would be more cost-effective, but prediction latency would suffer without GPU acceleration. The neural network calculations could be 5-10x slower based on our initial benchmarks. For a customer-facing model, slow predictions could lead to poor user experience.\\n\\nA: That's a very good point. While GPU-powered instances would be more expensive, the business value of sub-second prediction latency for users is high. We want customers to get engaging, personalized recommendations immediately to drive conversions.\\n\\nB: I agree, I think GPU acceleration makes more sense despite the increased cloud costs. In addition to the deep learning performance boost, some of the other model parallelization and tuning optimizations we're doing would also run faster on GPUs.\\n\\nC: It seems like GPU instances are the way to go then as long as the total monthly cost is affordable. However, we may be able to optimize the specific type of GPU instance to find the best balance of throughput versus cost. \\n\\nA: Definitely, the major cloud providers offer an array of GPU instance types optimized for different use cases. We should benchmark performance against our workload with NVIDIA T4 GPUs, which are cost-optimized options, as well as some higher-end options like A100 GPUs.\\n\\nC: Do you think we should also explore using something like Elastic Inference GPU attachments? Those let you augment existing instances with fractional GPU access that is more cost-effective.\\n\\nB: Hmm good question. In theory that could work well for the cost-performance balance. We'd need to test compatibility with the types of GPU optimizations we're running in the model though...\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \" <output>\\nA: \\n- Benchmark performance of recommendation model against different GPU instance types from major cloud providers including NVIDIA T4 and A100 GPUs\\n- Consider exploring Elastic Inference GPU attachments and test compatibility with model optimizations\\n\\nB: \\n- Help benchmark performance against different GPU instance types\\n- Consider exploring Elastic Inference GPU attachments and provide input on compatibility with model optimizations\\n\\nC: \\n- Consider exploring Elastic Inference GPU attachments as an alternative to full GPU instances for cost-performance balance  \\n- Help benchmark performance against different GPU instance types\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 2.119814157485962,\n",
      "  \"completion_token_count\": 122,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-12 13:58:09,976] p31920 {544935498.py:76} INFO - prompt_token_count is None for anthropic.claude-instant-v1, setting it to 950 \n",
      "[2024-01-12 13:58:09,977] p31920 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to further discuss options for the optimal cloud instance type to host our new product recommendation model. As a refresher on the requirements - this model will be query intensive, with thousands of customers hitting the prediction API simultaneously. And it relies on a large deep neural network for the recommendations. \\n\\nB: Yes, we should go through the pros and cons again of the main instance family options available. For standard instance types without GPUs, we'd likely need to go with a high CPU and memory specification to handle the computation and concurrency needs.\\n\\nC: Standard instances would be more cost-effective, but prediction latency would suffer without GPU acceleration. The neural network calculations could be 5-10x slower based on our initial benchmarks. For a customer-facing model, slow predictions could lead to poor user experience.\\n\\nA: That's a very good point. While GPU-powered instances would be more expensive, the business value of sub-second prediction latency for users is high. We want customers to get engaging, personalized recommendations immediately to drive conversions.\\n\\nB: I agree, I think GPU acceleration makes more sense despite the increased cloud costs. In addition to the deep learning performance boost, some of the other model parallelization and tuning optimizations we're doing would also run faster on GPUs.\\n\\nC: It seems like GPU instances are the way to go then as long as the total monthly cost is affordable. However, we may be able to optimize the specific type of GPU instance to find the best balance of throughput versus cost. \\n\\nA: Definitely, the major cloud providers offer an array of GPU instance types optimized for different use cases. We should benchmark performance against our workload with NVIDIA T4 GPUs, which are cost-optimized options, as well as some higher-end options like A100 GPUs.\\n\\nC: Do you think we should also explore using something like Elastic Inference GPU attachments? Those let you augment existing instances with fractional GPU access that is more cost-effective.\\n\\nB: Hmm good question. In theory that could work well for the cost-performance balance. We'd need to test compatibility with the types of GPU optimizations we're running in the model though...\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \"<output>\\nA: \\n- Benchmark performance of recommendation model against different GPU instance types from major cloud providers including NVIDIA T4 and A100 GPUs\\n- Consider exploring Elastic Inference GPU attachments and test compatibility with model optimizations\\n\\nB: \\n- Help benchmark performance against different GPU instance types\\n- Consider exploring Elastic Inference GPU attachments and provide input on compatibility with model optimizations\\n\\nC: \\n- Consider exploring Elastic Inference GPU attachments as an alternative to full GPU instances for cost-performance balance  \\n- Help benchmark performance against different GPU instance types\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 2.119814157485962,\n",
      "  \"completion_token_count\": 122,\n",
      "  \"prompt_token_count\": 950,\n",
      "  \"cost\": 0.00222072,\n",
      "  \"completion_word_count\": 89,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-12 13:58:09,978] p31920 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=cohere_template.txt, reps=3\n",
      "[2024-01-12 13:58:09,979] p31920 {544935498.py:35} INFO - going to summarize idx=2, file=data/raw/4/call_center_transcript_4_transcript.txt via cohere.command-text-v14\n",
      "[2024-01-12 13:58:09,980] p31920 {544935498.py:38} INFO - read prompt template from data/prompts/cohere_template.txt\n",
      "[2024-01-12 13:58:09,984] p31920 {544935498.py:43} INFO - prompt for data/raw/4/call_center_transcript_4_transcript.txt has 963 tokens\n",
      "[2024-01-12 13:58:09,984] p31920 {528272729.py:4} INFO - model_id=cohere.command-text-v14, prompt length is 4423 characters, 733 words\n",
      "[2024-01-12 13:58:18,885] p31920 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to further discuss options for the optimal cloud instance type to host our new product recommendation model. As a refresher on the requirements - this model will be query intensive, with thousands of customers hitting the prediction API simultaneously. And it relies on a large deep neural network for the recommendations. \\n\\nB: Yes, we should go through the pros and cons again of the main instance family options available. For standard instance types without GPUs, we'd likely need to go with a high CPU and memory specification to handle the computation and concurrency needs.\\n\\nC: Standard instances would be more cost-effective, but prediction latency would suffer without GPU acceleration. The neural network calculations could be 5-10x slower based on our initial benchmarks. For a customer-facing model, slow predictions could lead to poor user experience.\\n\\nA: That's a very good point. While GPU-powered instances would be more expensive, the business value of sub-second prediction latency for users is high. We want customers to get engaging, personalized recommendations immediately to drive conversions.\\n\\nB: I agree, I think GPU acceleration makes more sense despite the increased cloud costs. In addition to the deep learning performance boost, some of the other model parallelization and tuning optimizations we're doing would also run faster on GPUs.\\n\\nC: It seems like GPU instances are the way to go then as long as the total monthly cost is affordable. However, we may be able to optimize the specific type of GPU instance to find the best balance of throughput versus cost. \\n\\nA: Definitely, the major cloud providers offer an array of GPU instance types optimized for different use cases. We should benchmark performance against our workload with NVIDIA T4 GPUs, which are cost-optimized options, as well as some higher-end options like A100 GPUs.\\n\\nC: Do you think we should also explore using something like Elastic Inference GPU attachments? Those let you augment existing instances with fractional GPU access that is more cost-effective.\\n\\nB: Hmm good question. In theory that could work well for the cost-performance balance. We'd need to test compatibility with the types of GPU optimizations we're running in the model though...\\n</conversation>\",\n",
      "  \"completion\": \" Here are some action items for each speaker:\\n\\nA:\\n- Lead a discussion on the requirements of the product recommendation model\\n- Assess the potential of different cloud instance types to host the model (including standard vs GPU-powered instances)\\n- Take into account the cost-effectiveness and performance of each option \\n- Suggest possible options for benchmarking (e.g. NVIDIA T4 GPUs or Elastic Inference GPU attachments)\\n\\nB: \\n- Provide technical analysis and comparison of different cloud instance types\\n- Assess the potential performance gains of GPU-powered instances vs standard instances \\n- Consider the potential of different optimization techniques with different GPU types \\n- Confirm the compatibility of different GPU types with the current optimizations in the model \\n\\nC:\\n- Highlight the potential for latency improvements with GPU instances and how this could drive business value\\n- Support the exploration of cost-effective options, including Elastic Inference GPU attachments\\n- Collaborate with A and B on how to best balance throughput versus cost going forward \\n\\nPlease note these action items are based on the conversation transcript provided. It's possible that further details or context could alter some of the action items. Do you have any further information you'd like to add? \",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 8.899265050888062,\n",
      "  \"completion_token_count\": 264,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-12 13:58:18,885] p31920 {544935498.py:76} INFO - prompt_token_count is None for cohere.command-text-v14, setting it to 963 \n",
      "[2024-01-12 13:58:18,887] p31920 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to further discuss options for the optimal cloud instance type to host our new product recommendation model. As a refresher on the requirements - this model will be query intensive, with thousands of customers hitting the prediction API simultaneously. And it relies on a large deep neural network for the recommendations. \\n\\nB: Yes, we should go through the pros and cons again of the main instance family options available. For standard instance types without GPUs, we'd likely need to go with a high CPU and memory specification to handle the computation and concurrency needs.\\n\\nC: Standard instances would be more cost-effective, but prediction latency would suffer without GPU acceleration. The neural network calculations could be 5-10x slower based on our initial benchmarks. For a customer-facing model, slow predictions could lead to poor user experience.\\n\\nA: That's a very good point. While GPU-powered instances would be more expensive, the business value of sub-second prediction latency for users is high. We want customers to get engaging, personalized recommendations immediately to drive conversions.\\n\\nB: I agree, I think GPU acceleration makes more sense despite the increased cloud costs. In addition to the deep learning performance boost, some of the other model parallelization and tuning optimizations we're doing would also run faster on GPUs.\\n\\nC: It seems like GPU instances are the way to go then as long as the total monthly cost is affordable. However, we may be able to optimize the specific type of GPU instance to find the best balance of throughput versus cost. \\n\\nA: Definitely, the major cloud providers offer an array of GPU instance types optimized for different use cases. We should benchmark performance against our workload with NVIDIA T4 GPUs, which are cost-optimized options, as well as some higher-end options like A100 GPUs.\\n\\nC: Do you think we should also explore using something like Elastic Inference GPU attachments? Those let you augment existing instances with fractional GPU access that is more cost-effective.\\n\\nB: Hmm good question. In theory that could work well for the cost-performance balance. We'd need to test compatibility with the types of GPU optimizations we're running in the model though...\\n</conversation>\",\n",
      "  \"completion\": \"Here are some action items for each speaker:\\n\\nA:\\n- Lead a discussion on the requirements of the product recommendation model\\n- Assess the potential of different cloud instance types to host the model (including standard vs GPU-powered instances)\\n- Take into account the cost-effectiveness and performance of each option \\n- Suggest possible options for benchmarking (e.g. NVIDIA T4 GPUs or Elastic Inference GPU attachments)\\n\\nB: \\n- Provide technical analysis and comparison of different cloud instance types\\n- Assess the potential performance gains of GPU-powered instances vs standard instances \\n- Consider the potential of different optimization techniques with different GPU types \\n- Confirm the compatibility of different GPU types with the current optimizations in the model \\n\\nC:\\n- Highlight the potential for latency improvements with GPU instances and how this could drive business value\\n- Support the exploration of cost-effective options, including Elastic Inference GPU attachments\\n- Collaborate with A and B on how to best balance throughput versus cost going forward \\n\\nPlease note these action items are based on the conversation transcript provided. It's possible that further details or context could alter some of the action items. Do you have any further information you'd like to add?\",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 8.899265050888062,\n",
      "  \"completion_token_count\": 264,\n",
      "  \"prompt_token_count\": 963,\n",
      "  \"cost\": 0.0019725000000000003,\n",
      "  \"completion_word_count\": 198,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-12 13:58:18,887] p31920 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=titan_template.txt, reps=3\n",
      "[2024-01-12 13:58:18,888] p31920 {544935498.py:35} INFO - going to summarize idx=2, file=data/raw/4/call_center_transcript_4_transcript.txt via amazon.titan-text-express-v1\n",
      "[2024-01-12 13:58:18,889] p31920 {544935498.py:38} INFO - read prompt template from data/prompts/titan_template.txt\n",
      "[2024-01-12 13:58:18,892] p31920 {544935498.py:43} INFO - prompt for data/raw/4/call_center_transcript_4_transcript.txt has 968 tokens\n",
      "[2024-01-12 13:58:18,892] p31920 {528272729.py:4} INFO - model_id=amazon.titan-text-express-v1, prompt length is 4428 characters, 734 words\n",
      "[2024-01-12 13:58:25,072] p31920 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nA: I wanted to further discuss options for the optimal cloud instance type to host our new product recommendation model. As a refresher on the requirements - this model will be query intensive, with thousands of customers hitting the prediction API simultaneously. And it relies on a large deep neural network for the recommendations. \\n\\nB: Yes, we should go through the pros and cons again of the main instance family options available. For standard instance types without GPUs, we'd likely need to go with a high CPU and memory specification to handle the computation and concurrency needs.\\n\\nC: Standard instances would be more cost-effective, but prediction latency would suffer without GPU acceleration. The neural network calculations could be 5-10x slower based on our initial benchmarks. For a customer-facing model, slow predictions could lead to poor user experience.\\n\\nA: That's a very good point. While GPU-powered instances would be more expensive, the business value of sub-second prediction latency for users is high. We want customers to get engaging, personalized recommendations immediately to drive conversions.\\n\\nB: I agree, I think GPU acceleration makes more sense despite the increased cloud costs. In addition to the deep learning performance boost, some of the other model parallelization and tuning optimizations we're doing would also run faster on GPUs.\\n\\nC: It seems like GPU instances are the way to go then as long as the total monthly cost is affordable. However, we may be able to optimize the specific type of GPU instance to find the best balance of throughput versus cost. \\n\\nA: Definitely, the major cloud providers offer an array of GPU instance types optimized for different use cases. We should benchmark performance against our workload with NVIDIA T4 GPUs, which are cost-optimized options, as well as some higher-end options like A100 GPUs.\\n\\nC: Do you think we should also explore using something like Elastic Inference GPU attachments? Those let you augment existing instances with fractional GPU access that is more cost-effective.\\n\\nB: Hmm good question. In theory that could work well for the cost-performance balance. We'd need to test compatibility with the types of GPU optimizations we're running in the model though...\\n</conversation>\",\n",
      "  \"completion\": \"\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Evaluate the performance of NVIDIA T4 GPUs and higher-end options like A100 GPUs for the product recommendation model workload\\n- Explore using Elastic Inference GPU attachments for cost-effective GPU access\\n- Benchmark performance with different instance types and configurations to find the optimal balance of throughput and cost\\n\\nB:\\n- Research and test compatibility of Elastic Inference GPU attachments with the model's GPU optimizations\\n- Provide recommendations on the optimal instance type and configuration based on performance benchmarks and cost considerations\\n\\nC:\\n- Research and compare different GPU instance types offered by major cloud providers\\n- Provide recommendations on the optimal instance type and configuration based on performance benchmarks and cost considerations\\n- Assist in benchmarking and testing the performance of Elastic Inference GPU attachments with the model workload\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 6.177515983581543,\n",
      "  \"completion_token_count\": 186,\n",
      "  \"prompt_token_count\": 976\n",
      "}\n",
      "[2024-01-12 13:58:25,073] p31920 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nA: I wanted to further discuss options for the optimal cloud instance type to host our new product recommendation model. As a refresher on the requirements - this model will be query intensive, with thousands of customers hitting the prediction API simultaneously. And it relies on a large deep neural network for the recommendations. \\n\\nB: Yes, we should go through the pros and cons again of the main instance family options available. For standard instance types without GPUs, we'd likely need to go with a high CPU and memory specification to handle the computation and concurrency needs.\\n\\nC: Standard instances would be more cost-effective, but prediction latency would suffer without GPU acceleration. The neural network calculations could be 5-10x slower based on our initial benchmarks. For a customer-facing model, slow predictions could lead to poor user experience.\\n\\nA: That's a very good point. While GPU-powered instances would be more expensive, the business value of sub-second prediction latency for users is high. We want customers to get engaging, personalized recommendations immediately to drive conversions.\\n\\nB: I agree, I think GPU acceleration makes more sense despite the increased cloud costs. In addition to the deep learning performance boost, some of the other model parallelization and tuning optimizations we're doing would also run faster on GPUs.\\n\\nC: It seems like GPU instances are the way to go then as long as the total monthly cost is affordable. However, we may be able to optimize the specific type of GPU instance to find the best balance of throughput versus cost. \\n\\nA: Definitely, the major cloud providers offer an array of GPU instance types optimized for different use cases. We should benchmark performance against our workload with NVIDIA T4 GPUs, which are cost-optimized options, as well as some higher-end options like A100 GPUs.\\n\\nC: Do you think we should also explore using something like Elastic Inference GPU attachments? Those let you augment existing instances with fractional GPU access that is more cost-effective.\\n\\nB: Hmm good question. In theory that could work well for the cost-performance balance. We'd need to test compatibility with the types of GPU optimizations we're running in the model though...\\n</conversation>\",\n",
      "  \"completion\": \"<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Evaluate the performance of NVIDIA T4 GPUs and higher-end options like A100 GPUs for the product recommendation model workload\\n- Explore using Elastic Inference GPU attachments for cost-effective GPU access\\n- Benchmark performance with different instance types and configurations to find the optimal balance of throughput and cost\\n\\nB:\\n- Research and test compatibility of Elastic Inference GPU attachments with the model's GPU optimizations\\n- Provide recommendations on the optimal instance type and configuration based on performance benchmarks and cost considerations\\n\\nC:\\n- Research and compare different GPU instance types offered by major cloud providers\\n- Provide recommendations on the optimal instance type and configuration based on performance benchmarks and cost considerations\\n- Assist in benchmarking and testing the performance of Elastic Inference GPU attachments with the model workload\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 6.177515983581543,\n",
      "  \"completion_token_count\": 186,\n",
      "  \"prompt_token_count\": 976,\n",
      "  \"cost\": 0.0010784,\n",
      "  \"completion_word_count\": 143,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-12 13:58:25,074] p31920 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=anthropic_template_single_line_reason.txt, reps=3\n",
      "[2024-01-12 13:58:25,074] p31920 {544935498.py:35} INFO - going to summarize idx=2, file=data/raw/4/call_center_transcript_4_transcript.txt via anthropic.claude-instant-v1\n",
      "[2024-01-12 13:58:25,075] p31920 {544935498.py:38} INFO - read prompt template from data/prompts/anthropic_template_single_line_reason.txt\n",
      "[2024-01-12 13:58:25,078] p31920 {544935498.py:43} INFO - prompt for data/raw/4/call_center_transcript_4_transcript.txt has 950 tokens\n",
      "[2024-01-12 13:58:25,078] p31920 {528272729.py:4} INFO - model_id=anthropic.claude-instant-v1, prompt length is 4345 characters, 717 words\n",
      "[2024-01-12 13:58:27,271] p31920 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to further discuss options for the optimal cloud instance type to host our new product recommendation model. As a refresher on the requirements - this model will be query intensive, with thousands of customers hitting the prediction API simultaneously. And it relies on a large deep neural network for the recommendations. \\n\\nB: Yes, we should go through the pros and cons again of the main instance family options available. For standard instance types without GPUs, we'd likely need to go with a high CPU and memory specification to handle the computation and concurrency needs.\\n\\nC: Standard instances would be more cost-effective, but prediction latency would suffer without GPU acceleration. The neural network calculations could be 5-10x slower based on our initial benchmarks. For a customer-facing model, slow predictions could lead to poor user experience.\\n\\nA: That's a very good point. While GPU-powered instances would be more expensive, the business value of sub-second prediction latency for users is high. We want customers to get engaging, personalized recommendations immediately to drive conversions.\\n\\nB: I agree, I think GPU acceleration makes more sense despite the increased cloud costs. In addition to the deep learning performance boost, some of the other model parallelization and tuning optimizations we're doing would also run faster on GPUs.\\n\\nC: It seems like GPU instances are the way to go then as long as the total monthly cost is affordable. However, we may be able to optimize the specific type of GPU instance to find the best balance of throughput versus cost. \\n\\nA: Definitely, the major cloud providers offer an array of GPU instance types optimized for different use cases. We should benchmark performance against our workload with NVIDIA T4 GPUs, which are cost-optimized options, as well as some higher-end options like A100 GPUs.\\n\\nC: Do you think we should also explore using something like Elastic Inference GPU attachments? Those let you augment existing instances with fractional GPU access that is more cost-effective.\\n\\nB: Hmm good question. In theory that could work well for the cost-performance balance. We'd need to test compatibility with the types of GPU optimizations we're running in the model though...\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \" <output>\\nA: \\n- Benchmark performance of recommendation model against different GPU instance types from major cloud providers including NVIDIA T4 and A100 GPUs\\n- Consider exploring Elastic Inference GPU attachments and test compatibility with model optimizations\\n\\nB: \\n- Help benchmark performance against different GPU instance types\\n- Consider exploring Elastic Inference GPU attachments and provide input on compatibility with model optimizations\\n\\nC: \\n- Consider exploring Elastic Inference GPU attachments as an alternative to full GPU instances for cost-performance balance  \\n- Help benchmark performance against different GPU instance types\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 2.189725875854492,\n",
      "  \"completion_token_count\": 122,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-12 13:58:27,272] p31920 {544935498.py:76} INFO - prompt_token_count is None for anthropic.claude-instant-v1, setting it to 950 \n",
      "[2024-01-12 13:58:27,276] p31920 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to further discuss options for the optimal cloud instance type to host our new product recommendation model. As a refresher on the requirements - this model will be query intensive, with thousands of customers hitting the prediction API simultaneously. And it relies on a large deep neural network for the recommendations. \\n\\nB: Yes, we should go through the pros and cons again of the main instance family options available. For standard instance types without GPUs, we'd likely need to go with a high CPU and memory specification to handle the computation and concurrency needs.\\n\\nC: Standard instances would be more cost-effective, but prediction latency would suffer without GPU acceleration. The neural network calculations could be 5-10x slower based on our initial benchmarks. For a customer-facing model, slow predictions could lead to poor user experience.\\n\\nA: That's a very good point. While GPU-powered instances would be more expensive, the business value of sub-second prediction latency for users is high. We want customers to get engaging, personalized recommendations immediately to drive conversions.\\n\\nB: I agree, I think GPU acceleration makes more sense despite the increased cloud costs. In addition to the deep learning performance boost, some of the other model parallelization and tuning optimizations we're doing would also run faster on GPUs.\\n\\nC: It seems like GPU instances are the way to go then as long as the total monthly cost is affordable. However, we may be able to optimize the specific type of GPU instance to find the best balance of throughput versus cost. \\n\\nA: Definitely, the major cloud providers offer an array of GPU instance types optimized for different use cases. We should benchmark performance against our workload with NVIDIA T4 GPUs, which are cost-optimized options, as well as some higher-end options like A100 GPUs.\\n\\nC: Do you think we should also explore using something like Elastic Inference GPU attachments? Those let you augment existing instances with fractional GPU access that is more cost-effective.\\n\\nB: Hmm good question. In theory that could work well for the cost-performance balance. We'd need to test compatibility with the types of GPU optimizations we're running in the model though...\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \"<output>\\nA: \\n- Benchmark performance of recommendation model against different GPU instance types from major cloud providers including NVIDIA T4 and A100 GPUs\\n- Consider exploring Elastic Inference GPU attachments and test compatibility with model optimizations\\n\\nB: \\n- Help benchmark performance against different GPU instance types\\n- Consider exploring Elastic Inference GPU attachments and provide input on compatibility with model optimizations\\n\\nC: \\n- Consider exploring Elastic Inference GPU attachments as an alternative to full GPU instances for cost-performance balance  \\n- Help benchmark performance against different GPU instance types\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 2.189725875854492,\n",
      "  \"completion_token_count\": 122,\n",
      "  \"prompt_token_count\": 950,\n",
      "  \"cost\": 0.00222072,\n",
      "  \"completion_word_count\": 89,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-12 13:58:27,278] p31920 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=cohere_template.txt, reps=3\n",
      "[2024-01-12 13:58:27,279] p31920 {544935498.py:35} INFO - going to summarize idx=2, file=data/raw/4/call_center_transcript_4_transcript.txt via cohere.command-text-v14\n",
      "[2024-01-12 13:58:27,280] p31920 {544935498.py:38} INFO - read prompt template from data/prompts/cohere_template.txt\n",
      "[2024-01-12 13:58:27,286] p31920 {544935498.py:43} INFO - prompt for data/raw/4/call_center_transcript_4_transcript.txt has 963 tokens\n",
      "[2024-01-12 13:58:27,287] p31920 {528272729.py:4} INFO - model_id=cohere.command-text-v14, prompt length is 4423 characters, 733 words\n",
      "[2024-01-12 13:58:32,802] p31920 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to further discuss options for the optimal cloud instance type to host our new product recommendation model. As a refresher on the requirements - this model will be query intensive, with thousands of customers hitting the prediction API simultaneously. And it relies on a large deep neural network for the recommendations. \\n\\nB: Yes, we should go through the pros and cons again of the main instance family options available. For standard instance types without GPUs, we'd likely need to go with a high CPU and memory specification to handle the computation and concurrency needs.\\n\\nC: Standard instances would be more cost-effective, but prediction latency would suffer without GPU acceleration. The neural network calculations could be 5-10x slower based on our initial benchmarks. For a customer-facing model, slow predictions could lead to poor user experience.\\n\\nA: That's a very good point. While GPU-powered instances would be more expensive, the business value of sub-second prediction latency for users is high. We want customers to get engaging, personalized recommendations immediately to drive conversions.\\n\\nB: I agree, I think GPU acceleration makes more sense despite the increased cloud costs. In addition to the deep learning performance boost, some of the other model parallelization and tuning optimizations we're doing would also run faster on GPUs.\\n\\nC: It seems like GPU instances are the way to go then as long as the total monthly cost is affordable. However, we may be able to optimize the specific type of GPU instance to find the best balance of throughput versus cost. \\n\\nA: Definitely, the major cloud providers offer an array of GPU instance types optimized for different use cases. We should benchmark performance against our workload with NVIDIA T4 GPUs, which are cost-optimized options, as well as some higher-end options like A100 GPUs.\\n\\nC: Do you think we should also explore using something like Elastic Inference GPU attachments? Those let you augment existing instances with fractional GPU access that is more cost-effective.\\n\\nB: Hmm good question. In theory that could work well for the cost-performance balance. We'd need to test compatibility with the types of GPU optimizations we're running in the model though...\\n</conversation>\",\n",
      "  \"completion\": \" Here are the action items for each speaker:\\n\\nA:\\n- Lead a discussion on the requirements of the product recommendation model\\n- Evaluate the optimal cloud instance type that can handle thousands of customers \\n- Assess the pros and cons of standard instance types without GPUs and their ability to handle computation and concurrency needs\\n\\nB:\\n- Provide expertise on the performance boost of GPU acceleration and the potential for model optimizations \\n- Help assess the impact of prediction latency on the user experience \\n\\nC:\\n- Offer insights on cost-effective options such as Elastic Inference GPU attachments \\n- Lead the exploration of different GPU instance types and their compatibility with model optimizations \\n\\nWould you like me to create a more comprehensive list of action items based on this conversation? \",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 5.514203786849976,\n",
      "  \"completion_token_count\": 172,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-12 13:58:32,804] p31920 {544935498.py:76} INFO - prompt_token_count is None for cohere.command-text-v14, setting it to 963 \n",
      "[2024-01-12 13:58:32,807] p31920 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to further discuss options for the optimal cloud instance type to host our new product recommendation model. As a refresher on the requirements - this model will be query intensive, with thousands of customers hitting the prediction API simultaneously. And it relies on a large deep neural network for the recommendations. \\n\\nB: Yes, we should go through the pros and cons again of the main instance family options available. For standard instance types without GPUs, we'd likely need to go with a high CPU and memory specification to handle the computation and concurrency needs.\\n\\nC: Standard instances would be more cost-effective, but prediction latency would suffer without GPU acceleration. The neural network calculations could be 5-10x slower based on our initial benchmarks. For a customer-facing model, slow predictions could lead to poor user experience.\\n\\nA: That's a very good point. While GPU-powered instances would be more expensive, the business value of sub-second prediction latency for users is high. We want customers to get engaging, personalized recommendations immediately to drive conversions.\\n\\nB: I agree, I think GPU acceleration makes more sense despite the increased cloud costs. In addition to the deep learning performance boost, some of the other model parallelization and tuning optimizations we're doing would also run faster on GPUs.\\n\\nC: It seems like GPU instances are the way to go then as long as the total monthly cost is affordable. However, we may be able to optimize the specific type of GPU instance to find the best balance of throughput versus cost. \\n\\nA: Definitely, the major cloud providers offer an array of GPU instance types optimized for different use cases. We should benchmark performance against our workload with NVIDIA T4 GPUs, which are cost-optimized options, as well as some higher-end options like A100 GPUs.\\n\\nC: Do you think we should also explore using something like Elastic Inference GPU attachments? Those let you augment existing instances with fractional GPU access that is more cost-effective.\\n\\nB: Hmm good question. In theory that could work well for the cost-performance balance. We'd need to test compatibility with the types of GPU optimizations we're running in the model though...\\n</conversation>\",\n",
      "  \"completion\": \"Here are the action items for each speaker:\\n\\nA:\\n- Lead a discussion on the requirements of the product recommendation model\\n- Evaluate the optimal cloud instance type that can handle thousands of customers \\n- Assess the pros and cons of standard instance types without GPUs and their ability to handle computation and concurrency needs\\n\\nB:\\n- Provide expertise on the performance boost of GPU acceleration and the potential for model optimizations \\n- Help assess the impact of prediction latency on the user experience \\n\\nC:\\n- Offer insights on cost-effective options such as Elastic Inference GPU attachments \\n- Lead the exploration of different GPU instance types and their compatibility with model optimizations \\n\\nWould you like me to create a more comprehensive list of action items based on this conversation?\",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 5.514203786849976,\n",
      "  \"completion_token_count\": 172,\n",
      "  \"prompt_token_count\": 963,\n",
      "  \"cost\": 0.0017885000000000002,\n",
      "  \"completion_word_count\": 129,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-12 13:58:32,809] p31920 {544935498.py:19} INFO - idx=3, tf=data/raw/3/call_center_transcript_3_transcript.txt, file_id=call_center_transcript_3, golden_summary_fpath=data/raw/0/example_prompt_transcript_golden_summary.txt\n",
      "[2024-01-12 13:58:32,810] p31920 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=titan_template.txt, reps=3\n",
      "[2024-01-12 13:58:32,811] p31920 {544935498.py:35} INFO - going to summarize idx=3, file=data/raw/3/call_center_transcript_3_transcript.txt via amazon.titan-text-express-v1\n",
      "[2024-01-12 13:58:32,813] p31920 {544935498.py:38} INFO - read prompt template from data/prompts/titan_template.txt\n",
      "[2024-01-12 13:58:32,819] p31920 {544935498.py:43} INFO - prompt for data/raw/3/call_center_transcript_3_transcript.txt has 898 tokens\n",
      "[2024-01-12 13:58:32,820] p31920 {528272729.py:4} INFO - model_id=amazon.titan-text-express-v1, prompt length is 4020 characters, 680 words\n",
      "[2024-01-12 13:58:37,423] p31920 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nA: I wanted to have a broader discussion on responsible AI development principles. As we build more AI models, how do we ensure they are helpful, harmless, and aligned with human values?\\n\\nB: This is an important topic. We need to make ethical considerations a priority from the beginning of any AI project, not an afterthought. I think we should develop a review process focused on safety for all new models. \\n\\nAction item: Draft a proposal for an AI model safety review framework \\n\\nC: I agree. We should analyze potential risks like data bias and misuse upfront. Models also need to be secure - what if they were hacked?\\n\\nAction item: Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA: Valid points. Besides analyzing risks, we also need to ensure the objectives we give AI align with human values more broadly. Like being helpful to users, not just maximizing some narrow metric. \\n\\nAction item: Explore methodologies for value alignment in AI systems\\n\\nB: The objectives point connects to transparency too. Any AI decisions that impact users should be explainable. If we can't understand why an AI did something, we can't verify it's aligned.  \\n\\nAction item: Research existing XAI (explainable AI) techniques to augment our models\\n\\nC: Adding explainability makes sense. We should also discuss how to carefully test models before launch to catch additional issues. And have a plan to monitor their impacts over time.\\n\\nAction item: Develop testing and monitoring standards for AI models based on industry best practices\\n\\nA: Great suggestions all around. It seems like we have a blueprint to make responsibility, safety and ethics central to our AI efforts here. I'm optimistic if we build these considerations in from the start, we can drive real progress. Does anyone have any other thoughts before we break?\\n</conversation>\",\n",
      "  \"completion\": \"\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Draft a proposal for an AI model safety review framework\\n- Explore methodologies for value alignment in AI systems\\n\\nB:\\n- Outline additional potential safety risks to address such as data/algorithm bias and security\\n- Research existing XAI (explainable AI) techniques to augment our models\\n- Develop testing and monitoring standards for AI models based on industry best practices\\n\\nC:\\n- Add explainability to AI models\\n- Discuss how to carefully test models before launch to catch additional issues\\n- Have a plan to monitor their impacts over time\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 4.6025872230529785,\n",
      "  \"completion_token_count\": 138,\n",
      "  \"prompt_token_count\": 901\n",
      "}\n",
      "[2024-01-12 13:58:37,424] p31920 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nA: I wanted to have a broader discussion on responsible AI development principles. As we build more AI models, how do we ensure they are helpful, harmless, and aligned with human values?\\n\\nB: This is an important topic. We need to make ethical considerations a priority from the beginning of any AI project, not an afterthought. I think we should develop a review process focused on safety for all new models. \\n\\nAction item: Draft a proposal for an AI model safety review framework \\n\\nC: I agree. We should analyze potential risks like data bias and misuse upfront. Models also need to be secure - what if they were hacked?\\n\\nAction item: Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA: Valid points. Besides analyzing risks, we also need to ensure the objectives we give AI align with human values more broadly. Like being helpful to users, not just maximizing some narrow metric. \\n\\nAction item: Explore methodologies for value alignment in AI systems\\n\\nB: The objectives point connects to transparency too. Any AI decisions that impact users should be explainable. If we can't understand why an AI did something, we can't verify it's aligned.  \\n\\nAction item: Research existing XAI (explainable AI) techniques to augment our models\\n\\nC: Adding explainability makes sense. We should also discuss how to carefully test models before launch to catch additional issues. And have a plan to monitor their impacts over time.\\n\\nAction item: Develop testing and monitoring standards for AI models based on industry best practices\\n\\nA: Great suggestions all around. It seems like we have a blueprint to make responsibility, safety and ethics central to our AI efforts here. I'm optimistic if we build these considerations in from the start, we can drive real progress. Does anyone have any other thoughts before we break?\\n</conversation>\",\n",
      "  \"completion\": \"<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Draft a proposal for an AI model safety review framework\\n- Explore methodologies for value alignment in AI systems\\n\\nB:\\n- Outline additional potential safety risks to address such as data/algorithm bias and security\\n- Research existing XAI (explainable AI) techniques to augment our models\\n- Develop testing and monitoring standards for AI models based on industry best practices\\n\\nC:\\n- Add explainability to AI models\\n- Discuss how to carefully test models before launch to catch additional issues\\n- Have a plan to monitor their impacts over time\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 4.6025872230529785,\n",
      "  \"completion_token_count\": 138,\n",
      "  \"prompt_token_count\": 901,\n",
      "  \"cost\": 0.0009416000000000001,\n",
      "  \"completion_word_count\": 103,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-12 13:58:37,425] p31920 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=anthropic_template_single_line_reason.txt, reps=3\n",
      "[2024-01-12 13:58:37,425] p31920 {544935498.py:35} INFO - going to summarize idx=3, file=data/raw/3/call_center_transcript_3_transcript.txt via anthropic.claude-instant-v1\n",
      "[2024-01-12 13:58:37,426] p31920 {544935498.py:38} INFO - read prompt template from data/prompts/anthropic_template_single_line_reason.txt\n",
      "[2024-01-12 13:58:37,428] p31920 {544935498.py:43} INFO - prompt for data/raw/3/call_center_transcript_3_transcript.txt has 880 tokens\n",
      "[2024-01-12 13:58:37,428] p31920 {528272729.py:4} INFO - model_id=anthropic.claude-instant-v1, prompt length is 3937 characters, 663 words\n",
      "[2024-01-12 13:58:46,943] p31920 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to have a broader discussion on responsible AI development principles. As we build more AI models, how do we ensure they are helpful, harmless, and aligned with human values?\\n\\nB: This is an important topic. We need to make ethical considerations a priority from the beginning of any AI project, not an afterthought. I think we should develop a review process focused on safety for all new models. \\n\\nAction item: Draft a proposal for an AI model safety review framework \\n\\nC: I agree. We should analyze potential risks like data bias and misuse upfront. Models also need to be secure - what if they were hacked?\\n\\nAction item: Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA: Valid points. Besides analyzing risks, we also need to ensure the objectives we give AI align with human values more broadly. Like being helpful to users, not just maximizing some narrow metric. \\n\\nAction item: Explore methodologies for value alignment in AI systems\\n\\nB: The objectives point connects to transparency too. Any AI decisions that impact users should be explainable. If we can't understand why an AI did something, we can't verify it's aligned.  \\n\\nAction item: Research existing XAI (explainable AI) techniques to augment our models\\n\\nC: Adding explainability makes sense. We should also discuss how to carefully test models before launch to catch additional issues. And have a plan to monitor their impacts over time.\\n\\nAction item: Develop testing and monitoring standards for AI models based on industry best practices\\n\\nA: Great suggestions all around. It seems like we have a blueprint to make responsibility, safety and ethics central to our AI efforts here. I'm optimistic if we build these considerations in from the start, we can drive real progress. Does anyone have any other thoughts before we break?\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \" <output>\\nA: \\n- No explicit action items stated\\n\\nB:  \\n- Draft a proposal for an AI model safety review framework\\n\\nC:\\n- Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA:  \\n- Explore methodologies for value alignment in AI systems \\n\\nB:\\n- Research existing XAI (explainable AI) techniques to augment our models\\n\\nC:\\n- Develop testing and monitoring standards for AI models based on industry best practices\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 9.513514995574951,\n",
      "  \"completion_token_count\": 113,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-12 13:58:46,944] p31920 {544935498.py:76} INFO - prompt_token_count is None for anthropic.claude-instant-v1, setting it to 880 \n",
      "[2024-01-12 13:58:46,946] p31920 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to have a broader discussion on responsible AI development principles. As we build more AI models, how do we ensure they are helpful, harmless, and aligned with human values?\\n\\nB: This is an important topic. We need to make ethical considerations a priority from the beginning of any AI project, not an afterthought. I think we should develop a review process focused on safety for all new models. \\n\\nAction item: Draft a proposal for an AI model safety review framework \\n\\nC: I agree. We should analyze potential risks like data bias and misuse upfront. Models also need to be secure - what if they were hacked?\\n\\nAction item: Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA: Valid points. Besides analyzing risks, we also need to ensure the objectives we give AI align with human values more broadly. Like being helpful to users, not just maximizing some narrow metric. \\n\\nAction item: Explore methodologies for value alignment in AI systems\\n\\nB: The objectives point connects to transparency too. Any AI decisions that impact users should be explainable. If we can't understand why an AI did something, we can't verify it's aligned.  \\n\\nAction item: Research existing XAI (explainable AI) techniques to augment our models\\n\\nC: Adding explainability makes sense. We should also discuss how to carefully test models before launch to catch additional issues. And have a plan to monitor their impacts over time.\\n\\nAction item: Develop testing and monitoring standards for AI models based on industry best practices\\n\\nA: Great suggestions all around. It seems like we have a blueprint to make responsibility, safety and ethics central to our AI efforts here. I'm optimistic if we build these considerations in from the start, we can drive real progress. Does anyone have any other thoughts before we break?\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \"<output>\\nA: \\n- No explicit action items stated\\n\\nB:  \\n- Draft a proposal for an AI model safety review framework\\n\\nC:\\n- Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA:  \\n- Explore methodologies for value alignment in AI systems \\n\\nB:\\n- Research existing XAI (explainable AI) techniques to augment our models\\n\\nC:\\n- Develop testing and monitoring standards for AI models based on industry best practices\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 9.513514995574951,\n",
      "  \"completion_token_count\": 113,\n",
      "  \"prompt_token_count\": 880,\n",
      "  \"cost\": 0.00205703,\n",
      "  \"completion_word_count\": 73,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-12 13:58:46,947] p31920 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=cohere_template.txt, reps=3\n",
      "[2024-01-12 13:58:46,948] p31920 {544935498.py:35} INFO - going to summarize idx=3, file=data/raw/3/call_center_transcript_3_transcript.txt via cohere.command-text-v14\n",
      "[2024-01-12 13:58:46,949] p31920 {544935498.py:38} INFO - read prompt template from data/prompts/cohere_template.txt\n",
      "[2024-01-12 13:58:46,954] p31920 {544935498.py:43} INFO - prompt for data/raw/3/call_center_transcript_3_transcript.txt has 893 tokens\n",
      "[2024-01-12 13:58:46,955] p31920 {528272729.py:4} INFO - model_id=cohere.command-text-v14, prompt length is 4015 characters, 679 words\n",
      "[2024-01-12 13:58:51,099] p31920 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to have a broader discussion on responsible AI development principles. As we build more AI models, how do we ensure they are helpful, harmless, and aligned with human values?\\n\\nB: This is an important topic. We need to make ethical considerations a priority from the beginning of any AI project, not an afterthought. I think we should develop a review process focused on safety for all new models. \\n\\nAction item: Draft a proposal for an AI model safety review framework \\n\\nC: I agree. We should analyze potential risks like data bias and misuse upfront. Models also need to be secure - what if they were hacked?\\n\\nAction item: Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA: Valid points. Besides analyzing risks, we also need to ensure the objectives we give AI align with human values more broadly. Like being helpful to users, not just maximizing some narrow metric. \\n\\nAction item: Explore methodologies for value alignment in AI systems\\n\\nB: The objectives point connects to transparency too. Any AI decisions that impact users should be explainable. If we can't understand why an AI did something, we can't verify it's aligned.  \\n\\nAction item: Research existing XAI (explainable AI) techniques to augment our models\\n\\nC: Adding explainability makes sense. We should also discuss how to carefully test models before launch to catch additional issues. And have a plan to monitor their impacts over time.\\n\\nAction item: Develop testing and monitoring standards for AI models based on industry best practices\\n\\nA: Great suggestions all around. It seems like we have a blueprint to make responsibility, safety and ethics central to our AI efforts here. I'm optimistic if we build these considerations in from the start, we can drive real progress. Does anyone have any other thoughts before we break?\\n</conversation>\",\n",
      "  \"completion\": \" <output>\\nA: \\n- Draft a proposal for an AI model safety review framework \\n- Explore methodologies for value alignment in AI systems \\n\\nB: \\n- None\\n\\nC:\\n- Outline additional safety risks \\n- Discuss how to carefully test models before launch and monitor their impacts over time \\n- Implement testing and monitoring standards for AI based on industry best practices \\n\\n</output>\\n\\nI hope these action items help ensure that the key topics and next steps from your meeting are actionable! Do you need help with anything else? \",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 4.143467903137207,\n",
      "  \"completion_token_count\": 114,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-12 13:58:51,099] p31920 {544935498.py:76} INFO - prompt_token_count is None for cohere.command-text-v14, setting it to 893 \n",
      "[2024-01-12 13:58:51,101] p31920 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to have a broader discussion on responsible AI development principles. As we build more AI models, how do we ensure they are helpful, harmless, and aligned with human values?\\n\\nB: This is an important topic. We need to make ethical considerations a priority from the beginning of any AI project, not an afterthought. I think we should develop a review process focused on safety for all new models. \\n\\nAction item: Draft a proposal for an AI model safety review framework \\n\\nC: I agree. We should analyze potential risks like data bias and misuse upfront. Models also need to be secure - what if they were hacked?\\n\\nAction item: Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA: Valid points. Besides analyzing risks, we also need to ensure the objectives we give AI align with human values more broadly. Like being helpful to users, not just maximizing some narrow metric. \\n\\nAction item: Explore methodologies for value alignment in AI systems\\n\\nB: The objectives point connects to transparency too. Any AI decisions that impact users should be explainable. If we can't understand why an AI did something, we can't verify it's aligned.  \\n\\nAction item: Research existing XAI (explainable AI) techniques to augment our models\\n\\nC: Adding explainability makes sense. We should also discuss how to carefully test models before launch to catch additional issues. And have a plan to monitor their impacts over time.\\n\\nAction item: Develop testing and monitoring standards for AI models based on industry best practices\\n\\nA: Great suggestions all around. It seems like we have a blueprint to make responsibility, safety and ethics central to our AI efforts here. I'm optimistic if we build these considerations in from the start, we can drive real progress. Does anyone have any other thoughts before we break?\\n</conversation>\",\n",
      "  \"completion\": \"<output>\\nA: \\n- Draft a proposal for an AI model safety review framework \\n- Explore methodologies for value alignment in AI systems \\n\\nB: \\n- None\\n\\nC:\\n- Outline additional safety risks \\n- Discuss how to carefully test models before launch and monitor their impacts over time \\n- Implement testing and monitoring standards for AI based on industry best practices \\n\\n</output>\\n\\nI hope these action items help ensure that the key topics and next steps from your meeting are actionable! Do you need help with anything else?\",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 4.143467903137207,\n",
      "  \"completion_token_count\": 114,\n",
      "  \"prompt_token_count\": 893,\n",
      "  \"cost\": 0.0015674999999999999,\n",
      "  \"completion_word_count\": 86,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-12 13:58:51,102] p31920 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=titan_template.txt, reps=3\n",
      "[2024-01-12 13:58:51,102] p31920 {544935498.py:35} INFO - going to summarize idx=3, file=data/raw/3/call_center_transcript_3_transcript.txt via amazon.titan-text-express-v1\n",
      "[2024-01-12 13:58:51,103] p31920 {544935498.py:38} INFO - read prompt template from data/prompts/titan_template.txt\n",
      "[2024-01-12 13:58:51,107] p31920 {544935498.py:43} INFO - prompt for data/raw/3/call_center_transcript_3_transcript.txt has 898 tokens\n",
      "[2024-01-12 13:58:51,107] p31920 {528272729.py:4} INFO - model_id=amazon.titan-text-express-v1, prompt length is 4020 characters, 680 words\n",
      "[2024-01-12 13:58:55,678] p31920 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nA: I wanted to have a broader discussion on responsible AI development principles. As we build more AI models, how do we ensure they are helpful, harmless, and aligned with human values?\\n\\nB: This is an important topic. We need to make ethical considerations a priority from the beginning of any AI project, not an afterthought. I think we should develop a review process focused on safety for all new models. \\n\\nAction item: Draft a proposal for an AI model safety review framework \\n\\nC: I agree. We should analyze potential risks like data bias and misuse upfront. Models also need to be secure - what if they were hacked?\\n\\nAction item: Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA: Valid points. Besides analyzing risks, we also need to ensure the objectives we give AI align with human values more broadly. Like being helpful to users, not just maximizing some narrow metric. \\n\\nAction item: Explore methodologies for value alignment in AI systems\\n\\nB: The objectives point connects to transparency too. Any AI decisions that impact users should be explainable. If we can't understand why an AI did something, we can't verify it's aligned.  \\n\\nAction item: Research existing XAI (explainable AI) techniques to augment our models\\n\\nC: Adding explainability makes sense. We should also discuss how to carefully test models before launch to catch additional issues. And have a plan to monitor their impacts over time.\\n\\nAction item: Develop testing and monitoring standards for AI models based on industry best practices\\n\\nA: Great suggestions all around. It seems like we have a blueprint to make responsibility, safety and ethics central to our AI efforts here. I'm optimistic if we build these considerations in from the start, we can drive real progress. Does anyone have any other thoughts before we break?\\n</conversation>\",\n",
      "  \"completion\": \"\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Draft a proposal for an AI model safety review framework\\n- Explore methodologies for value alignment in AI systems\\n\\nB:\\n- Outline additional potential safety risks to address such as data/algorithm bias and security\\n- Research existing XAI (explainable AI) techniques to augment our models\\n- Develop testing and monitoring standards for AI models based on industry best practices\\n\\nC:\\n- Add explainability to AI models\\n- Discuss how to carefully test models before launch to catch additional issues\\n- Have a plan to monitor their impacts over time\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 4.5700719356536865,\n",
      "  \"completion_token_count\": 138,\n",
      "  \"prompt_token_count\": 901\n",
      "}\n",
      "[2024-01-12 13:58:55,680] p31920 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nA: I wanted to have a broader discussion on responsible AI development principles. As we build more AI models, how do we ensure they are helpful, harmless, and aligned with human values?\\n\\nB: This is an important topic. We need to make ethical considerations a priority from the beginning of any AI project, not an afterthought. I think we should develop a review process focused on safety for all new models. \\n\\nAction item: Draft a proposal for an AI model safety review framework \\n\\nC: I agree. We should analyze potential risks like data bias and misuse upfront. Models also need to be secure - what if they were hacked?\\n\\nAction item: Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA: Valid points. Besides analyzing risks, we also need to ensure the objectives we give AI align with human values more broadly. Like being helpful to users, not just maximizing some narrow metric. \\n\\nAction item: Explore methodologies for value alignment in AI systems\\n\\nB: The objectives point connects to transparency too. Any AI decisions that impact users should be explainable. If we can't understand why an AI did something, we can't verify it's aligned.  \\n\\nAction item: Research existing XAI (explainable AI) techniques to augment our models\\n\\nC: Adding explainability makes sense. We should also discuss how to carefully test models before launch to catch additional issues. And have a plan to monitor their impacts over time.\\n\\nAction item: Develop testing and monitoring standards for AI models based on industry best practices\\n\\nA: Great suggestions all around. It seems like we have a blueprint to make responsibility, safety and ethics central to our AI efforts here. I'm optimistic if we build these considerations in from the start, we can drive real progress. Does anyone have any other thoughts before we break?\\n</conversation>\",\n",
      "  \"completion\": \"<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Draft a proposal for an AI model safety review framework\\n- Explore methodologies for value alignment in AI systems\\n\\nB:\\n- Outline additional potential safety risks to address such as data/algorithm bias and security\\n- Research existing XAI (explainable AI) techniques to augment our models\\n- Develop testing and monitoring standards for AI models based on industry best practices\\n\\nC:\\n- Add explainability to AI models\\n- Discuss how to carefully test models before launch to catch additional issues\\n- Have a plan to monitor their impacts over time\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 4.5700719356536865,\n",
      "  \"completion_token_count\": 138,\n",
      "  \"prompt_token_count\": 901,\n",
      "  \"cost\": 0.0009416000000000001,\n",
      "  \"completion_word_count\": 103,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-12 13:58:55,681] p31920 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=anthropic_template_single_line_reason.txt, reps=3\n",
      "[2024-01-12 13:58:55,681] p31920 {544935498.py:35} INFO - going to summarize idx=3, file=data/raw/3/call_center_transcript_3_transcript.txt via anthropic.claude-instant-v1\n",
      "[2024-01-12 13:58:55,683] p31920 {544935498.py:38} INFO - read prompt template from data/prompts/anthropic_template_single_line_reason.txt\n",
      "[2024-01-12 13:58:55,686] p31920 {544935498.py:43} INFO - prompt for data/raw/3/call_center_transcript_3_transcript.txt has 880 tokens\n",
      "[2024-01-12 13:58:55,687] p31920 {528272729.py:4} INFO - model_id=anthropic.claude-instant-v1, prompt length is 3937 characters, 663 words\n",
      "[2024-01-12 13:58:57,556] p31920 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to have a broader discussion on responsible AI development principles. As we build more AI models, how do we ensure they are helpful, harmless, and aligned with human values?\\n\\nB: This is an important topic. We need to make ethical considerations a priority from the beginning of any AI project, not an afterthought. I think we should develop a review process focused on safety for all new models. \\n\\nAction item: Draft a proposal for an AI model safety review framework \\n\\nC: I agree. We should analyze potential risks like data bias and misuse upfront. Models also need to be secure - what if they were hacked?\\n\\nAction item: Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA: Valid points. Besides analyzing risks, we also need to ensure the objectives we give AI align with human values more broadly. Like being helpful to users, not just maximizing some narrow metric. \\n\\nAction item: Explore methodologies for value alignment in AI systems\\n\\nB: The objectives point connects to transparency too. Any AI decisions that impact users should be explainable. If we can't understand why an AI did something, we can't verify it's aligned.  \\n\\nAction item: Research existing XAI (explainable AI) techniques to augment our models\\n\\nC: Adding explainability makes sense. We should also discuss how to carefully test models before launch to catch additional issues. And have a plan to monitor their impacts over time.\\n\\nAction item: Develop testing and monitoring standards for AI models based on industry best practices\\n\\nA: Great suggestions all around. It seems like we have a blueprint to make responsibility, safety and ethics central to our AI efforts here. I'm optimistic if we build these considerations in from the start, we can drive real progress. Does anyone have any other thoughts before we break?\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \" <output>\\nA: \\n- No explicit action items stated\\n\\nB:  \\n- Draft a proposal for an AI model safety review framework\\n\\nC:\\n- Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA:  \\n- Explore methodologies for value alignment in AI systems \\n\\nB:\\n- Research existing XAI (explainable AI) techniques to augment our models\\n\\nC:\\n- Develop testing and monitoring standards for AI models based on industry best practices\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 1.8681399822235107,\n",
      "  \"completion_token_count\": 113,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-12 13:58:57,557] p31920 {544935498.py:76} INFO - prompt_token_count is None for anthropic.claude-instant-v1, setting it to 880 \n",
      "[2024-01-12 13:58:57,559] p31920 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to have a broader discussion on responsible AI development principles. As we build more AI models, how do we ensure they are helpful, harmless, and aligned with human values?\\n\\nB: This is an important topic. We need to make ethical considerations a priority from the beginning of any AI project, not an afterthought. I think we should develop a review process focused on safety for all new models. \\n\\nAction item: Draft a proposal for an AI model safety review framework \\n\\nC: I agree. We should analyze potential risks like data bias and misuse upfront. Models also need to be secure - what if they were hacked?\\n\\nAction item: Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA: Valid points. Besides analyzing risks, we also need to ensure the objectives we give AI align with human values more broadly. Like being helpful to users, not just maximizing some narrow metric. \\n\\nAction item: Explore methodologies for value alignment in AI systems\\n\\nB: The objectives point connects to transparency too. Any AI decisions that impact users should be explainable. If we can't understand why an AI did something, we can't verify it's aligned.  \\n\\nAction item: Research existing XAI (explainable AI) techniques to augment our models\\n\\nC: Adding explainability makes sense. We should also discuss how to carefully test models before launch to catch additional issues. And have a plan to monitor their impacts over time.\\n\\nAction item: Develop testing and monitoring standards for AI models based on industry best practices\\n\\nA: Great suggestions all around. It seems like we have a blueprint to make responsibility, safety and ethics central to our AI efforts here. I'm optimistic if we build these considerations in from the start, we can drive real progress. Does anyone have any other thoughts before we break?\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \"<output>\\nA: \\n- No explicit action items stated\\n\\nB:  \\n- Draft a proposal for an AI model safety review framework\\n\\nC:\\n- Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA:  \\n- Explore methodologies for value alignment in AI systems \\n\\nB:\\n- Research existing XAI (explainable AI) techniques to augment our models\\n\\nC:\\n- Develop testing and monitoring standards for AI models based on industry best practices\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 1.8681399822235107,\n",
      "  \"completion_token_count\": 113,\n",
      "  \"prompt_token_count\": 880,\n",
      "  \"cost\": 0.00205703,\n",
      "  \"completion_word_count\": 73,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-12 13:58:57,561] p31920 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=cohere_template.txt, reps=3\n",
      "[2024-01-12 13:58:57,561] p31920 {544935498.py:35} INFO - going to summarize idx=3, file=data/raw/3/call_center_transcript_3_transcript.txt via cohere.command-text-v14\n",
      "[2024-01-12 13:58:57,563] p31920 {544935498.py:38} INFO - read prompt template from data/prompts/cohere_template.txt\n",
      "[2024-01-12 13:58:57,567] p31920 {544935498.py:43} INFO - prompt for data/raw/3/call_center_transcript_3_transcript.txt has 893 tokens\n",
      "[2024-01-12 13:58:57,567] p31920 {528272729.py:4} INFO - model_id=cohere.command-text-v14, prompt length is 4015 characters, 679 words\n",
      "[2024-01-12 13:59:03,440] p31920 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to have a broader discussion on responsible AI development principles. As we build more AI models, how do we ensure they are helpful, harmless, and aligned with human values?\\n\\nB: This is an important topic. We need to make ethical considerations a priority from the beginning of any AI project, not an afterthought. I think we should develop a review process focused on safety for all new models. \\n\\nAction item: Draft a proposal for an AI model safety review framework \\n\\nC: I agree. We should analyze potential risks like data bias and misuse upfront. Models also need to be secure - what if they were hacked?\\n\\nAction item: Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA: Valid points. Besides analyzing risks, we also need to ensure the objectives we give AI align with human values more broadly. Like being helpful to users, not just maximizing some narrow metric. \\n\\nAction item: Explore methodologies for value alignment in AI systems\\n\\nB: The objectives point connects to transparency too. Any AI decisions that impact users should be explainable. If we can't understand why an AI did something, we can't verify it's aligned.  \\n\\nAction item: Research existing XAI (explainable AI) techniques to augment our models\\n\\nC: Adding explainability makes sense. We should also discuss how to carefully test models before launch to catch additional issues. And have a plan to monitor their impacts over time.\\n\\nAction item: Develop testing and monitoring standards for AI models based on industry best practices\\n\\nA: Great suggestions all around. It seems like we have a blueprint to make responsibility, safety and ethics central to our AI efforts here. I'm optimistic if we build these considerations in from the start, we can drive real progress. Does anyone have any other thoughts before we break?\\n</conversation>\",\n",
      "  \"completion\": \" <output>\\nA: \\n- Draft a proposal for an AI model safety review process\\n- Explore methodologies for value alignment \\n- Share the responsibility, safety, and ethics blueprint with the broader AI team \\n\\nB: \\n- None\\n\\nC:\\n- Outline additional AI safety risks \\n- Discuss how to incorporate explainability (XAI) into models \\n- Develop testing and monitoring standards for AI \\n- Share the action items and discussions from this meeting with relevant stakeholders\\n</output>\\n\\nEach speaker is assigned actionable items based on their discussion points. Please note that the items are ordered based on the conversation's flow and the time stamp of each speaker's remarks. \\n\\nAre there any other ways I can help structure the conversation or summarize the action items? \",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 5.871854782104492,\n",
      "  \"completion_token_count\": 160,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-12 13:59:03,441] p31920 {544935498.py:76} INFO - prompt_token_count is None for cohere.command-text-v14, setting it to 893 \n",
      "[2024-01-12 13:59:03,442] p31920 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to have a broader discussion on responsible AI development principles. As we build more AI models, how do we ensure they are helpful, harmless, and aligned with human values?\\n\\nB: This is an important topic. We need to make ethical considerations a priority from the beginning of any AI project, not an afterthought. I think we should develop a review process focused on safety for all new models. \\n\\nAction item: Draft a proposal for an AI model safety review framework \\n\\nC: I agree. We should analyze potential risks like data bias and misuse upfront. Models also need to be secure - what if they were hacked?\\n\\nAction item: Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA: Valid points. Besides analyzing risks, we also need to ensure the objectives we give AI align with human values more broadly. Like being helpful to users, not just maximizing some narrow metric. \\n\\nAction item: Explore methodologies for value alignment in AI systems\\n\\nB: The objectives point connects to transparency too. Any AI decisions that impact users should be explainable. If we can't understand why an AI did something, we can't verify it's aligned.  \\n\\nAction item: Research existing XAI (explainable AI) techniques to augment our models\\n\\nC: Adding explainability makes sense. We should also discuss how to carefully test models before launch to catch additional issues. And have a plan to monitor their impacts over time.\\n\\nAction item: Develop testing and monitoring standards for AI models based on industry best practices\\n\\nA: Great suggestions all around. It seems like we have a blueprint to make responsibility, safety and ethics central to our AI efforts here. I'm optimistic if we build these considerations in from the start, we can drive real progress. Does anyone have any other thoughts before we break?\\n</conversation>\",\n",
      "  \"completion\": \"<output>\\nA: \\n- Draft a proposal for an AI model safety review process\\n- Explore methodologies for value alignment \\n- Share the responsibility, safety, and ethics blueprint with the broader AI team \\n\\nB: \\n- None\\n\\nC:\\n- Outline additional AI safety risks \\n- Discuss how to incorporate explainability (XAI) into models \\n- Develop testing and monitoring standards for AI \\n- Share the action items and discussions from this meeting with relevant stakeholders\\n</output>\\n\\nEach speaker is assigned actionable items based on their discussion points. Please note that the items are ordered based on the conversation's flow and the time stamp of each speaker's remarks. \\n\\nAre there any other ways I can help structure the conversation or summarize the action items?\",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 5.871854782104492,\n",
      "  \"completion_token_count\": 160,\n",
      "  \"prompt_token_count\": 893,\n",
      "  \"cost\": 0.0016595,\n",
      "  \"completion_word_count\": 120,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-12 13:59:03,443] p31920 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=titan_template.txt, reps=3\n",
      "[2024-01-12 13:59:03,444] p31920 {544935498.py:35} INFO - going to summarize idx=3, file=data/raw/3/call_center_transcript_3_transcript.txt via amazon.titan-text-express-v1\n",
      "[2024-01-12 13:59:03,444] p31920 {544935498.py:38} INFO - read prompt template from data/prompts/titan_template.txt\n",
      "[2024-01-12 13:59:03,447] p31920 {544935498.py:43} INFO - prompt for data/raw/3/call_center_transcript_3_transcript.txt has 898 tokens\n",
      "[2024-01-12 13:59:03,447] p31920 {528272729.py:4} INFO - model_id=amazon.titan-text-express-v1, prompt length is 4020 characters, 680 words\n",
      "[2024-01-12 13:59:08,073] p31920 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nA: I wanted to have a broader discussion on responsible AI development principles. As we build more AI models, how do we ensure they are helpful, harmless, and aligned with human values?\\n\\nB: This is an important topic. We need to make ethical considerations a priority from the beginning of any AI project, not an afterthought. I think we should develop a review process focused on safety for all new models. \\n\\nAction item: Draft a proposal for an AI model safety review framework \\n\\nC: I agree. We should analyze potential risks like data bias and misuse upfront. Models also need to be secure - what if they were hacked?\\n\\nAction item: Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA: Valid points. Besides analyzing risks, we also need to ensure the objectives we give AI align with human values more broadly. Like being helpful to users, not just maximizing some narrow metric. \\n\\nAction item: Explore methodologies for value alignment in AI systems\\n\\nB: The objectives point connects to transparency too. Any AI decisions that impact users should be explainable. If we can't understand why an AI did something, we can't verify it's aligned.  \\n\\nAction item: Research existing XAI (explainable AI) techniques to augment our models\\n\\nC: Adding explainability makes sense. We should also discuss how to carefully test models before launch to catch additional issues. And have a plan to monitor their impacts over time.\\n\\nAction item: Develop testing and monitoring standards for AI models based on industry best practices\\n\\nA: Great suggestions all around. It seems like we have a blueprint to make responsibility, safety and ethics central to our AI efforts here. I'm optimistic if we build these considerations in from the start, we can drive real progress. Does anyone have any other thoughts before we break?\\n</conversation>\",\n",
      "  \"completion\": \"\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Draft a proposal for an AI model safety review framework\\n- Explore methodologies for value alignment in AI systems\\n\\nB:\\n- Outline additional potential safety risks to address such as data/algorithm bias and security\\n- Research existing XAI (explainable AI) techniques to augment our models\\n- Develop testing and monitoring standards for AI models based on industry best practices\\n\\nC:\\n- Add explainability to AI models\\n- Discuss how to carefully test models before launch to catch additional issues\\n- Have a plan to monitor their impacts over time\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 4.62456488609314,\n",
      "  \"completion_token_count\": 138,\n",
      "  \"prompt_token_count\": 901\n",
      "}\n",
      "[2024-01-12 13:59:08,074] p31920 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n\\\\n\\\\n\\n<conversation>\\nA: I wanted to have a broader discussion on responsible AI development principles. As we build more AI models, how do we ensure they are helpful, harmless, and aligned with human values?\\n\\nB: This is an important topic. We need to make ethical considerations a priority from the beginning of any AI project, not an afterthought. I think we should develop a review process focused on safety for all new models. \\n\\nAction item: Draft a proposal for an AI model safety review framework \\n\\nC: I agree. We should analyze potential risks like data bias and misuse upfront. Models also need to be secure - what if they were hacked?\\n\\nAction item: Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA: Valid points. Besides analyzing risks, we also need to ensure the objectives we give AI align with human values more broadly. Like being helpful to users, not just maximizing some narrow metric. \\n\\nAction item: Explore methodologies for value alignment in AI systems\\n\\nB: The objectives point connects to transparency too. Any AI decisions that impact users should be explainable. If we can't understand why an AI did something, we can't verify it's aligned.  \\n\\nAction item: Research existing XAI (explainable AI) techniques to augment our models\\n\\nC: Adding explainability makes sense. We should also discuss how to carefully test models before launch to catch additional issues. And have a plan to monitor their impacts over time.\\n\\nAction item: Develop testing and monitoring standards for AI models based on industry best practices\\n\\nA: Great suggestions all around. It seems like we have a blueprint to make responsibility, safety and ethics central to our AI efforts here. I'm optimistic if we build these considerations in from the start, we can drive real progress. Does anyone have any other thoughts before we break?\\n</conversation>\",\n",
      "  \"completion\": \"<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Draft a proposal for an AI model safety review framework\\n- Explore methodologies for value alignment in AI systems\\n\\nB:\\n- Outline additional potential safety risks to address such as data/algorithm bias and security\\n- Research existing XAI (explainable AI) techniques to augment our models\\n- Develop testing and monitoring standards for AI models based on industry best practices\\n\\nC:\\n- Add explainability to AI models\\n- Discuss how to carefully test models before launch to catch additional issues\\n- Have a plan to monitor their impacts over time\\n</output>\",\n",
      "  \"model_id\": \"amazon.titan-text-express-v1\",\n",
      "  \"time_taken_in_seconds\": 4.62456488609314,\n",
      "  \"completion_token_count\": 138,\n",
      "  \"prompt_token_count\": 901,\n",
      "  \"cost\": 0.0009416000000000001,\n",
      "  \"completion_word_count\": 103,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-12 13:59:08,074] p31920 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=anthropic_template_single_line_reason.txt, reps=3\n",
      "[2024-01-12 13:59:08,075] p31920 {544935498.py:35} INFO - going to summarize idx=3, file=data/raw/3/call_center_transcript_3_transcript.txt via anthropic.claude-instant-v1\n",
      "[2024-01-12 13:59:08,075] p31920 {544935498.py:38} INFO - read prompt template from data/prompts/anthropic_template_single_line_reason.txt\n",
      "[2024-01-12 13:59:08,078] p31920 {544935498.py:43} INFO - prompt for data/raw/3/call_center_transcript_3_transcript.txt has 880 tokens\n",
      "[2024-01-12 13:59:08,078] p31920 {528272729.py:4} INFO - model_id=anthropic.claude-instant-v1, prompt length is 3937 characters, 663 words\n",
      "[2024-01-12 13:59:09,864] p31920 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to have a broader discussion on responsible AI development principles. As we build more AI models, how do we ensure they are helpful, harmless, and aligned with human values?\\n\\nB: This is an important topic. We need to make ethical considerations a priority from the beginning of any AI project, not an afterthought. I think we should develop a review process focused on safety for all new models. \\n\\nAction item: Draft a proposal for an AI model safety review framework \\n\\nC: I agree. We should analyze potential risks like data bias and misuse upfront. Models also need to be secure - what if they were hacked?\\n\\nAction item: Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA: Valid points. Besides analyzing risks, we also need to ensure the objectives we give AI align with human values more broadly. Like being helpful to users, not just maximizing some narrow metric. \\n\\nAction item: Explore methodologies for value alignment in AI systems\\n\\nB: The objectives point connects to transparency too. Any AI decisions that impact users should be explainable. If we can't understand why an AI did something, we can't verify it's aligned.  \\n\\nAction item: Research existing XAI (explainable AI) techniques to augment our models\\n\\nC: Adding explainability makes sense. We should also discuss how to carefully test models before launch to catch additional issues. And have a plan to monitor their impacts over time.\\n\\nAction item: Develop testing and monitoring standards for AI models based on industry best practices\\n\\nA: Great suggestions all around. It seems like we have a blueprint to make responsibility, safety and ethics central to our AI efforts here. I'm optimistic if we build these considerations in from the start, we can drive real progress. Does anyone have any other thoughts before we break?\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \" <output>\\nA: \\n- No explicit action items stated\\n\\nB:  \\n- Draft a proposal for an AI model safety review framework\\n\\nC:\\n- Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA:  \\n- Explore methodologies for value alignment in AI systems \\n\\nB:\\n- Research existing XAI (explainable AI) techniques to augment our models\\n\\nC:\\n- Develop testing and monitoring standards for AI models based on industry best practices\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 1.7853407859802246,\n",
      "  \"completion_token_count\": 113,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-12 13:59:09,865] p31920 {544935498.py:76} INFO - prompt_token_count is None for anthropic.claude-instant-v1, setting it to 880 \n",
      "[2024-01-12 13:59:09,866] p31920 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"Human: Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to have a broader discussion on responsible AI development principles. As we build more AI models, how do we ensure they are helpful, harmless, and aligned with human values?\\n\\nB: This is an important topic. We need to make ethical considerations a priority from the beginning of any AI project, not an afterthought. I think we should develop a review process focused on safety for all new models. \\n\\nAction item: Draft a proposal for an AI model safety review framework \\n\\nC: I agree. We should analyze potential risks like data bias and misuse upfront. Models also need to be secure - what if they were hacked?\\n\\nAction item: Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA: Valid points. Besides analyzing risks, we also need to ensure the objectives we give AI align with human values more broadly. Like being helpful to users, not just maximizing some narrow metric. \\n\\nAction item: Explore methodologies for value alignment in AI systems\\n\\nB: The objectives point connects to transparency too. Any AI decisions that impact users should be explainable. If we can't understand why an AI did something, we can't verify it's aligned.  \\n\\nAction item: Research existing XAI (explainable AI) techniques to augment our models\\n\\nC: Adding explainability makes sense. We should also discuss how to carefully test models before launch to catch additional issues. And have a plan to monitor their impacts over time.\\n\\nAction item: Develop testing and monitoring standards for AI models based on industry best practices\\n\\nA: Great suggestions all around. It seems like we have a blueprint to make responsibility, safety and ethics central to our AI efforts here. I'm optimistic if we build these considerations in from the start, we can drive real progress. Does anyone have any other thoughts before we break?\\n</conversation>\\n\\nAssistant:\",\n",
      "  \"completion\": \"<output>\\nA: \\n- No explicit action items stated\\n\\nB:  \\n- Draft a proposal for an AI model safety review framework\\n\\nC:\\n- Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA:  \\n- Explore methodologies for value alignment in AI systems \\n\\nB:\\n- Research existing XAI (explainable AI) techniques to augment our models\\n\\nC:\\n- Develop testing and monitoring standards for AI models based on industry best practices\\n</output>\",\n",
      "  \"model_id\": \"anthropic.claude-instant-v1\",\n",
      "  \"time_taken_in_seconds\": 1.7853407859802246,\n",
      "  \"completion_token_count\": 113,\n",
      "  \"prompt_token_count\": 880,\n",
      "  \"cost\": 0.00205703,\n",
      "  \"completion_word_count\": 73,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-12 13:59:09,867] p31920 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=cohere_template.txt, reps=3\n",
      "[2024-01-12 13:59:09,868] p31920 {544935498.py:35} INFO - going to summarize idx=3, file=data/raw/3/call_center_transcript_3_transcript.txt via cohere.command-text-v14\n",
      "[2024-01-12 13:59:09,869] p31920 {544935498.py:38} INFO - read prompt template from data/prompts/cohere_template.txt\n",
      "[2024-01-12 13:59:09,872] p31920 {544935498.py:43} INFO - prompt for data/raw/3/call_center_transcript_3_transcript.txt has 893 tokens\n",
      "[2024-01-12 13:59:09,872] p31920 {528272729.py:4} INFO - model_id=cohere.command-text-v14, prompt length is 4015 characters, 679 words\n",
      "[2024-01-12 13:59:13,335] p31920 {528272729.py:41} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to have a broader discussion on responsible AI development principles. As we build more AI models, how do we ensure they are helpful, harmless, and aligned with human values?\\n\\nB: This is an important topic. We need to make ethical considerations a priority from the beginning of any AI project, not an afterthought. I think we should develop a review process focused on safety for all new models. \\n\\nAction item: Draft a proposal for an AI model safety review framework \\n\\nC: I agree. We should analyze potential risks like data bias and misuse upfront. Models also need to be secure - what if they were hacked?\\n\\nAction item: Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA: Valid points. Besides analyzing risks, we also need to ensure the objectives we give AI align with human values more broadly. Like being helpful to users, not just maximizing some narrow metric. \\n\\nAction item: Explore methodologies for value alignment in AI systems\\n\\nB: The objectives point connects to transparency too. Any AI decisions that impact users should be explainable. If we can't understand why an AI did something, we can't verify it's aligned.  \\n\\nAction item: Research existing XAI (explainable AI) techniques to augment our models\\n\\nC: Adding explainability makes sense. We should also discuss how to carefully test models before launch to catch additional issues. And have a plan to monitor their impacts over time.\\n\\nAction item: Develop testing and monitoring standards for AI models based on industry best practices\\n\\nA: Great suggestions all around. It seems like we have a blueprint to make responsibility, safety and ethics central to our AI efforts here. I'm optimistic if we build these considerations in from the start, we can drive real progress. Does anyone have any other thoughts before we break?\\n</conversation>\",\n",
      "  \"completion\": \" <output>\\nA: \\n- Draft a proposal for an AI model safety review framework \\n- Explore methodologies for value alignment in AI systems \\n\\nB: \\n- None\\n\\nC:\\n- Outline additional safety risks \\n- Discuss how to carefully test models before launch and monitor their impacts over time \\n- Implement testing and monitoring standards for AI based on industry best practices \\n\\n</output>\\n\\nDo these action items seem suitable for the speakers?\",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 3.4615650177001953,\n",
      "  \"completion_token_count\": 92,\n",
      "  \"prompt_token_count\": null\n",
      "}\n",
      "[2024-01-12 13:59:13,337] p31920 {544935498.py:76} INFO - prompt_token_count is None for cohere.command-text-v14, setting it to 893 \n",
      "[2024-01-12 13:59:13,339] p31920 {544935498.py:98} INFO - {\n",
      "  \"exception\": null,\n",
      "  \"prompt\": \"You are an AI bot that is good at determining reason for a call from contact center transcripts. Read the conversation between the call participants. Based on the participants of the call discuss, create a list of action items for each speaker in the call transcript.\\nI am giving you an example of a conversation and the desired output below. \\n\\n<conversation>\\nA: Hi folks, I wanted to discuss the timeline for launching the new app update.\\nB: Sure A, what aspect did you want to talk through?  \\nA: I'm mostly concerned that some of the new features seem to be falling behind schedule based on the updates I'm getting from the teams.\\nB: Okay, let me loop in C since she's managing the development roadmap.  \\nC: Hey all, thanks for bringing this up. What features are you worried about A?\\nA: The new recommendation algorithm integration seems pretty delayed based on what engineering told me. Also the UI refresh.  \\nC: You're right, the algorithm work is a bit backed up. As for the UI, I'll follow up - I thought that was on track.\\nB: Maybe we should prioritize getting the algorithm piece back on schedule since that's key for our main app update goal.  \\nA: Agreed. C, can you work with engineering on that? And B, to your point, I'm happy to help re-prioritize other things if needed.\\nC: Sure, I'll sync up with engineering today and get a plan to get us back on track.  \\nB: Sounds good, let's plan to regroup next week once you have an update.\\n</conversation>\\n\\n<output>\\nHere are the action items I gathered for each person:\\n\\nA:\\n- Help re-prioritize other workstreams if needed to get algorithm integration back on track\\n- Regroup next week for an update on new timeline\\n\\nB: \\n- None explicitly stated\\n\\nC:\\n- Follow up on status of UI refresh\\n- Work with engineering team to get recommendation algorithm integration back on schedule \\n- Sync up with engineering today and come up with updated timeline\\n- Provide update next week on new timeline\\n</output>\\n\\nSimilar to the above example generate a list of action items for each speaker from the conversation provided below. Put the action items between the <output></output> tags. \\n\\n<conversation>\\nA: I wanted to have a broader discussion on responsible AI development principles. As we build more AI models, how do we ensure they are helpful, harmless, and aligned with human values?\\n\\nB: This is an important topic. We need to make ethical considerations a priority from the beginning of any AI project, not an afterthought. I think we should develop a review process focused on safety for all new models. \\n\\nAction item: Draft a proposal for an AI model safety review framework \\n\\nC: I agree. We should analyze potential risks like data bias and misuse upfront. Models also need to be secure - what if they were hacked?\\n\\nAction item: Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA: Valid points. Besides analyzing risks, we also need to ensure the objectives we give AI align with human values more broadly. Like being helpful to users, not just maximizing some narrow metric. \\n\\nAction item: Explore methodologies for value alignment in AI systems\\n\\nB: The objectives point connects to transparency too. Any AI decisions that impact users should be explainable. If we can't understand why an AI did something, we can't verify it's aligned.  \\n\\nAction item: Research existing XAI (explainable AI) techniques to augment our models\\n\\nC: Adding explainability makes sense. We should also discuss how to carefully test models before launch to catch additional issues. And have a plan to monitor their impacts over time.\\n\\nAction item: Develop testing and monitoring standards for AI models based on industry best practices\\n\\nA: Great suggestions all around. It seems like we have a blueprint to make responsibility, safety and ethics central to our AI efforts here. I'm optimistic if we build these considerations in from the start, we can drive real progress. Does anyone have any other thoughts before we break?\\n</conversation>\",\n",
      "  \"completion\": \"<output>\\nA: \\n- Draft a proposal for an AI model safety review framework \\n- Explore methodologies for value alignment in AI systems \\n\\nB: \\n- None\\n\\nC:\\n- Outline additional safety risks \\n- Discuss how to carefully test models before launch and monitor their impacts over time \\n- Implement testing and monitoring standards for AI based on industry best practices \\n\\n</output>\\n\\nDo these action items seem suitable for the speakers?\",\n",
      "  \"model_id\": \"cohere.command-text-v14\",\n",
      "  \"time_taken_in_seconds\": 3.4615650177001953,\n",
      "  \"completion_token_count\": 92,\n",
      "  \"prompt_token_count\": 893,\n",
      "  \"cost\": 0.0015235,\n",
      "  \"completion_word_count\": 69,\n",
      "  \"experiment\": \"single-line-reason\"\n",
      "}\n",
      "[2024-01-12 13:59:13,341] p31920 {544935498.py:19} INFO - idx=4, tf=data/raw/2/call_center_transcript_2_transcript.txt, file_id=call_center_transcript_2, golden_summary_fpath=data/raw/0/example_prompt_transcript_golden_summary.txt\n",
      "[2024-01-12 13:59:13,341] p31920 {544935498.py:29} INFO - exp_name=single-line-reason, prompt_template=titan_template.txt, reps=3\n",
      "[2024-01-12 13:59:13,348] p31920 {544935498.py:35} INFO - going to summarize idx=4, file=data/raw/2/call_center_transcript_2_transcript.txt via amazon.titan-text-express-v1\n",
      "[2024-01-12 13:59:13,356] p31920 {544935498.py:38} INFO - read prompt template from data/prompts/titan_template.txt\n",
      "[2024-01-12 13:59:13,363] p31920 {544935498.py:43} INFO - prompt for data/raw/2/call_center_transcript_2_transcript.txt has 793 tokens\n",
      "[2024-01-12 13:59:13,369] p31920 {528272729.py:4} INFO - model_id=amazon.titan-text-express-v1, prompt length is 3472 characters, 588 words\n"
     ]
    }
   ],
   "source": [
    "from json import JSONEncoder\n",
    "import re\n",
    "from pathlib import Path\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "class CustomJSONEncoder(JSONEncoder):\n",
    "    def default(self, o):\n",
    "        if isinstance(o, Exception):\n",
    "            return {'error_type': o.__class__.__name__, 'error_message': str(o)}\n",
    "        return JSONEncoder.default(self, o)\n",
    "\n",
    "for idx, tf in enumerate(transcript_files):\n",
    "    transcript = Path(tf).read_text()\n",
    "    fname = os.path.basename(tf)\n",
    "    file_id = \"_\".join(fname.split('_')[:-1])\n",
    "    golden_summary_fpath = os.path.join(config['dir']['raw'], '0', \"example_prompt_transcript_golden_summary.txt\")\n",
    "    logger.info(f\"idx={idx}, tf={tf}, file_id={file_id}, golden_summary_fpath={golden_summary_fpath}\")\n",
    "    # for each experiment\n",
    "    for experiment in config['experiments']:\n",
    "        exp_name = experiment['name']        \n",
    "        model_list = experiment['model_list']\n",
    "        reps = experiment['reps']        \n",
    "        for rep in range(reps):\n",
    "            for model_info in model_list:\n",
    "                model_name = model_info['model']\n",
    "                prompt_template_fname = model_info['prompt_template']\n",
    "                logger.info(f\"exp_name={exp_name}, prompt_template={prompt_template_fname}, reps={reps}\")\n",
    "                model = config['bedrock_models'].get(model_name)\n",
    "                if model is None:\n",
    "                    logger.error(f\"model={model_name} not found in bedrock_models\")\n",
    "                    continue\n",
    "                model['model_id'] = model_name\n",
    "                logger.info(f\"going to summarize idx={idx}, file={tf} via {model['model_id']}\")\n",
    "                fpath = os.path.join(config['dir']['prompts'], prompt_template_fname)\n",
    "                prompt_template = Path(fpath).read_text()\n",
    "                logger.info(f\"read prompt template from {fpath}\")\n",
    "\n",
    "                prompt = prompt_template.format(transcript)\n",
    "                # print(prompt)\n",
    "                prompt_token_count = count_tokens(prompt)\n",
    "                logger.info(f\"prompt for {tf} has {prompt_token_count} tokens\")\n",
    "\n",
    "                if (prompt_token_count + 125) > model['context_length']:\n",
    "                    logger.info(f\"cannot summarize {tf} with {model['model_id']} as prompt length {prompt_token_count} > {model['context_length']}\")\n",
    "                    continue\n",
    "                very_large_prompt = prompt_token_count > config['prompt']['very_large_prompt']['threshold']\n",
    "                inference_parameters = config['inference_params'][model['inference_param_set']]\n",
    "                \n",
    "                resp = get_text_response_from_bedrock(prompt, inference_parameters, model['model_id'])\n",
    "                if resp['exception'] is not None:\n",
    "                    logger.error(f\"exception occurred for {tf}, model_id={model['model_id']}\")\n",
    "                    e = resp['exception']\n",
    "                    if e.response['Error']['Code'] == 'ThrottlingException':\n",
    "                        retries = 0\n",
    "                        while True:\n",
    "                            retries += 1\n",
    "                            if very_large_prompt is True:\n",
    "                                time.sleep(retries * config['prompt']['very_large_prompt']['sleep_time'])\n",
    "                            else:\n",
    "                                time.sleep(retries * config['prompt']['normal_prompt']['sleep_time'])\n",
    "                            logger.error(f\"going to retry for {tf}, model_id={model['model_id']}, retries={retries}\")\n",
    "                            resp = get_text_response_from_bedrock(prompt, inference_parameters, model['model_id'])\n",
    "                            if resp['exception'] is not None:\n",
    "                                logger.error(f\"exception occurred for {tf}, model_id={model['model_id']} on retry as well\")\n",
    "                                if retries >= config['max_retries']:\n",
    "                                    logger.error(f\"retries={retries} >= configured max retries={config['max_retries']}, giving up\")\n",
    "                                    break\n",
    "                            else:\n",
    "                                logger.info(f\"retry succeeded, retries={retries}\")\n",
    "                                break\n",
    "\n",
    "                if resp['exception'] is None:\n",
    "                    if resp['prompt_token_count'] is None:\n",
    "                        logger.info(f\"prompt_token_count is None for {model_name}, setting it to {prompt_token_count} \")\n",
    "                        resp['prompt_token_count'] = prompt_token_count\n",
    "                    resp['completion'] = re.sub(r\"<reason>|</reason>\", \"\", resp['completion']).strip()\n",
    "                    resp['completion'] = re.sub(r\"<reasons>|</reasons>\", \"\", resp['completion']).strip()\n",
    "                    dir_path = os.path.join(config['dir']['completions'], exp_name, file_id)\n",
    "                    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "                    fpath = os.path.join(dir_path, f\"{file_id}_{model['model_id']}_rep{rep+1}.txt\")\n",
    "                    Path(fpath).write_text(resp['completion'])\n",
    "\n",
    "                    if Path(golden_summary_fpath).is_file() is True:\n",
    "                        golden_summary = Path(golden_summary_fpath).read_text()\n",
    "                        # rouge score\n",
    "                        resp['rouge_l_f1_score'] = get_rouge_l_score(golden_summary, resp['completion'])\n",
    "                        # cosine similarity\n",
    "                        resp['cosine_similarity'] = get_cosine_similarity(golden_summary, resp['completion'])\n",
    "                    resp['cost'] = model['prompt_token_pricing_per_million'] * (resp['prompt_token_count'] / 1000000) + \\\n",
    "                        model['completion_token_pricing_per_million'] * (resp['completion_token_count'] / 1000000)\n",
    "                    \n",
    "                    resp['completion_word_count'] = len(resp['completion'].split())\n",
    "                    resp['experiment'] = exp_name\n",
    "                    \n",
    "                logger.info(json.dumps(resp, indent=2))\n",
    "                dir_path = os.path.join(config['dir']['metrics'], exp_name, file_id)\n",
    "                os.makedirs(dir_path, exist_ok=True)\n",
    "                fpath = os.path.join(dir_path, f\"{file_id}_{model['model_id']}_rep{rep+1}.json\")\n",
    "                Path(fpath).write_text(json.dumps(resp, cls=CustomJSONEncoder, indent=2))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
