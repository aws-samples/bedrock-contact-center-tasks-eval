{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle asynchronous calls for Bedrock Models with concurrent calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "import yaml\n",
    "import time\n",
    "import glob\n",
    "import logging\n",
    "import pandas as pd\n",
    "from typing import Dict\n",
    "from pathlib import Path\n",
    "from tokenizer_utils import count_tokens\n",
    "from bedrock_utils import get_bedrock_client\n",
    "from utils import  (\n",
    "    get_rouge_l_score,\n",
    "    get_cosine_similarity,\n",
    "    parse_model_response,\n",
    "    is_amazon_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set the logger to log all of the information in\n",
    "logging.basicConfig(format='[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize the config file to get all global constants\n",
    "CONFIG_FILE_PATH = \"config.yaml\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-12 15:11:10,708] p32262 {3034282685.py:5} INFO - config read from config.yaml -> {\n",
      "  \"app_name\": \"contact-center-transcript-summarization\",\n",
      "  \"aws\": {\n",
      "    \"region\": \"us-east-1\",\n",
      "    \"sagemaker_execution_role\": \"Admin\"\n",
      "  },\n",
      "  \"dir\": {\n",
      "    \"data\": \"data\",\n",
      "    \"raw\": \"data/raw\",\n",
      "    \"golden\": \"data/raw/golden\",\n",
      "    \"prompts\": \"data/prompts\",\n",
      "    \"models\": \"data/models\",\n",
      "    \"metrics\": \"data/metrics\",\n",
      "    \"completions\": \"data/completions\",\n",
      "    \"async_completions\": \"data/async_completions\"\n",
      "  },\n",
      "  \"data\": {\n",
      "    \"raw_data_file\": \"data.csv\",\n",
      "    \"golden_transcript\": \"data/raw/golden/transcript.txt\",\n",
      "    \"golden_transcript_summary\": \"data/raw/golden/summary.txt\"\n",
      "  },\n",
      "  \"prompt\": {\n",
      "    \"very_large_prompt\": {\n",
      "      \"sleep_time\": 180,\n",
      "      \"threshold\": 70000\n",
      "    },\n",
      "    \"normal_prompt\": {\n",
      "      \"sleep_time\": 60\n",
      "    }\n",
      "  },\n",
      "  \"max_retries\": 3,\n",
      "  \"desired_word_count_for_summary\": 80,\n",
      "  \"experiments\": [\n",
      "    {\n",
      "      \"name\": \"single-line-reason\",\n",
      "      \"prompt_template\": null,\n",
      "      \"reps\": 3,\n",
      "      \"model_list\": [\n",
      "        {\n",
      "          \"model\": \"amazon.titan-text-express-v1\",\n",
      "          \"prompt_template\": \"titan_template.txt\",\n",
      "          \"concurrency_levels\": [\n",
      "            1,\n",
      "            2\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"model\": \"anthropic.claude-instant-v1\",\n",
      "          \"prompt_template\": \"anthropic_template_single_line_reason.txt\",\n",
      "          \"concurrency_levels\": [\n",
      "            1,\n",
      "            2\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"model\": \"cohere.command-text-v14\",\n",
      "          \"prompt_template\": \"cohere_template.txt\",\n",
      "          \"concurrency_levels\": [\n",
      "            1,\n",
      "            2\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"bedrock_models\": {\n",
      "    \"cohere.command-text-v14\": {\n",
      "      \"context_length\": 4000,\n",
      "      \"prompt_token_pricing_per_million\": 1.5,\n",
      "      \"completion_token_pricing_per_million\": 2.0,\n",
      "      \"inference_param_set\": \"cohere\"\n",
      "    },\n",
      "    \"amazon.titan-text-express-v1\": {\n",
      "      \"context_length\": 8000,\n",
      "      \"prompt_token_pricing_per_million\": 0.8,\n",
      "      \"completion_token_pricing_per_million\": 1.6,\n",
      "      \"inference_param_set\": \"titan\"\n",
      "    },\n",
      "    \"anthropic.claude-v2:1\": {\n",
      "      \"context_length\": 100000,\n",
      "      \"prompt_token_pricing_per_million\": 8,\n",
      "      \"completion_token_pricing_per_million\": 24,\n",
      "      \"inference_param_set\": \"claude\"\n",
      "    },\n",
      "    \"anthropic.claude-instant-v1\": {\n",
      "      \"context_length\": 9000,\n",
      "      \"prompt_token_pricing_per_million\": 1.63,\n",
      "      \"completion_token_pricing_per_million\": 5.51,\n",
      "      \"inference_param_set\": \"claude\"\n",
      "    }\n",
      "  },\n",
      "  \"inference_params\": {\n",
      "    \"claude\": {\n",
      "      \"max_tokens_to_sample\": 512,\n",
      "      \"temperature\": 0.1,\n",
      "      \"top_k\": 250,\n",
      "      \"top_p\": 0.5,\n",
      "      \"stop_sequences\": [],\n",
      "      \"anthropic_version\": \"bedrock-2023-05-31\"\n",
      "    },\n",
      "    \"titan\": {\n",
      "      \"maxTokenCount\": 512,\n",
      "      \"stopSequences\": [],\n",
      "      \"temperature\": 0.1,\n",
      "      \"topP\": 0.9\n",
      "    },\n",
      "    \"cohere\": {\n",
      "      \"max_tokens\": 512,\n",
      "      \"temperature\": 0.1,\n",
      "      \"p\": 0.9,\n",
      "      \"k\": 0\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# read the config yaml file\n",
    "fpath = CONFIG_FILE_PATH\n",
    "with open(fpath, 'r') as yaml_in:\n",
    "    config = yaml.safe_load(yaml_in)\n",
    "logger.info(f\"config read from {fpath} -> {json.dumps(config, indent=2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-12 15:11:16,551] p32262 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new client\n",
      "  Using region: None\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock-runtime(https://bedrock-runtime.us-east-1.amazonaws.com)\n"
     ]
    }
   ],
   "source": [
    "## Initialize the bedrock client\n",
    "bedrock_client = get_bedrock_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-12 15:11:17,212] p32262 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new client\n",
      "  Using region: None\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock(https://bedrock.us-east-1.amazonaws.com)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelArn</th>\n",
       "      <th>modelId</th>\n",
       "      <th>modelName</th>\n",
       "      <th>providerName</th>\n",
       "      <th>inputModalities</th>\n",
       "      <th>outputModalities</th>\n",
       "      <th>responseStreamingSupported</th>\n",
       "      <th>customizationsSupported</th>\n",
       "      <th>inferenceTypesSupported</th>\n",
       "      <th>modelLifecycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-tg1-large</td>\n",
       "      <td>Titan Text Large</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-e1t-medium</td>\n",
       "      <td>Titan Text Embeddings</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[EMBEDDING]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'LEGACY'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-image-generator-v1:0</td>\n",
       "      <td>Titan Image Generator G1</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT, IMAGE]</td>\n",
       "      <td>[IMAGE]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[FINE_TUNING]</td>\n",
       "      <td>[ON_DEMAND, PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-image-generator-v1</td>\n",
       "      <td>Titan Image Generator G1</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT, IMAGE]</td>\n",
       "      <td>[IMAGE]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-embed-g1-text-02</td>\n",
       "      <td>Titan Text Embeddings v2</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[EMBEDDING]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-text-lite-v1:0:4k</td>\n",
       "      <td>Titan Text G1 - Lite</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[FINE_TUNING, CONTINUED_PRE_TRAINING]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-text-lite-v1</td>\n",
       "      <td>Titan Text G1 - Lite</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-text-express-v1:0:8k</td>\n",
       "      <td>Titan Text G1 - Express</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[FINE_TUNING, CONTINUED_PRE_TRAINING]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-text-express-v1</td>\n",
       "      <td>Titan Text G1 - Express</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-embed-text-v1:2:8k</td>\n",
       "      <td>Titan Embeddings G1 - Text</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[EMBEDDING]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-embed-text-v1</td>\n",
       "      <td>Titan Embeddings G1 - Text</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[EMBEDDING]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-embed-image-v1:0</td>\n",
       "      <td>Titan Multimodal Embeddings G1</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT, IMAGE]</td>\n",
       "      <td>[EMBEDDING]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[FINE_TUNING]</td>\n",
       "      <td>[ON_DEMAND, PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-embed-image-v1</td>\n",
       "      <td>Titan Multimodal Embeddings G1</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT, IMAGE]</td>\n",
       "      <td>[EMBEDDING]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/st...</td>\n",
       "      <td>stability.stable-diffusion-xl</td>\n",
       "      <td>SDXL 0.8</td>\n",
       "      <td>Stability AI</td>\n",
       "      <td>[TEXT, IMAGE]</td>\n",
       "      <td>[IMAGE]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/st...</td>\n",
       "      <td>stability.stable-diffusion-xl-v0</td>\n",
       "      <td>SDXL 0.8</td>\n",
       "      <td>Stability AI</td>\n",
       "      <td>[TEXT, IMAGE]</td>\n",
       "      <td>[IMAGE]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/st...</td>\n",
       "      <td>stability.stable-diffusion-xl-v1:0</td>\n",
       "      <td>SDXL 1.0</td>\n",
       "      <td>Stability AI</td>\n",
       "      <td>[TEXT, IMAGE]</td>\n",
       "      <td>[IMAGE]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/st...</td>\n",
       "      <td>stability.stable-diffusion-xl-v1</td>\n",
       "      <td>SDXL 1.0</td>\n",
       "      <td>Stability AI</td>\n",
       "      <td>[TEXT, IMAGE]</td>\n",
       "      <td>[IMAGE]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/ai...</td>\n",
       "      <td>ai21.j2-grande-instruct</td>\n",
       "      <td>J2 Grande Instruct</td>\n",
       "      <td>AI21 Labs</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/ai...</td>\n",
       "      <td>ai21.j2-jumbo-instruct</td>\n",
       "      <td>J2 Jumbo Instruct</td>\n",
       "      <td>AI21 Labs</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/ai...</td>\n",
       "      <td>ai21.j2-mid</td>\n",
       "      <td>Jurassic-2 Mid</td>\n",
       "      <td>AI21 Labs</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/ai...</td>\n",
       "      <td>ai21.j2-mid-v1</td>\n",
       "      <td>Jurassic-2 Mid</td>\n",
       "      <td>AI21 Labs</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/ai...</td>\n",
       "      <td>ai21.j2-ultra</td>\n",
       "      <td>Jurassic-2 Ultra</td>\n",
       "      <td>AI21 Labs</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/ai...</td>\n",
       "      <td>ai21.j2-ultra-v1</td>\n",
       "      <td>Jurassic-2 Ultra</td>\n",
       "      <td>AI21 Labs</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/an...</td>\n",
       "      <td>anthropic.claude-instant-v1:2:100k</td>\n",
       "      <td>Claude Instant</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/an...</td>\n",
       "      <td>anthropic.claude-instant-v1</td>\n",
       "      <td>Claude Instant</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/an...</td>\n",
       "      <td>anthropic.claude-v1</td>\n",
       "      <td>Claude</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'LEGACY'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/an...</td>\n",
       "      <td>anthropic.claude-v2:0:18k</td>\n",
       "      <td>Claude</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/an...</td>\n",
       "      <td>anthropic.claude-v2:0:100k</td>\n",
       "      <td>Claude</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/an...</td>\n",
       "      <td>anthropic.claude-v2:1:18k</td>\n",
       "      <td>Claude</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/an...</td>\n",
       "      <td>anthropic.claude-v2:1:200k</td>\n",
       "      <td>Claude</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/an...</td>\n",
       "      <td>anthropic.claude-v2:1</td>\n",
       "      <td>Claude</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/an...</td>\n",
       "      <td>anthropic.claude-v2</td>\n",
       "      <td>Claude</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/co...</td>\n",
       "      <td>cohere.command-text-v14:7:4k</td>\n",
       "      <td>Command</td>\n",
       "      <td>Cohere</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[FINE_TUNING]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/co...</td>\n",
       "      <td>cohere.command-text-v14</td>\n",
       "      <td>Command</td>\n",
       "      <td>Cohere</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/co...</td>\n",
       "      <td>cohere.command-light-text-v14:7:4k</td>\n",
       "      <td>Command Light</td>\n",
       "      <td>Cohere</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[FINE_TUNING]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/co...</td>\n",
       "      <td>cohere.command-light-text-v14</td>\n",
       "      <td>Command Light</td>\n",
       "      <td>Cohere</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/co...</td>\n",
       "      <td>cohere.embed-english-v3</td>\n",
       "      <td>Embed English</td>\n",
       "      <td>Cohere</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[EMBEDDING]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/co...</td>\n",
       "      <td>cohere.embed-multilingual-v3</td>\n",
       "      <td>Embed Multilingual</td>\n",
       "      <td>Cohere</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[EMBEDDING]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/me...</td>\n",
       "      <td>meta.llama2-13b-chat-v1:0:4k</td>\n",
       "      <td>Llama 2 Chat 13B</td>\n",
       "      <td>Meta</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/me...</td>\n",
       "      <td>meta.llama2-13b-chat-v1</td>\n",
       "      <td>Llama 2 Chat 13B</td>\n",
       "      <td>Meta</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/me...</td>\n",
       "      <td>meta.llama2-70b-chat-v1:0:4k</td>\n",
       "      <td>Llama 2 Chat 70B</td>\n",
       "      <td>Meta</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/me...</td>\n",
       "      <td>meta.llama2-70b-chat-v1</td>\n",
       "      <td>Llama 2 Chat 70B</td>\n",
       "      <td>Meta</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/me...</td>\n",
       "      <td>meta.llama2-13b-v1:0:4k</td>\n",
       "      <td>Llama 2 13B</td>\n",
       "      <td>Meta</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[FINE_TUNING]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/me...</td>\n",
       "      <td>meta.llama2-13b-v1</td>\n",
       "      <td>Llama 2 13B</td>\n",
       "      <td>Meta</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/me...</td>\n",
       "      <td>meta.llama2-70b-v1:0:4k</td>\n",
       "      <td>Llama 2 70B</td>\n",
       "      <td>Meta</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[FINE_TUNING]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/me...</td>\n",
       "      <td>meta.llama2-70b-v1</td>\n",
       "      <td>Llama 2 70B</td>\n",
       "      <td>Meta</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             modelArn  \\\n",
       "0   arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "1   arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "2   arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "3   arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "4   arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "5   arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "6   arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "7   arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "8   arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "9   arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "10  arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "11  arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "12  arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "13  arn:aws:bedrock:us-east-1::foundation-model/st...   \n",
       "14  arn:aws:bedrock:us-east-1::foundation-model/st...   \n",
       "15  arn:aws:bedrock:us-east-1::foundation-model/st...   \n",
       "16  arn:aws:bedrock:us-east-1::foundation-model/st...   \n",
       "17  arn:aws:bedrock:us-east-1::foundation-model/ai...   \n",
       "18  arn:aws:bedrock:us-east-1::foundation-model/ai...   \n",
       "19  arn:aws:bedrock:us-east-1::foundation-model/ai...   \n",
       "20  arn:aws:bedrock:us-east-1::foundation-model/ai...   \n",
       "21  arn:aws:bedrock:us-east-1::foundation-model/ai...   \n",
       "22  arn:aws:bedrock:us-east-1::foundation-model/ai...   \n",
       "23  arn:aws:bedrock:us-east-1::foundation-model/an...   \n",
       "24  arn:aws:bedrock:us-east-1::foundation-model/an...   \n",
       "25  arn:aws:bedrock:us-east-1::foundation-model/an...   \n",
       "26  arn:aws:bedrock:us-east-1::foundation-model/an...   \n",
       "27  arn:aws:bedrock:us-east-1::foundation-model/an...   \n",
       "28  arn:aws:bedrock:us-east-1::foundation-model/an...   \n",
       "29  arn:aws:bedrock:us-east-1::foundation-model/an...   \n",
       "30  arn:aws:bedrock:us-east-1::foundation-model/an...   \n",
       "31  arn:aws:bedrock:us-east-1::foundation-model/an...   \n",
       "32  arn:aws:bedrock:us-east-1::foundation-model/co...   \n",
       "33  arn:aws:bedrock:us-east-1::foundation-model/co...   \n",
       "34  arn:aws:bedrock:us-east-1::foundation-model/co...   \n",
       "35  arn:aws:bedrock:us-east-1::foundation-model/co...   \n",
       "36  arn:aws:bedrock:us-east-1::foundation-model/co...   \n",
       "37  arn:aws:bedrock:us-east-1::foundation-model/co...   \n",
       "38  arn:aws:bedrock:us-east-1::foundation-model/me...   \n",
       "39  arn:aws:bedrock:us-east-1::foundation-model/me...   \n",
       "40  arn:aws:bedrock:us-east-1::foundation-model/me...   \n",
       "41  arn:aws:bedrock:us-east-1::foundation-model/me...   \n",
       "42  arn:aws:bedrock:us-east-1::foundation-model/me...   \n",
       "43  arn:aws:bedrock:us-east-1::foundation-model/me...   \n",
       "44  arn:aws:bedrock:us-east-1::foundation-model/me...   \n",
       "45  arn:aws:bedrock:us-east-1::foundation-model/me...   \n",
       "\n",
       "                               modelId                       modelName  \\\n",
       "0               amazon.titan-tg1-large                Titan Text Large   \n",
       "1              amazon.titan-e1t-medium           Titan Text Embeddings   \n",
       "2    amazon.titan-image-generator-v1:0        Titan Image Generator G1   \n",
       "3      amazon.titan-image-generator-v1        Titan Image Generator G1   \n",
       "4        amazon.titan-embed-g1-text-02        Titan Text Embeddings v2   \n",
       "5       amazon.titan-text-lite-v1:0:4k            Titan Text G1 - Lite   \n",
       "6            amazon.titan-text-lite-v1            Titan Text G1 - Lite   \n",
       "7    amazon.titan-text-express-v1:0:8k         Titan Text G1 - Express   \n",
       "8         amazon.titan-text-express-v1         Titan Text G1 - Express   \n",
       "9      amazon.titan-embed-text-v1:2:8k      Titan Embeddings G1 - Text   \n",
       "10          amazon.titan-embed-text-v1      Titan Embeddings G1 - Text   \n",
       "11       amazon.titan-embed-image-v1:0  Titan Multimodal Embeddings G1   \n",
       "12         amazon.titan-embed-image-v1  Titan Multimodal Embeddings G1   \n",
       "13       stability.stable-diffusion-xl                        SDXL 0.8   \n",
       "14    stability.stable-diffusion-xl-v0                        SDXL 0.8   \n",
       "15  stability.stable-diffusion-xl-v1:0                        SDXL 1.0   \n",
       "16    stability.stable-diffusion-xl-v1                        SDXL 1.0   \n",
       "17             ai21.j2-grande-instruct              J2 Grande Instruct   \n",
       "18              ai21.j2-jumbo-instruct               J2 Jumbo Instruct   \n",
       "19                         ai21.j2-mid                  Jurassic-2 Mid   \n",
       "20                      ai21.j2-mid-v1                  Jurassic-2 Mid   \n",
       "21                       ai21.j2-ultra                Jurassic-2 Ultra   \n",
       "22                    ai21.j2-ultra-v1                Jurassic-2 Ultra   \n",
       "23  anthropic.claude-instant-v1:2:100k                  Claude Instant   \n",
       "24         anthropic.claude-instant-v1                  Claude Instant   \n",
       "25                 anthropic.claude-v1                          Claude   \n",
       "26           anthropic.claude-v2:0:18k                          Claude   \n",
       "27          anthropic.claude-v2:0:100k                          Claude   \n",
       "28           anthropic.claude-v2:1:18k                          Claude   \n",
       "29          anthropic.claude-v2:1:200k                          Claude   \n",
       "30               anthropic.claude-v2:1                          Claude   \n",
       "31                 anthropic.claude-v2                          Claude   \n",
       "32        cohere.command-text-v14:7:4k                         Command   \n",
       "33             cohere.command-text-v14                         Command   \n",
       "34  cohere.command-light-text-v14:7:4k                   Command Light   \n",
       "35       cohere.command-light-text-v14                   Command Light   \n",
       "36             cohere.embed-english-v3                   Embed English   \n",
       "37        cohere.embed-multilingual-v3              Embed Multilingual   \n",
       "38        meta.llama2-13b-chat-v1:0:4k                Llama 2 Chat 13B   \n",
       "39             meta.llama2-13b-chat-v1                Llama 2 Chat 13B   \n",
       "40        meta.llama2-70b-chat-v1:0:4k                Llama 2 Chat 70B   \n",
       "41             meta.llama2-70b-chat-v1                Llama 2 Chat 70B   \n",
       "42             meta.llama2-13b-v1:0:4k                     Llama 2 13B   \n",
       "43                  meta.llama2-13b-v1                     Llama 2 13B   \n",
       "44             meta.llama2-70b-v1:0:4k                     Llama 2 70B   \n",
       "45                  meta.llama2-70b-v1                     Llama 2 70B   \n",
       "\n",
       "    providerName inputModalities outputModalities responseStreamingSupported  \\\n",
       "0         Amazon          [TEXT]           [TEXT]                       True   \n",
       "1         Amazon          [TEXT]      [EMBEDDING]                        NaN   \n",
       "2         Amazon   [TEXT, IMAGE]          [IMAGE]                        NaN   \n",
       "3         Amazon   [TEXT, IMAGE]          [IMAGE]                        NaN   \n",
       "4         Amazon          [TEXT]      [EMBEDDING]                        NaN   \n",
       "5         Amazon          [TEXT]           [TEXT]                       True   \n",
       "6         Amazon          [TEXT]           [TEXT]                       True   \n",
       "7         Amazon          [TEXT]           [TEXT]                       True   \n",
       "8         Amazon          [TEXT]           [TEXT]                       True   \n",
       "9         Amazon          [TEXT]      [EMBEDDING]                      False   \n",
       "10        Amazon          [TEXT]      [EMBEDDING]                      False   \n",
       "11        Amazon   [TEXT, IMAGE]      [EMBEDDING]                        NaN   \n",
       "12        Amazon   [TEXT, IMAGE]      [EMBEDDING]                        NaN   \n",
       "13  Stability AI   [TEXT, IMAGE]          [IMAGE]                        NaN   \n",
       "14  Stability AI   [TEXT, IMAGE]          [IMAGE]                        NaN   \n",
       "15  Stability AI   [TEXT, IMAGE]          [IMAGE]                        NaN   \n",
       "16  Stability AI   [TEXT, IMAGE]          [IMAGE]                        NaN   \n",
       "17     AI21 Labs          [TEXT]           [TEXT]                      False   \n",
       "18     AI21 Labs          [TEXT]           [TEXT]                      False   \n",
       "19     AI21 Labs          [TEXT]           [TEXT]                      False   \n",
       "20     AI21 Labs          [TEXT]           [TEXT]                      False   \n",
       "21     AI21 Labs          [TEXT]           [TEXT]                      False   \n",
       "22     AI21 Labs          [TEXT]           [TEXT]                      False   \n",
       "23     Anthropic          [TEXT]           [TEXT]                       True   \n",
       "24     Anthropic          [TEXT]           [TEXT]                       True   \n",
       "25     Anthropic          [TEXT]           [TEXT]                       True   \n",
       "26     Anthropic          [TEXT]           [TEXT]                       True   \n",
       "27     Anthropic          [TEXT]           [TEXT]                       True   \n",
       "28     Anthropic          [TEXT]           [TEXT]                       True   \n",
       "29     Anthropic          [TEXT]           [TEXT]                       True   \n",
       "30     Anthropic          [TEXT]           [TEXT]                       True   \n",
       "31     Anthropic          [TEXT]           [TEXT]                       True   \n",
       "32        Cohere          [TEXT]           [TEXT]                       True   \n",
       "33        Cohere          [TEXT]           [TEXT]                       True   \n",
       "34        Cohere          [TEXT]           [TEXT]                       True   \n",
       "35        Cohere          [TEXT]           [TEXT]                       True   \n",
       "36        Cohere          [TEXT]      [EMBEDDING]                      False   \n",
       "37        Cohere          [TEXT]      [EMBEDDING]                      False   \n",
       "38          Meta          [TEXT]           [TEXT]                       True   \n",
       "39          Meta          [TEXT]           [TEXT]                       True   \n",
       "40          Meta          [TEXT]           [TEXT]                       True   \n",
       "41          Meta          [TEXT]           [TEXT]                       True   \n",
       "42          Meta          [TEXT]           [TEXT]                       True   \n",
       "43          Meta          [TEXT]           [TEXT]                       True   \n",
       "44          Meta          [TEXT]           [TEXT]                       True   \n",
       "45          Meta          [TEXT]           [TEXT]                       True   \n",
       "\n",
       "                  customizationsSupported   inferenceTypesSupported  \\\n",
       "0                                      []               [ON_DEMAND]   \n",
       "1                                      []               [ON_DEMAND]   \n",
       "2                           [FINE_TUNING]  [ON_DEMAND, PROVISIONED]   \n",
       "3                                      []               [ON_DEMAND]   \n",
       "4                                      []               [ON_DEMAND]   \n",
       "5   [FINE_TUNING, CONTINUED_PRE_TRAINING]             [PROVISIONED]   \n",
       "6                                      []               [ON_DEMAND]   \n",
       "7   [FINE_TUNING, CONTINUED_PRE_TRAINING]             [PROVISIONED]   \n",
       "8                                      []               [ON_DEMAND]   \n",
       "9                                      []             [PROVISIONED]   \n",
       "10                                     []               [ON_DEMAND]   \n",
       "11                          [FINE_TUNING]  [ON_DEMAND, PROVISIONED]   \n",
       "12                                     []               [ON_DEMAND]   \n",
       "13                                     []               [ON_DEMAND]   \n",
       "14                                     []               [ON_DEMAND]   \n",
       "15                                     []             [PROVISIONED]   \n",
       "16                                     []               [ON_DEMAND]   \n",
       "17                                     []               [ON_DEMAND]   \n",
       "18                                     []               [ON_DEMAND]   \n",
       "19                                     []               [ON_DEMAND]   \n",
       "20                                     []               [ON_DEMAND]   \n",
       "21                                     []               [ON_DEMAND]   \n",
       "22                                     []               [ON_DEMAND]   \n",
       "23                                     []             [PROVISIONED]   \n",
       "24                                     []               [ON_DEMAND]   \n",
       "25                                     []               [ON_DEMAND]   \n",
       "26                                     []             [PROVISIONED]   \n",
       "27                                     []             [PROVISIONED]   \n",
       "28                                     []             [PROVISIONED]   \n",
       "29                                     []             [PROVISIONED]   \n",
       "30                                     []               [ON_DEMAND]   \n",
       "31                                     []               [ON_DEMAND]   \n",
       "32                          [FINE_TUNING]             [PROVISIONED]   \n",
       "33                                     []               [ON_DEMAND]   \n",
       "34                          [FINE_TUNING]             [PROVISIONED]   \n",
       "35                                     []               [ON_DEMAND]   \n",
       "36                                     []               [ON_DEMAND]   \n",
       "37                                     []               [ON_DEMAND]   \n",
       "38                                     []             [PROVISIONED]   \n",
       "39                                     []               [ON_DEMAND]   \n",
       "40                                     []                        []   \n",
       "41                                     []               [ON_DEMAND]   \n",
       "42                          [FINE_TUNING]                        []   \n",
       "43                                     []                        []   \n",
       "44                          [FINE_TUNING]                        []   \n",
       "45                                     []                        []   \n",
       "\n",
       "          modelLifecycle  \n",
       "0   {'status': 'ACTIVE'}  \n",
       "1   {'status': 'LEGACY'}  \n",
       "2   {'status': 'ACTIVE'}  \n",
       "3   {'status': 'ACTIVE'}  \n",
       "4   {'status': 'ACTIVE'}  \n",
       "5   {'status': 'ACTIVE'}  \n",
       "6   {'status': 'ACTIVE'}  \n",
       "7   {'status': 'ACTIVE'}  \n",
       "8   {'status': 'ACTIVE'}  \n",
       "9   {'status': 'ACTIVE'}  \n",
       "10  {'status': 'ACTIVE'}  \n",
       "11  {'status': 'ACTIVE'}  \n",
       "12  {'status': 'ACTIVE'}  \n",
       "13  {'status': 'ACTIVE'}  \n",
       "14  {'status': 'ACTIVE'}  \n",
       "15  {'status': 'ACTIVE'}  \n",
       "16  {'status': 'ACTIVE'}  \n",
       "17  {'status': 'ACTIVE'}  \n",
       "18  {'status': 'ACTIVE'}  \n",
       "19  {'status': 'ACTIVE'}  \n",
       "20  {'status': 'ACTIVE'}  \n",
       "21  {'status': 'ACTIVE'}  \n",
       "22  {'status': 'ACTIVE'}  \n",
       "23  {'status': 'ACTIVE'}  \n",
       "24  {'status': 'ACTIVE'}  \n",
       "25  {'status': 'LEGACY'}  \n",
       "26  {'status': 'ACTIVE'}  \n",
       "27  {'status': 'ACTIVE'}  \n",
       "28  {'status': 'ACTIVE'}  \n",
       "29  {'status': 'ACTIVE'}  \n",
       "30  {'status': 'ACTIVE'}  \n",
       "31  {'status': 'ACTIVE'}  \n",
       "32  {'status': 'ACTIVE'}  \n",
       "33  {'status': 'ACTIVE'}  \n",
       "34  {'status': 'ACTIVE'}  \n",
       "35  {'status': 'ACTIVE'}  \n",
       "36  {'status': 'ACTIVE'}  \n",
       "37  {'status': 'ACTIVE'}  \n",
       "38  {'status': 'ACTIVE'}  \n",
       "39  {'status': 'ACTIVE'}  \n",
       "40  {'status': 'ACTIVE'}  \n",
       "41  {'status': 'ACTIVE'}  \n",
       "42  {'status': 'ACTIVE'}  \n",
       "43  {'status': 'ACTIVE'}  \n",
       "44  {'status': 'ACTIVE'}  \n",
       "45  {'status': 'ACTIVE'}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boto3_bedrock = get_bedrock_client(runtime=False)\n",
    "fm_list_response = boto3_bedrock.list_foundation_models()\n",
    "fm_list = fm_list_response['modelSummaries']\n",
    "df_fm = pd.DataFrame(fm_list)\n",
    "display(df_fm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-12 15:11:18,426] p32262 {3139140113.py:2} INFO - found 5 transcript_files ->\n",
      "['data/raw/0/call_center_transcript_1_transcript.txt', 'data/raw/1/call_center_transcript_0_transcript.txt', 'data/raw/4/call_center_transcript_4_transcript.txt', 'data/raw/3/call_center_transcript_3_transcript.txt', 'data/raw/2/call_center_transcript_2_transcript.txt']\n"
     ]
    }
   ],
   "source": [
    "transcript_files = glob.glob(os.path.join(config['dir']['raw'], \"*\", \"*transcript.txt\"))\n",
    "logger.info(f\"found {len(transcript_files)} transcript_files ->\\n{transcript_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/Users/madhurpt/Downloads/bedrock-contact-center-tasks-eval-main-3/utils.py'>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Re load the utils file to make sure all functions are included from the utils class before importing them\n",
    "import importlib\n",
    "import utils\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All model payloads per transcript per bedrock model ->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'model_id': 'amazon.titan-text-express-v1',\n",
       "  'payload': {'inputText': \"A: I wanted to discuss our strategy around generative AI and how we should approach this emerging technology. As you know, several applications have captured a lot of attention recently. \\nAction item: Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n\\nB: Yes, generative AI is definitely a hot topic right now. All the major tech companies seem to be investing heavily in this space.\\nAction item: Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nA: Exactly. I think we need to have a plan here too or risk falling behind. What kind of applications do you see for generative AI in our products? Could it be used to automate certain processes or enhance our users' experience?\\nAction item: Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nC: There's certainly potential, but we'd need to proceed cautiously. While the capabilities are impressive, the technology still has problems with accuracy and bias that could negatively impact customers if we don't validate it thoroughly before rolling anything out.\\nAction item: Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nB: I agree. We'll want to set clear guidelines for what generative AI should and\"}},\n",
       " {'model_id': 'anthropic.claude-instant-v1',\n",
       "  'payload': {'prompt': \"\\n\\nHuman: A: I wanted to discuss our strategy around generative AI and how we should approach this emerging technology. As you know, several applications have captured a lot of attention recently. \\nAction item: Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n\\nB: Yes, generative AI is definitely a hot topic right now. All the major tech companies seem to be investing heavily in this space.\\nAction item: Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nA: Exactly. I think we need to have a plan here too or risk falling behind. What kind of applications do you see for generative AI in our products? Could it be used to automate certain processes or enhance our users' experience?\\nAction item: Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nC: There's certainly potential, but we'd need to proceed cautiously. While the capabilities are impressive, the technology still has problems with accuracy and bias that could negatively impact customers if we don't validate it thoroughly before rolling anything out.\\nAction item: Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nB: I agree. We'll want to set clear guidelines for what generative AI should and\\n\\nAssistant:\",\n",
       "   'max_tokens_to_sample': 300,\n",
       "   'temperature': 0.5,\n",
       "   'top_k': 250,\n",
       "   'top_p': 1}},\n",
       " {'model_id': 'cohere.command-text-v14',\n",
       "  'payload': {'prompt': \"A: I wanted to discuss our strategy around generative AI and how we should approach this emerging technology. As you know, several applications have captured a lot of attention recently. \\nAction item: Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n\\nB: Yes, generative AI is definitely a hot topic right now. All the major tech companies seem to be investing heavily in this space.\\nAction item: Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nA: Exactly. I think we need to have a plan here too or risk falling behind. What kind of applications do you see for generative AI in our products? Could it be used to automate certain processes or enhance our users' experience?\\nAction item: Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nC: There's certainly potential, but we'd need to proceed cautiously. While the capabilities are impressive, the technology still has problems with accuracy and bias that could negatively impact customers if we don't validate it thoroughly before rolling anything out.\\nAction item: Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nB: I agree. We'll want to set clear guidelines for what generative AI should and\",\n",
       "   'max_tokens': 100,\n",
       "   'temperature': 0.8}},\n",
       " {'model_id': 'amazon.titan-text-express-v1',\n",
       "  'payload': {'inputText': 'Meeting transcript: \\nA: Hi B, I want to discuss the workstream for our new product launch\\nB: Sure A, is there anything in particular you want to discuss?\\nA: Yes, I want to talk about how users enter into the product.  \\nB: Ok, in that case let me add in C.\\nC: Hey everyone\\nB: Hi C, A wants to discuss how users enter into the product.\\nA: its too complicated and we should remove friction.  for example, why do I need to fill out additional forms? I also find it difficult to find where to access the product when I first land on the landing page.  \\nB: I would also add that I think there are too many steps.\\nC: Ok, I can work on the landing page to make the product more discoverable but B can you work on the additonal forms?\\nB: Yes but I would need to work with James from another team as he needs to unblock the sign up workflow. A can you document any other concerns so that I can discuss with James only once?\\nA: Sure.'}},\n",
       " {'model_id': 'anthropic.claude-instant-v1',\n",
       "  'payload': {'prompt': '\\n\\nHuman: Meeting transcript: \\nA: Hi B, I want to discuss the workstream for our new product launch\\nB: Sure A, is there anything in particular you want to discuss?\\nA: Yes, I want to talk about how users enter into the product.  \\nB: Ok, in that case let me add in C.\\nC: Hey everyone\\nB: Hi C, A wants to discuss how users enter into the product.\\nA: its too complicated and we should remove friction.  for example, why do I need to fill out additional forms? I also find it difficult to find where to access the product when I first land on the landing page.  \\nB: I would also add that I think there are too many steps.\\nC: Ok, I can work on the landing page to make the product more discoverable but B can you work on the additonal forms?\\nB: Yes but I would need to work with James from another team as he needs to unblock the sign up workflow. A can you document any other concerns so that I can discuss with James only once?\\nA: Sure.\\n\\nAssistant:',\n",
       "   'max_tokens_to_sample': 300,\n",
       "   'temperature': 0.5,\n",
       "   'top_k': 250,\n",
       "   'top_p': 1}},\n",
       " {'model_id': 'cohere.command-text-v14',\n",
       "  'payload': {'prompt': 'Meeting transcript: \\nA: Hi B, I want to discuss the workstream for our new product launch\\nB: Sure A, is there anything in particular you want to discuss?\\nA: Yes, I want to talk about how users enter into the product.  \\nB: Ok, in that case let me add in C.\\nC: Hey everyone\\nB: Hi C, A wants to discuss how users enter into the product.\\nA: its too complicated and we should remove friction.  for example, why do I need to fill out additional forms? I also find it difficult to find where to access the product when I first land on the landing page.  \\nB: I would also add that I think there are too many steps.\\nC: Ok, I can work on the landing page to make the product more discoverable but B can you work on the additonal forms?\\nB: Yes but I would need to work with James from another team as he needs to unblock the sign up workflow. A can you document any other concerns so that I can discuss with James only once?\\nA: Sure.',\n",
       "   'max_tokens': 100,\n",
       "   'temperature': 0.8}},\n",
       " {'model_id': 'amazon.titan-text-express-v1',\n",
       "  'payload': {'inputText': \"A: I wanted to further discuss options for the optimal cloud instance type to host our new product recommendation model. As a refresher on the requirements - this model will be query intensive, with thousands of customers hitting the prediction API simultaneously. And it relies on a large deep neural network for the recommendations. \\n\\nB: Yes, we should go through the pros and cons again of the main instance family options available. For standard instance types without GPUs, we'd likely need to go with a high CPU and memory specification to handle the computation and concurrency needs.\\n\\nC: Standard instances would be more cost-effective, but prediction latency would suffer without GPU acceleration. The neural network calculations could be 5-10x slower based on our initial benchmarks. For a customer-facing model, slow predictions could lead to poor user experience.\\n\\nA: That's a very good point. While GPU-powered instances would be more expensive, the business value of sub-second prediction latency for users is high. We want customers to get engaging, personalized recommendations immediately to drive conversions.\\n\\nB: I agree, I think GPU acceleration makes more sense despite the increased cloud costs. In addition to the deep learning performance boost, some of the other model parallelization and tuning optimizations we're doing would also run faster on GPUs.\\n\\nC: It seems like GPU instances are the way to go then as long as the total monthly cost is affordable. However, we may be able to optimize the specific type of GPU instance to find the best balance of throughput versus cost. \\n\\nA: Definitely, the major cloud providers offer an array of GPU instance types optimized for different use cases. We should benchmark performance against our workload with NVIDIA T4 GPUs, which are cost-optimized options, as well as some higher-end options like A100 GPUs.\\n\\nC: Do you think we should also explore using something like Elastic Inference GPU attachments? Those let you augment existing instances with fractional GPU access that is more cost-effective.\\n\\nB: Hmm good question. In theory that could work well for the cost-performance balance. We'd need to test compatibility with the types of GPU optimizations we're running in the model though...\"}},\n",
       " {'model_id': 'anthropic.claude-instant-v1',\n",
       "  'payload': {'prompt': \"\\n\\nHuman: A: I wanted to further discuss options for the optimal cloud instance type to host our new product recommendation model. As a refresher on the requirements - this model will be query intensive, with thousands of customers hitting the prediction API simultaneously. And it relies on a large deep neural network for the recommendations. \\n\\nB: Yes, we should go through the pros and cons again of the main instance family options available. For standard instance types without GPUs, we'd likely need to go with a high CPU and memory specification to handle the computation and concurrency needs.\\n\\nC: Standard instances would be more cost-effective, but prediction latency would suffer without GPU acceleration. The neural network calculations could be 5-10x slower based on our initial benchmarks. For a customer-facing model, slow predictions could lead to poor user experience.\\n\\nA: That's a very good point. While GPU-powered instances would be more expensive, the business value of sub-second prediction latency for users is high. We want customers to get engaging, personalized recommendations immediately to drive conversions.\\n\\nB: I agree, I think GPU acceleration makes more sense despite the increased cloud costs. In addition to the deep learning performance boost, some of the other model parallelization and tuning optimizations we're doing would also run faster on GPUs.\\n\\nC: It seems like GPU instances are the way to go then as long as the total monthly cost is affordable. However, we may be able to optimize the specific type of GPU instance to find the best balance of throughput versus cost. \\n\\nA: Definitely, the major cloud providers offer an array of GPU instance types optimized for different use cases. We should benchmark performance against our workload with NVIDIA T4 GPUs, which are cost-optimized options, as well as some higher-end options like A100 GPUs.\\n\\nC: Do you think we should also explore using something like Elastic Inference GPU attachments? Those let you augment existing instances with fractional GPU access that is more cost-effective.\\n\\nB: Hmm good question. In theory that could work well for the cost-performance balance. We'd need to test compatibility with the types of GPU optimizations we're running in the model though...\\n\\nAssistant:\",\n",
       "   'max_tokens_to_sample': 300,\n",
       "   'temperature': 0.5,\n",
       "   'top_k': 250,\n",
       "   'top_p': 1}},\n",
       " {'model_id': 'cohere.command-text-v14',\n",
       "  'payload': {'prompt': \"A: I wanted to further discuss options for the optimal cloud instance type to host our new product recommendation model. As a refresher on the requirements - this model will be query intensive, with thousands of customers hitting the prediction API simultaneously. And it relies on a large deep neural network for the recommendations. \\n\\nB: Yes, we should go through the pros and cons again of the main instance family options available. For standard instance types without GPUs, we'd likely need to go with a high CPU and memory specification to handle the computation and concurrency needs.\\n\\nC: Standard instances would be more cost-effective, but prediction latency would suffer without GPU acceleration. The neural network calculations could be 5-10x slower based on our initial benchmarks. For a customer-facing model, slow predictions could lead to poor user experience.\\n\\nA: That's a very good point. While GPU-powered instances would be more expensive, the business value of sub-second prediction latency for users is high. We want customers to get engaging, personalized recommendations immediately to drive conversions.\\n\\nB: I agree, I think GPU acceleration makes more sense despite the increased cloud costs. In addition to the deep learning performance boost, some of the other model parallelization and tuning optimizations we're doing would also run faster on GPUs.\\n\\nC: It seems like GPU instances are the way to go then as long as the total monthly cost is affordable. However, we may be able to optimize the specific type of GPU instance to find the best balance of throughput versus cost. \\n\\nA: Definitely, the major cloud providers offer an array of GPU instance types optimized for different use cases. We should benchmark performance against our workload with NVIDIA T4 GPUs, which are cost-optimized options, as well as some higher-end options like A100 GPUs.\\n\\nC: Do you think we should also explore using something like Elastic Inference GPU attachments? Those let you augment existing instances with fractional GPU access that is more cost-effective.\\n\\nB: Hmm good question. In theory that could work well for the cost-performance balance. We'd need to test compatibility with the types of GPU optimizations we're running in the model though...\",\n",
       "   'max_tokens': 100,\n",
       "   'temperature': 0.8}},\n",
       " {'model_id': 'amazon.titan-text-express-v1',\n",
       "  'payload': {'inputText': \"A: I wanted to have a broader discussion on responsible AI development principles. As we build more AI models, how do we ensure they are helpful, harmless, and aligned with human values?\\n\\nB: This is an important topic. We need to make ethical considerations a priority from the beginning of any AI project, not an afterthought. I think we should develop a review process focused on safety for all new models. \\n\\nAction item: Draft a proposal for an AI model safety review framework \\n\\nC: I agree. We should analyze potential risks like data bias and misuse upfront. Models also need to be secure - what if they were hacked?\\n\\nAction item: Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA: Valid points. Besides analyzing risks, we also need to ensure the objectives we give AI align with human values more broadly. Like being helpful to users, not just maximizing some narrow metric. \\n\\nAction item: Explore methodologies for value alignment in AI systems\\n\\nB: The objectives point connects to transparency too. Any AI decisions that impact users should be explainable. If we can't understand why an AI did something, we can't verify it's aligned.  \\n\\nAction item: Research existing XAI (explainable AI) techniques to augment our models\\n\\nC: Adding explainability makes sense. We should also discuss how to carefully test models before launch to catch additional issues. And have a plan to monitor their impacts over time.\\n\\nAction item: Develop testing and monitoring standards for AI models based on industry best practices\\n\\nA: Great suggestions all around. It seems like we have a blueprint to make responsibility, safety and ethics central to our AI efforts here. I'm optimistic if we build these considerations in from the start, we can drive real progress. Does anyone have any other thoughts before we break?\"}},\n",
       " {'model_id': 'anthropic.claude-instant-v1',\n",
       "  'payload': {'prompt': \"\\n\\nHuman: A: I wanted to have a broader discussion on responsible AI development principles. As we build more AI models, how do we ensure they are helpful, harmless, and aligned with human values?\\n\\nB: This is an important topic. We need to make ethical considerations a priority from the beginning of any AI project, not an afterthought. I think we should develop a review process focused on safety for all new models. \\n\\nAction item: Draft a proposal for an AI model safety review framework \\n\\nC: I agree. We should analyze potential risks like data bias and misuse upfront. Models also need to be secure - what if they were hacked?\\n\\nAction item: Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA: Valid points. Besides analyzing risks, we also need to ensure the objectives we give AI align with human values more broadly. Like being helpful to users, not just maximizing some narrow metric. \\n\\nAction item: Explore methodologies for value alignment in AI systems\\n\\nB: The objectives point connects to transparency too. Any AI decisions that impact users should be explainable. If we can't understand why an AI did something, we can't verify it's aligned.  \\n\\nAction item: Research existing XAI (explainable AI) techniques to augment our models\\n\\nC: Adding explainability makes sense. We should also discuss how to carefully test models before launch to catch additional issues. And have a plan to monitor their impacts over time.\\n\\nAction item: Develop testing and monitoring standards for AI models based on industry best practices\\n\\nA: Great suggestions all around. It seems like we have a blueprint to make responsibility, safety and ethics central to our AI efforts here. I'm optimistic if we build these considerations in from the start, we can drive real progress. Does anyone have any other thoughts before we break?\\n\\nAssistant:\",\n",
       "   'max_tokens_to_sample': 300,\n",
       "   'temperature': 0.5,\n",
       "   'top_k': 250,\n",
       "   'top_p': 1}},\n",
       " {'model_id': 'cohere.command-text-v14',\n",
       "  'payload': {'prompt': \"A: I wanted to have a broader discussion on responsible AI development principles. As we build more AI models, how do we ensure they are helpful, harmless, and aligned with human values?\\n\\nB: This is an important topic. We need to make ethical considerations a priority from the beginning of any AI project, not an afterthought. I think we should develop a review process focused on safety for all new models. \\n\\nAction item: Draft a proposal for an AI model safety review framework \\n\\nC: I agree. We should analyze potential risks like data bias and misuse upfront. Models also need to be secure - what if they were hacked?\\n\\nAction item: Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA: Valid points. Besides analyzing risks, we also need to ensure the objectives we give AI align with human values more broadly. Like being helpful to users, not just maximizing some narrow metric. \\n\\nAction item: Explore methodologies for value alignment in AI systems\\n\\nB: The objectives point connects to transparency too. Any AI decisions that impact users should be explainable. If we can't understand why an AI did something, we can't verify it's aligned.  \\n\\nAction item: Research existing XAI (explainable AI) techniques to augment our models\\n\\nC: Adding explainability makes sense. We should also discuss how to carefully test models before launch to catch additional issues. And have a plan to monitor their impacts over time.\\n\\nAction item: Develop testing and monitoring standards for AI models based on industry best practices\\n\\nA: Great suggestions all around. It seems like we have a blueprint to make responsibility, safety and ethics central to our AI efforts here. I'm optimistic if we build these considerations in from the start, we can drive real progress. Does anyone have any other thoughts before we break?\",\n",
       "   'max_tokens': 100,\n",
       "   'temperature': 0.8}},\n",
       " {'model_id': 'amazon.titan-text-express-v1',\n",
       "  'payload': {'inputText': 'A: I wanted to discuss ideas for a new startup in the mobile gaming space. The success of companies like Angry Birds shows there is a lot of potential still untapped. \\nAction item: Research recent trends and growth in mobile gaming to identify opportunities\\n\\nB: I agree mobile gaming is hot right now. Have you thought about potential types of games we could develop? Should we try freemium or paid apps?\\nAction item: Outline pros and cons for freemium vs paid monetization models\\n\\nC: We should consider other business models too like in-game ads or sponsorships. The key is retaining users and driving high engagement.\\nAction item: Explore in-game ad networks and pricing\\nAction item: Brainstorm ideas to maximize user retention \\n\\nA: Those are good points. I also think we need to prototype game concepts quickly to validate demand before investing too heavily in development.\\nAction item: Define process for rapidly prototyping and testing game concepts  \\n\\nB: Yes, we could even use some AI tools now to auto-generate simple game artwork and mechanics. This can help speed up testing. \\nAction item: Evaluate AI-powered game prototyping tools to complement our development efforts\\n\\nC: Automating pieces through AI makes sense. Though we still need to ensure quality bar for any games we officially launch.\\n'}},\n",
       " {'model_id': 'anthropic.claude-instant-v1',\n",
       "  'payload': {'prompt': '\\n\\nHuman: A: I wanted to discuss ideas for a new startup in the mobile gaming space. The success of companies like Angry Birds shows there is a lot of potential still untapped. \\nAction item: Research recent trends and growth in mobile gaming to identify opportunities\\n\\nB: I agree mobile gaming is hot right now. Have you thought about potential types of games we could develop? Should we try freemium or paid apps?\\nAction item: Outline pros and cons for freemium vs paid monetization models\\n\\nC: We should consider other business models too like in-game ads or sponsorships. The key is retaining users and driving high engagement.\\nAction item: Explore in-game ad networks and pricing\\nAction item: Brainstorm ideas to maximize user retention \\n\\nA: Those are good points. I also think we need to prototype game concepts quickly to validate demand before investing too heavily in development.\\nAction item: Define process for rapidly prototyping and testing game concepts  \\n\\nB: Yes, we could even use some AI tools now to auto-generate simple game artwork and mechanics. This can help speed up testing. \\nAction item: Evaluate AI-powered game prototyping tools to complement our development efforts\\n\\nC: Automating pieces through AI makes sense. Though we still need to ensure quality bar for any games we officially launch.\\n\\n\\nAssistant:',\n",
       "   'max_tokens_to_sample': 300,\n",
       "   'temperature': 0.5,\n",
       "   'top_k': 250,\n",
       "   'top_p': 1}},\n",
       " {'model_id': 'cohere.command-text-v14',\n",
       "  'payload': {'prompt': 'A: I wanted to discuss ideas for a new startup in the mobile gaming space. The success of companies like Angry Birds shows there is a lot of potential still untapped. \\nAction item: Research recent trends and growth in mobile gaming to identify opportunities\\n\\nB: I agree mobile gaming is hot right now. Have you thought about potential types of games we could develop? Should we try freemium or paid apps?\\nAction item: Outline pros and cons for freemium vs paid monetization models\\n\\nC: We should consider other business models too like in-game ads or sponsorships. The key is retaining users and driving high engagement.\\nAction item: Explore in-game ad networks and pricing\\nAction item: Brainstorm ideas to maximize user retention \\n\\nA: Those are good points. I also think we need to prototype game concepts quickly to validate demand before investing too heavily in development.\\nAction item: Define process for rapidly prototyping and testing game concepts  \\n\\nB: Yes, we could even use some AI tools now to auto-generate simple game artwork and mechanics. This can help speed up testing. \\nAction item: Evaluate AI-powered game prototyping tools to complement our development efforts\\n\\nC: Automating pieces through AI makes sense. Though we still need to ensure quality bar for any games we officially launch.\\n',\n",
       "   'max_tokens': 100,\n",
       "   'temperature': 0.8}}]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from json import JSONEncoder\n",
    "import re\n",
    "from pathlib import Path\n",
    "import os\n",
    "import time\n",
    "import utils\n",
    "import json\n",
    "from create_payload import model_payloads\n",
    "\n",
    "\n",
    "\n",
    "## Create a payload referring to the model_payloads script\n",
    "def create_payloads_for_all_models(transcript_files, config):\n",
    "\n",
    "    ## initialize a payload dict\n",
    "    all_payloads = []\n",
    "\n",
    "    ## Iterate through all of the transcript files available\n",
    "    for idx, tf in enumerate(transcript_files):\n",
    "        transcript = Path(tf).read_text()\n",
    "        fname = os.path.basename(tf)\n",
    "        file_id = \"_\".join(fname.split('_')[:-1])\n",
    "\n",
    "        ## Iterate through every experiment for each transcript file\n",
    "        for experiment in config['experiments']:\n",
    "            exp_name = experiment['name']\n",
    "            model_list = experiment['model_list']\n",
    "            \n",
    "            ## Iterate through each model for each transcript file\n",
    "            for model_info in model_list:\n",
    "                model_name = model_info['model']\n",
    "                model = config['bedrock_models'].get(model_name)\n",
    "\n",
    "                if model is None:\n",
    "                    logger.error(f\"model={model_name} not found in bedrock_models\")\n",
    "                    continue\n",
    "                \n",
    "                # Use the imported create_payload function to generate the payload\n",
    "                payload_dict = {\n",
    "                    \"model_id\": model_name,\n",
    "                    \"payload\": model_payloads(transcript, model_name)\n",
    "                }\n",
    "                all_payloads.append(payload_dict)\n",
    "\n",
    "    return all_payloads\n",
    "\n",
    "print(\"All model payloads per transcript per bedrock model ->\")\n",
    "create_payloads_for_all_models(transcript_files, config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import requests as req\n",
    "import botocore.session\n",
    "from botocore.auth import SigV4Auth\n",
    "from botocore.awsrequest import AWSRequest\n",
    "from typing import Dict, List\n",
    "\n",
    "SERVICE_NAME = 'bedrock'\n",
    "region = 'us-east-1'\n",
    "\n",
    "## Utilizing the bedrock REST API to get inference from each bedrock model\n",
    "def get_inference(model_id: str, payload: Dict) -> Dict:\n",
    "    try:\n",
    "        endpoint = f\"https://{SERVICE_NAME}-runtime.{region}.amazonaws.com/model/{model_id}/invoke\"\n",
    "        request_body = json.dumps(payload)\n",
    "\n",
    "        request = AWSRequest(method='POST', url=endpoint, data=request_body, headers={'content-type': 'application/json'})\n",
    "        session = botocore.session.Session()\n",
    "        sigv4 = SigV4Auth(session.get_credentials(), SERVICE_NAME, region)\n",
    "        sigv4.add_auth(request)\n",
    "        prepped = request.prepare()\n",
    "\n",
    "        response = req.post(prepped.url, headers=prepped.headers, data=request_body)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(f\"Error: Received status code {response.status_code}, Response: {response.text}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Exception occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "## Utilize the async calls for creating a thread of model invocations\n",
    "async def async_calls_on_model(model_id, payload):\n",
    "    try:\n",
    "        response = await asyncio.to_thread(get_inference, model_id, payload)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Error in async_calls_on_model: {e}\")\n",
    "        return None\n",
    "\n",
    "async def async_invoke_model(model_name, payloads):\n",
    "    responses = []\n",
    "    for payload in payloads:\n",
    "        response = await async_calls_on_model(model_name, payload)\n",
    "        responses.append(response)\n",
    "    return responses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "## Filter the model payloads by the type of model id offering at bedrock for simpler calling\n",
    "def filter_payloads_for_model(model_name, all_payloads):\n",
    "    return [payload for payload in all_payloads if payload['model_id'] == model_name]\n",
    "\n",
    "## Function to process a model through invoking it with transcripts through various concurrencies in config.yml\n",
    "async def process_model(model_info, all_payloads, csv_writer, concurrency_level):\n",
    "    model_id = model_info['model']\n",
    "    ## filter the model by the id\n",
    "    model_payloads = filter_payloads_for_model(model_id, all_payloads)\n",
    "\n",
    "    ## loop through the conc levels and the model_payloads\n",
    "    for i in range(0, len(model_payloads), concurrency_level):\n",
    "        batch_payloads = [payload['payload'] for payload in model_payloads[i:i + concurrency_level]]\n",
    "        print(f\"Running {model_id} at concurrency level {concurrency_level} with {len(batch_payloads)} requests...\")\n",
    "\n",
    "        ## track metrics: latency\n",
    "        start_time = time.time()\n",
    "        responses = await async_invoke_model(model_id, batch_payloads)\n",
    "        end_time = time.time()\n",
    "        latency = (end_time - start_time)  # in seconds\n",
    "\n",
    "        # Log and write each response to the CSV\n",
    "        for j, response in enumerate(responses):\n",
    "            csv_writer.writerow({\n",
    "                'Model_id': model_id,\n",
    "                'call transcript': batch_payloads[j],\n",
    "                'Concurrency Level': concurrency_level,\n",
    "                'Latency (seconds)': latency,\n",
    "                'Response': json.dumps(response)\n",
    "            })\n",
    "            \n",
    "            print(f\"Response {j+1} at concurrency level {concurrency_level}: {response}\")\n",
    "\n",
    "        print(f\"Latency: {latency} seconds\\n\")\n",
    "\n",
    "## save to csv function\n",
    "def init_csv_file(csv_file_path):\n",
    "    with open(csv_file_path, 'w', newline='') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=['Model_id', 'call transcript', 'Concurrency Level', 'Latency (seconds)', 'Response'])\n",
    "        writer.writeheader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-12 15:11:30,943] p32262 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "[2024-01-12 15:11:30,943] p32262 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "[2024-01-12 15:11:30,944] p32262 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running amazon.titan-text-express-v1 at concurrency level 1 with 1 requests...\n",
      "Running anthropic.claude-instant-v1 at concurrency level 1 with 1 requests...\n",
      "Running cohere.command-text-v14 at concurrency level 1 with 1 requests...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-12 15:11:34,249] p32262 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1 at concurrency level 1: {'generations': [{'finish_reason': 'MAX_TOKENS', 'id': '7f885b12-cfb8-4069-b155-2b2a8623e5cb', 'text': \" should not be used for. Otherwise, we could open ourselves up to potential misuse. \\n\\nAction item: Create a governance framework to outline appropriate use cases and ensure fair and responsible use of generative AI technology. This framework will help us stay aligned as we implement this technology.\\n\\nA: Thank you all for the productive discussion. Let's come back together to review our progress on these action items in a week. In the meantime, please share your initial thoughts and any relevant materials with the\"}], 'id': 'd7446088-0cd3-49cb-9348-8c4315474047', 'prompt': \"A: I wanted to discuss our strategy around generative AI and how we should approach this emerging technology. As you know, several applications have captured a lot of attention recently. \\nAction item: Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n\\nB: Yes, generative AI is definitely a hot topic right now. All the major tech companies seem to be investing heavily in this space.\\nAction item: Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nA: Exactly. I think we need to have a plan here too or risk falling behind. What kind of applications do you see for generative AI in our products? Could it be used to automate certain processes or enhance our users' experience?\\nAction item: Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nC: There's certainly potential, but we'd need to proceed cautiously. While the capabilities are impressive, the technology still has problems with accuracy and bias that could negatively impact customers if we don't validate it thoroughly before rolling anything out.\\nAction item: Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nB: I agree. We'll want to set clear guidelines for what generative AI should and\"}\n",
      "Latency: 3.3150110244750977 seconds\n",
      "\n",
      "Running cohere.command-text-v14 at concurrency level 1 with 1 requests...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-12 15:11:35,608] p32262 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "[2024-01-12 15:11:35,664] p32262 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1 at concurrency level 1: {'inputTextTokenCount': 282, 'results': [{'tokenCount': 128, 'outputText': \" should not be used for to ensure that we're adhering to our company's values and legal requirements.\\nAction item: Draft guidelines for responsible use of generative AI and present them to leadership for approval\\n\\nA: That's a good point. We should also consider how we can integrate generative AI with other technologies like natural language processing and machine learning to create even more powerful and personalized experiences for our users.\\nAction item: Explore potential partnerships with companies that specialize in these areas to integrate generative AI into our products\\n\\nC: Another thing to think about is how we can train our employees to work with generative AI and\", 'completionReason': 'LENGTH'}]}\n",
      "Latency: 4.674283981323242 seconds\n",
      "\n",
      "Running amazon.titan-text-express-v1 at concurrency level 1 with 1 requests...\n",
      "Response 1 at concurrency level 1: {'completion': ' You all raise important points. While generative AI shows promise, ensuring safety, transparency and ethical use should be top priorities. Some next steps:\\n\\n1. Map out use cases, but focus first on applications where consequences of errors/bias would be minimal. This allows learning without risk. \\n\\n2. Develop validation frameworks as suggested, with metrics for accuracy, fairness, privacy and more. Consider third-party audits. \\n\\n3. Engage experts in AI safety and ethics to advise on frameworks and potential issues. Their insights will help build accountability.\\n\\n4. Be transparent in communicating capabilities and limitations to users. Setting appropriate expectations is key to maintaining trust.\\n\\n5. Advocate for responsible development industry-wide. By working with others, we can help establish best practices to guide this technology responsibly.\\n\\nThe opportunities of generative AI are exciting. But by moving carefully and conscientiously, focusing on safety, transparency and accountability, I believe we can help ensure it develops in a way that benefits users and society. Does this approach seem like a balanced way forward?', 'stop_reason': 'stop_sequence', 'stop': '\\n\\nHuman:'}\n",
      "Latency: 4.73930025100708 seconds\n",
      "\n",
      "Running anthropic.claude-instant-v1 at concurrency level 1 with 1 requests...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-12 15:11:37,589] p32262 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1 at concurrency level 1: {'generations': [{'finish_reason': 'MAX_TOKENS', 'id': '30aa985e-aeee-434a-8c1d-ee2a43c485f8', 'text': ' Based on the conversation, it appears that there are issues with the user experience surrounding the entry or access of users to a product or service. A complex and time-consuming process is currently in place. To improve this, it is proposed to simplify the user experience by removing friction and making it easier for users to find and access the product. In order to achieve this, it is decided that work will be done on the landing page and the forms users must fill out. \\n\\nAre there any further'}], 'id': 'a94a0a0d-95c4-4a63-9f63-e9c4f89f035c', 'prompt': 'Meeting transcript: \\nA: Hi B, I want to discuss the workstream for our new product launch\\nB: Sure A, is there anything in particular you want to discuss?\\nA: Yes, I want to talk about how users enter into the product.  \\nB: Ok, in that case let me add in C.\\nC: Hey everyone\\nB: Hi C, A wants to discuss how users enter into the product.\\nA: its too complicated and we should remove friction.  for example, why do I need to fill out additional forms? I also find it difficult to find where to access the product when I first land on the landing page.  \\nB: I would also add that I think there are too many steps.\\nC: Ok, I can work on the landing page to make the product more discoverable but B can you work on the additonal forms?\\nB: Yes but I would need to work with James from another team as he needs to unblock the sign up workflow. A can you document any other concerns so that I can discuss with James only once?\\nA: Sure.'}\n",
      "Latency: 3.3460769653320312 seconds\n",
      "\n",
      "Running cohere.command-text-v14 at concurrency level 1 with 1 requests...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-12 15:11:38,275] p32262 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1 at concurrency level 1: {'inputTextTokenCount': 234, 'results': [{'tokenCount': 69, 'outputText': ' I will document all the issues and send it to you by EOD.\\nA and B discuss how users enter into the product. A wants to remove friction and make it more discoverable, while B can work on the additional forms and unblock the sign up workflow. A will document any other concerns and send them to B by EOD.', 'completionReason': 'FINISH'}]}\n",
      "Latency: 2.673892021179199 seconds\n",
      "\n",
      "Running amazon.titan-text-express-v1 at concurrency level 1 with 1 requests...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-12 15:11:39,728] p32262 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1 at concurrency level 1: {'completion': ' Here is a summary of the key discussion points:\\n\\n- A wanted to discuss how users enter the new product, specifically any friction points in the onboarding process. \\n\\n- A found it too complicated with additional forms that added unnecessary steps. The landing page also made it difficult to find how to access the product.\\n\\n- B agreed there were too many steps in the process. \\n\\n- C offered to work on improving discoverability on the landing page. B agreed to work on streamlining the additional forms but would need to coordinate with James from another team to unblock the signup workflow. \\n\\n- A offered to document any other concerns upfront so B could discuss everything at once with James to reduce back-and-forth.\\n\\nThe main topics discussed were friction points in the user onboarding experience, including unnecessary forms, too many steps, and discoverability on the landing page. Action items were assigned to C to improve the landing page and B to streamline forms by working with James from another team. A agreed to document additional concerns to facilitate the discussion between B and James.', 'stop_reason': 'stop_sequence', 'stop': '\\n\\nHuman:'}\n",
      "Latency: 4.065376043319702 seconds\n",
      "\n",
      "Running anthropic.claude-instant-v1 at concurrency level 1 with 1 requests...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-12 15:11:40,511] p32262 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1 at concurrency level 1: {'generations': [{'finish_reason': 'COMPLETE', 'id': '4be8a4b5-27f2-4c19-a11f-8ced812da72b', 'text': ' In this conversation, the team is discussing how to choose the best cloud instance type to host their product recommendation model. They have determined that they need a GPU-powered instance to provide fast predictions and a good user experience. They will need to choose a specific GPU instance type to find the best balance of throughput and cost. The team will explore options such as NVIDIA T4 and A100 GPUs and Elastic Inference GPU attachments. '}], 'id': '54b95bc2-6cec-4298-a7c8-55d9b09fda54', 'prompt': \"A: I wanted to further discuss options for the optimal cloud instance type to host our new product recommendation model. As a refresher on the requirements - this model will be query intensive, with thousands of customers hitting the prediction API simultaneously. And it relies on a large deep neural network for the recommendations. \\n\\nB: Yes, we should go through the pros and cons again of the main instance family options available. For standard instance types without GPUs, we'd likely need to go with a high CPU and memory specification to handle the computation and concurrency needs.\\n\\nC: Standard instances would be more cost-effective, but prediction latency would suffer without GPU acceleration. The neural network calculations could be 5-10x slower based on our initial benchmarks. For a customer-facing model, slow predictions could lead to poor user experience.\\n\\nA: That's a very good point. While GPU-powered instances would be more expensive, the business value of sub-second prediction latency for users is high. We want customers to get engaging, personalized recommendations immediately to drive conversions.\\n\\nB: I agree, I think GPU acceleration makes more sense despite the increased cloud costs. In addition to the deep learning performance boost, some of the other model parallelization and tuning optimizations we're doing would also run faster on GPUs.\\n\\nC: It seems like GPU instances are the way to go then as long as the total monthly cost is affordable. However, we may be able to optimize the specific type of GPU instance to find the best balance of throughput versus cost. \\n\\nA: Definitely, the major cloud providers offer an array of GPU instance types optimized for different use cases. We should benchmark performance against our workload with NVIDIA T4 GPUs, which are cost-optimized options, as well as some higher-end options like A100 GPUs.\\n\\nC: Do you think we should also explore using something like Elastic Inference GPU attachments? Those let you augment existing instances with fractional GPU access that is more cost-effective.\\n\\nB: Hmm good question. In theory that could work well for the cost-performance balance. We'd need to test compatibility with the types of GPU optimizations we're running in the model though...\"}\n",
      "Latency: 2.9145331382751465 seconds\n",
      "\n",
      "Running cohere.command-text-v14 at concurrency level 1 with 1 requests...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-12 15:11:42,803] p32262 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1 at concurrency level 1: {'inputTextTokenCount': 460, 'results': [{'tokenCount': 128, 'outputText': \"\\n\\nA: That's a valid point. We should definitely do some testing to see if it would impact the model performance. Another option to consider is using serverless computing platforms like AWS Lambda or GCP Cloud Functions for the prediction API. They could handle the increased workload and scale automatically without the need for managing instances.\\n\\nB: That's a great suggestion. Serverless would also eliminate the need for us to worry about instance types and scaling. However, we would need to ensure that the serverless platform can handle the latency requirements of our deep learning model and provide enough concurrent execution capacity.\\n\\nA: Absolutely,\", 'completionReason': 'LENGTH'}]}\n",
      "Latency: 4.5204758644104 seconds\n",
      "\n",
      "Running amazon.titan-text-express-v1 at concurrency level 1 with 1 requests...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-12 15:11:43,831] p32262 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "[2024-01-12 15:11:43,981] p32262 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1 at concurrency level 1: {'generations': [{'finish_reason': 'MAX_TOKENS', 'id': '3ea87410-de11-4cd6-89cc-a3c125887546', 'text': \" As an AI model, I can provide some insights to your team's discussion on developing responsible AI systems. \\n\\nThe team has identified several key considerations in ensuring responsible development of AI systems: \\n\\n1. Safety: The team discusses the need to develop a safety review process for new AI models and outline additional risks, such as data bias and security concerns. This proactive approach ensures that potential hazards are identified and mitigated early in the development process. \\n2. Value Alignment: Team members agree that\"}], 'id': '34ddbb45-5b5d-4213-b1e3-c0fdb58502de', 'prompt': \"A: I wanted to have a broader discussion on responsible AI development principles. As we build more AI models, how do we ensure they are helpful, harmless, and aligned with human values?\\n\\nB: This is an important topic. We need to make ethical considerations a priority from the beginning of any AI project, not an afterthought. I think we should develop a review process focused on safety for all new models. \\n\\nAction item: Draft a proposal for an AI model safety review framework \\n\\nC: I agree. We should analyze potential risks like data bias and misuse upfront. Models also need to be secure - what if they were hacked?\\n\\nAction item: Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA: Valid points. Besides analyzing risks, we also need to ensure the objectives we give AI align with human values more broadly. Like being helpful to users, not just maximizing some narrow metric. \\n\\nAction item: Explore methodologies for value alignment in AI systems\\n\\nB: The objectives point connects to transparency too. Any AI decisions that impact users should be explainable. If we can't understand why an AI did something, we can't verify it's aligned.  \\n\\nAction item: Research existing XAI (explainable AI) techniques to augment our models\\n\\nC: Adding explainability makes sense. We should also discuss how to carefully test models before launch to catch additional issues. And have a plan to monitor their impacts over time.\\n\\nAction item: Develop testing and monitoring standards for AI models based on industry best practices\\n\\nA: Great suggestions all around. It seems like we have a blueprint to make responsibility, safety and ethics central to our AI efforts here. I'm optimistic if we build these considerations in from the start, we can drive real progress. Does anyone have any other thoughts before we break?\"}\n",
      "Latency: 3.3276937007904053 seconds\n",
      "\n",
      "Running cohere.command-text-v14 at concurrency level 1 with 1 requests...\n",
      "Response 1 at concurrency level 1: {'completion': ' Here are a few key considerations in choosing an optimal cloud instance type for your machine learning workload:\\n\\n- GPU acceleration is important given the need for low latency predictions and model parallelization optimizations. GPUs will provide a significant performance boost over standard CPU instances.\\n\\n- Benchmark different GPU instance types against your specific model and usage patterns to find the best throughput-cost balance. Cost-optimized NVIDIA T4 GPUs are a good starting point. \\n\\n- Also test higher-end GPUs like A100 if your benchmarks show they could further improve performance within budget. Faster predictions may improve user experience.\\n\\n- Elastic Inference GPU attachments are worth exploring as they provide fractional GPU access at lower cost than full instances. Test compatibility with your model optimizations.\\n\\n- Consider total monthly cloud costs to ensure the solution remains affordable long-term. Optimization efforts like benchmarking different instance types can help maximize performance within budget.\\n\\nThe key is thorough benchmarking and testing different options to identify the best performing, cost-effective solution tailored to your specific ML workload and business needs. GPU acceleration is important but the type and configuration needs validation.', 'stop_reason': 'stop_sequence', 'stop': '\\n\\nHuman:'}\n",
      "Latency: 4.251190662384033 seconds\n",
      "\n",
      "Running anthropic.claude-instant-v1 at concurrency level 1 with 1 requests...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-12 15:11:47,240] p32262 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1 at concurrency level 1: {'generations': [{'finish_reason': 'MAX_TOKENS', 'id': 'ac39d7fe-1177-4483-ae26-c5baf7344c14', 'text': \" Great discussion, team! Let's summarize and assign the following action items:\\n\\n- A: Research mobile gaming trends and identify potential niches to target, with a focus on markets that have been overlooked. \\n- B: Outline the pros and cons of different monetization models (freemium, paid, in-game ads, sponsorships) and recommend the best approach for our target audience.\\n- C: Explore in-game ad networks and their potential benefits, along with retention strategies and\"}], 'id': '05f408d4-367d-4bcb-a3aa-def050f8f7d8', 'prompt': 'A: I wanted to discuss ideas for a new startup in the mobile gaming space. The success of companies like Angry Birds shows there is a lot of potential still untapped. \\nAction item: Research recent trends and growth in mobile gaming to identify opportunities\\n\\nB: I agree mobile gaming is hot right now. Have you thought about potential types of games we could develop? Should we try freemium or paid apps?\\nAction item: Outline pros and cons for freemium vs paid monetization models\\n\\nC: We should consider other business models too like in-game ads or sponsorships. The key is retaining users and driving high engagement.\\nAction item: Explore in-game ad networks and pricing\\nAction item: Brainstorm ideas to maximize user retention \\n\\nA: Those are good points. I also think we need to prototype game concepts quickly to validate demand before investing too heavily in development.\\nAction item: Define process for rapidly prototyping and testing game concepts  \\n\\nB: Yes, we could even use some AI tools now to auto-generate simple game artwork and mechanics. This can help speed up testing. \\nAction item: Evaluate AI-powered game prototyping tools to complement our development efforts\\n\\nC: Automating pieces through AI makes sense. Though we still need to ensure quality bar for any games we officially launch.\\n'}\n",
      "Latency: 3.2901430130004883 seconds\n",
      "\n",
      "Response 1 at concurrency level 1: {'inputTextTokenCount': 385, 'results': [{'tokenCount': 128, 'outputText': '\\n\\nB: One thing we could consider is involving a diverse range of stakeholders in the review process, including experts in ethics, law and user experience. Their perspectives can help identify blind spots and ensure a more comprehensive approach.\\n\\nAction item: Identify and engage stakeholders in the AI model safety review process\\n\\nC: Another idea is to establish partnerships with organizations that specialize in ethical AI development, such as the IEEE or the AI Ethics Institute. They can provide guidance and resources to help us stay up to date on best practices.\\n\\nAction item: Research and establish partnerships with ethical AI organizations\\n\\nA: Excellent ideas. Let', 'completionReason': 'LENGTH'}]}\n",
      "Latency: 4.445047855377197 seconds\n",
      "\n",
      "Running amazon.titan-text-express-v1 at concurrency level 1 with 1 requests...\n",
      "Response 1 at concurrency level 1: {'inputTextTokenCount': 277, 'results': [{'tokenCount': 64, 'outputText': \"Action item: Develop guidelines and quality control processes for AI-generated content\\n\\nA: Agreed. Let's also stay up-to-date with emerging technologies like augmented reality and virtual reality. These could offer new and exciting gaming experiences.\\nAction item: Research AR/VR technologies and potential applications for mobile gaming\", 'completionReason': 'FINISH'}]}\n",
      "Latency: 2.3266968727111816 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-12 15:11:49,942] p32262 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1 at concurrency level 1: {'completion': ' You all raise excellent points. A few additional thoughts:\\n\\n- Consider how to involve diverse stakeholders, including subject matter experts, in the development process. Their perspectives can help surface unintended consequences.\\n\\n- Be transparent not just about model decisions, but the entire development process. This builds trust.\\n\\n- Plan for ongoing human oversight. Even the most carefully designed systems may require mid-flight adjustments as real-world use uncovers new issues. \\n\\n- Focus on societal impacts, not just technical metrics. Ensure any AI application meaningfully benefits humanity. \\n\\n- Remain vigilant about potential harms like discrimination, privacy risks, job disruption and more. New issues will emerge over time. \\n\\n- Continually re-evaluate objectives as society\\'s values change. What is considered \"helpful\" today may differ in five or ten years. \\n\\n- Share knowledge and collaborate across companies/research groups. A rising tide lifts all boats when it comes to responsible progress.\\n\\nThe steps you outlined lay a strong foundation. With openness, care and humanity\\'s best interests in mind, I\\'m hopeful the path forward can be a positive one. Please let me know if any other perspectives could be useful to the discussion.', 'stop_reason': 'stop_sequence', 'stop': '\\n\\nHuman:'}\n",
      "Latency: 5.961560964584351 seconds\n",
      "\n",
      "Running anthropic.claude-instant-v1 at concurrency level 1 with 1 requests...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-12 15:11:56,966] p32262 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "[2024-01-12 15:11:56,966] p32262 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "[2024-01-12 15:11:56,966] p32262 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1 at concurrency level 1: {'completion': \" Here are some key points we discussed:\\n\\n- Mobile gaming is a hot space with ongoing opportunities, as shown by Angry Birds' success. \\n\\n- We should research trends to identify openings in the market. \\n\\n- Consider freemium vs paid models, balancing monetization strategies. \\n\\n- In-game ads/sponsorships are alternative revenue streams worth exploring. \\n\\n- User retention and engagement should be top priorities in design.\\n\\n- Rapidly prototyping concepts allows validating demand before heavy development. \\n\\n- AI tools could help speed prototyping by auto-generating basic assets/mechanics for testing.\\n\\n- While AI can automate pieces, official launches still require ensuring a quality standard.\\n\\nThe next steps we agreed on include:\\n\\n1. Researching mobile gaming trends and growth \\n2. Outlining pros/cons of freemium vs paid models\\n3. Exploring in-game ad networks and pricing models  \\n4. Brainstorming user retention strategies\\n5. Defining a process for rapid prototyping and concept testing\\n6. Evaluating AI-powered prototyping tools to complement development\\n\\nPlease let me know if you need any part of the discussion summarized differently or have additional topics to discuss regarding planning for this new mobile gaming startup.\", 'stop_reason': 'stop_sequence', 'stop': '\\n\\nHuman:'}\n",
      "Latency: 6.995261907577515 seconds\n",
      "\n",
      "Running amazon.titan-text-express-v1 at concurrency level 2 with 2 requests...\n",
      "Running anthropic.claude-instant-v1 at concurrency level 2 with 2 requests...\n",
      "Running cohere.command-text-v14 at concurrency level 2 with 2 requests...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-12 15:11:58,652] p32262 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "[2024-01-12 15:12:01,145] p32262 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "[2024-01-12 15:12:01,817] p32262 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "[2024-01-12 15:12:01,892] p32262 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1 at concurrency level 2: {'generations': [{'finish_reason': 'COMPLETE', 'id': '502b905f-98e7-4165-a136-49aa1d24d35b', 'text': \" shouldn't do for our products to ensure consistent and appropriate application of the technology.\\nAction item: Create a document outlining the ethical guidelines for using generative AI, and specify what consequences should apply if these guidelines are not followed.\"}], 'id': '83b8afcf-7ff7-44b8-9f1d-e278392cdfdb', 'prompt': \"A: I wanted to discuss our strategy around generative AI and how we should approach this emerging technology. As you know, several applications have captured a lot of attention recently. \\nAction item: Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n\\nB: Yes, generative AI is definitely a hot topic right now. All the major tech companies seem to be investing heavily in this space.\\nAction item: Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nA: Exactly. I think we need to have a plan here too or risk falling behind. What kind of applications do you see for generative AI in our products? Could it be used to automate certain processes or enhance our users' experience?\\nAction item: Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nC: There's certainly potential, but we'd need to proceed cautiously. While the capabilities are impressive, the technology still has problems with accuracy and bias that could negatively impact customers if we don't validate it thoroughly before rolling anything out.\\nAction item: Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nB: I agree. We'll want to set clear guidelines for what generative AI should and\"}\n",
      "Response 2 at concurrency level 2: {'generations': [{'finish_reason': 'MAX_TOKENS', 'id': '71a7a4dd-23bd-4abb-8f9e-5f180c024540', 'text': ' Based on the conversation between A, B, and C, it seems that the team is working on improving the user experience for their new product launch, specifically in the area of user entry. \\n\\nThe discussion revolved around the issues with the current user entry process, such as multiple steps, additional forms, and difficulties in discovering the product on the landing page.\\n\\nTo address these issues, C will work on making the product more discoverable on the landing page, while B will focus on'}], 'id': '8d77e788-d116-4def-af27-8f9b91c10d4f', 'prompt': 'Meeting transcript: \\nA: Hi B, I want to discuss the workstream for our new product launch\\nB: Sure A, is there anything in particular you want to discuss?\\nA: Yes, I want to talk about how users enter into the product.  \\nB: Ok, in that case let me add in C.\\nC: Hey everyone\\nB: Hi C, A wants to discuss how users enter into the product.\\nA: its too complicated and we should remove friction.  for example, why do I need to fill out additional forms? I also find it difficult to find where to access the product when I first land on the landing page.  \\nB: I would also add that I think there are too many steps.\\nC: Ok, I can work on the landing page to make the product more discoverable but B can you work on the additonal forms?\\nB: Yes but I would need to work with James from another team as he needs to unblock the sign up workflow. A can you document any other concerns so that I can discuss with James only once?\\nA: Sure.'}\n",
      "Latency: 4.952975034713745 seconds\n",
      "\n",
      "Running cohere.command-text-v14 at concurrency level 2 with 2 requests...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-12 15:12:04,286] p32262 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1 at concurrency level 2: {'inputTextTokenCount': 282, 'results': [{'tokenCount': 128, 'outputText': \" should not be used for, and have a process in place to evaluate new applications as they come up.\\n\\nA: That's a good point. We should also keep an eye on the regulatory landscape around generative AI and make sure we're compliant.\\n\\nAction item: Research the regulatory landscape around generative AI and identify any potential risks or compliance issues\\n\\nBy setting up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products, researching current generative AI initiatives at other tech companies to analyze the competitive landscape, outlining high-level ideas for where generative AI could drive automation or\", 'completionReason': 'LENGTH'}]}\n",
      "Response 2 at concurrency level 2: {'inputTextTokenCount': 234, 'results': [{'tokenCount': 65, 'outputText': '\\nA wants to discuss how users enter into the product and proposes removing friction and reducing the number of steps. C can work on the landing page to make the product more discoverable, while B can work with James from another team to unblock the sign-up workflow. A will document any other concerns for discussion with James.', 'completionReason': 'FINISH'}]}\n",
      "Latency: 7.343433141708374 seconds\n",
      "\n",
      "Running amazon.titan-text-express-v1 at concurrency level 2 with 2 requests...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-12 15:12:04,886] p32262 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "[2024-01-12 15:12:05,154] p32262 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1 at concurrency level 2: {'completion': \" You all raise excellent points. While generative AI shows promise, ensuring safety, accuracy and ethics should be top priorities before product integration. Some ideas:\\n\\n- Start small - pilot low-risk applications to test validation frameworks. This allows learning while limiting potential harms. \\n\\n- Involve diverse stakeholders from the beginning. Bring in those representing various communities to advise on issues like bias, privacy and acceptable uses. \\n\\n- Be transparent. Clearly communicate model limitations and oversight measures to build trust with users and regulators. \\n\\n- Continuously evaluate. Monitor applications post-launch and make improvements based on real-world data to strengthen performance and address emerging concerns.\\n\\nThe technology is still evolving rapidly. Moving carefully and accountably now can help us reap benefits while avoiding pitfalls down the road. Does this perspective help further a thoughtful discussion on responsibly exploring generative AI opportunities? I'm happy to discuss any part of the framework in more detail.\", 'stop_reason': 'stop_sequence', 'stop': '\\n\\nHuman:'}\n",
      "Response 2 at concurrency level 2: {'completion': ' Here is a summary of the key discussion points:\\n\\n- A wanted to discuss how users enter the product, finding the current process too complicated with too much friction. \\n\\n- Specifically, A questioned why additional forms need to be filled out and found it difficult to find where to access the product on the landing page.\\n\\n- B agreed there are too many steps in the process.\\n\\n- C offered to work on improving the landing page to make the product more discoverable. \\n\\n- B agreed to work on reducing additional forms but will need to coordinate with James from another team to unblock the signup workflow.  \\n\\n- A agreed to document any other concerns so B can discuss with James in one go to help streamline the process.\\n\\nThe main topics discussed were friction points in the user onboarding/entry process, specifically around forms and discoverability on the landing page. Actions were identified for C to improve discovery and B to streamline forms by working with another team, with A assisting to provide additional feedback.', 'stop_reason': 'stop_sequence', 'stop': '\\n\\nHuman:'}\n",
      "Latency: 8.212053060531616 seconds\n",
      "\n",
      "Running anthropic.claude-instant-v1 at concurrency level 2 with 2 requests...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-12 15:12:06,369] p32262 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1 at concurrency level 2: {'generations': [{'finish_reason': 'COMPLETE', 'id': '17bbc838-cbfc-48cb-8ab0-b922180eac8e', 'text': \" In this discussion, it is generally agreed that using GPU acceleration is necessary for the new product recommendation model because of the sub-second prediction latency needed to provide a good user experience. The team will consider different GPU options from major cloud providers, including NVIDIA's T4 and A100 GPUs, and explore Elastic Inference GPU attachments for fractional GPU access. Compatibility with the model and cost-effectiveness will be the main factors in the decision. \"}], 'id': 'd67ec378-2360-405f-ba8b-06a80f0c0baa', 'prompt': \"A: I wanted to further discuss options for the optimal cloud instance type to host our new product recommendation model. As a refresher on the requirements - this model will be query intensive, with thousands of customers hitting the prediction API simultaneously. And it relies on a large deep neural network for the recommendations. \\n\\nB: Yes, we should go through the pros and cons again of the main instance family options available. For standard instance types without GPUs, we'd likely need to go with a high CPU and memory specification to handle the computation and concurrency needs.\\n\\nC: Standard instances would be more cost-effective, but prediction latency would suffer without GPU acceleration. The neural network calculations could be 5-10x slower based on our initial benchmarks. For a customer-facing model, slow predictions could lead to poor user experience.\\n\\nA: That's a very good point. While GPU-powered instances would be more expensive, the business value of sub-second prediction latency for users is high. We want customers to get engaging, personalized recommendations immediately to drive conversions.\\n\\nB: I agree, I think GPU acceleration makes more sense despite the increased cloud costs. In addition to the deep learning performance boost, some of the other model parallelization and tuning optimizations we're doing would also run faster on GPUs.\\n\\nC: It seems like GPU instances are the way to go then as long as the total monthly cost is affordable. However, we may be able to optimize the specific type of GPU instance to find the best balance of throughput versus cost. \\n\\nA: Definitely, the major cloud providers offer an array of GPU instance types optimized for different use cases. We should benchmark performance against our workload with NVIDIA T4 GPUs, which are cost-optimized options, as well as some higher-end options like A100 GPUs.\\n\\nC: Do you think we should also explore using something like Elastic Inference GPU attachments? Those let you augment existing instances with fractional GPU access that is more cost-effective.\\n\\nB: Hmm good question. In theory that could work well for the cost-performance balance. We'd need to test compatibility with the types of GPU optimizations we're running in the model though...\"}\n",
      "Response 2 at concurrency level 2: {'generations': [{'finish_reason': 'COMPLETE', 'id': '2dd008f4-57ac-4a55-8743-7d68370ab433', 'text': ' As an AI language model, I can help you with drafting an actionable proposal based on the discussion points. Would you like me to outline the proposed AI model safety review framework? '}], 'id': '0388b375-f418-48bd-b88a-48bc60d56b91', 'prompt': \"A: I wanted to have a broader discussion on responsible AI development principles. As we build more AI models, how do we ensure they are helpful, harmless, and aligned with human values?\\n\\nB: This is an important topic. We need to make ethical considerations a priority from the beginning of any AI project, not an afterthought. I think we should develop a review process focused on safety for all new models. \\n\\nAction item: Draft a proposal for an AI model safety review framework \\n\\nC: I agree. We should analyze potential risks like data bias and misuse upfront. Models also need to be secure - what if they were hacked?\\n\\nAction item: Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA: Valid points. Besides analyzing risks, we also need to ensure the objectives we give AI align with human values more broadly. Like being helpful to users, not just maximizing some narrow metric. \\n\\nAction item: Explore methodologies for value alignment in AI systems\\n\\nB: The objectives point connects to transparency too. Any AI decisions that impact users should be explainable. If we can't understand why an AI did something, we can't verify it's aligned.  \\n\\nAction item: Research existing XAI (explainable AI) techniques to augment our models\\n\\nC: Adding explainability makes sense. We should also discuss how to carefully test models before launch to catch additional issues. And have a plan to monitor their impacts over time.\\n\\nAction item: Develop testing and monitoring standards for AI models based on industry best practices\\n\\nA: Great suggestions all around. It seems like we have a blueprint to make responsibility, safety and ethics central to our AI efforts here. I'm optimistic if we build these considerations in from the start, we can drive real progress. Does anyone have any other thoughts before we break?\"}\n",
      "Latency: 4.46789288520813 seconds\n",
      "\n",
      "Running cohere.command-text-v14 at concurrency level 2 with 1 requests...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-12 15:12:08,597] p32262 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "[2024-01-12 15:12:09,338] p32262 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1 at concurrency level 2: {'generations': [{'finish_reason': 'MAX_TOKENS', 'id': '9e6cfca7-cc97-4209-acae-80f579d0a2ad', 'text': ' As the team behind a startup in the mobile gaming space, you each have a role to play in the development and success of the business. It is important to take into consideration your ideas and to take action on those ideas. \\n\\nHere are some potential tasks and assignments to consider: \\n\\n1. Research mobile gaming trends: Identify growth opportunities and gain a comprehensive understanding of the current market. This will help you all make informed decisions about the type of games to develop and how best to engage your'}], 'id': '750faf68-b5cf-4b9a-b792-4619f74311e7', 'prompt': 'A: I wanted to discuss ideas for a new startup in the mobile gaming space. The success of companies like Angry Birds shows there is a lot of potential still untapped. \\nAction item: Research recent trends and growth in mobile gaming to identify opportunities\\n\\nB: I agree mobile gaming is hot right now. Have you thought about potential types of games we could develop? Should we try freemium or paid apps?\\nAction item: Outline pros and cons for freemium vs paid monetization models\\n\\nC: We should consider other business models too like in-game ads or sponsorships. The key is retaining users and driving high engagement.\\nAction item: Explore in-game ad networks and pricing\\nAction item: Brainstorm ideas to maximize user retention \\n\\nA: Those are good points. I also think we need to prototype game concepts quickly to validate demand before investing too heavily in development.\\nAction item: Define process for rapidly prototyping and testing game concepts  \\n\\nB: Yes, we could even use some AI tools now to auto-generate simple game artwork and mechanics. This can help speed up testing. \\nAction item: Evaluate AI-powered game prototyping tools to complement our development efforts\\n\\nC: Automating pieces through AI makes sense. Though we still need to ensure quality bar for any games we officially launch.\\n'}\n",
      "Latency: 3.2582547664642334 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-12 15:12:13,450] p32262 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "[2024-01-12 15:12:13,509] p32262 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1 at concurrency level 2: {'inputTextTokenCount': 460, 'results': [{'tokenCount': 128, 'outputText': \"\\n\\nA: Agreed, it's worth investigating. Another option to consider is using serverless computing platforms like AWS Lambda or GCP Cloud Functions for the prediction API. These platforms can automatically scale to meet demand and can handle bursty traffic without the need for upfront infrastructure investments.\\n\\nB: That's a great point. Serverless could be particularly useful for handling unpredictable spikes in traffic. We'd need to ensure that the model can be deployed and optimized for serverless environments though.\\n\\nC: Definitely, there are some challenges with serverless, but it could be worth exploring as an alternative to managing our own infrastructure\", 'completionReason': 'LENGTH'}]}\n",
      "Response 2 at concurrency level 2: {'inputTextTokenCount': 385, 'results': [{'tokenCount': 128, 'outputText': \"\\n\\nB: One other thing we could consider is how to involve a diverse range of stakeholders in the development process. Different perspectives can help identify and mitigate risks. \\n\\nAction item: Develop a strategy for engaging stakeholders in AI model development and review\\n\\nC: Excellent point. We should also consider how to train AI developers in ethical principles and best practices. \\n\\nAction item: Develop training programs for AI developers on ethical principles and best practices\\n\\nA: All great ideas. Let's summarize our action items and keep this conversation going. We have a lot of work to do, but I'm confident we can build AI systems\", 'completionReason': 'LENGTH'}]}\n",
      "Latency: 9.154606819152832 seconds\n",
      "\n",
      "Running amazon.titan-text-express-v1 at concurrency level 2 with 1 requests...\n",
      "Response 1 at concurrency level 2: {'completion': ' Here are a few key considerations in choosing the optimal cloud instance type for your deep learning model serving workload:\\n\\n- GPU acceleration is important given the performance requirements and customer experience goals. Standard CPU instances would likely not meet latency SLAs.\\n\\n- Benchmark different GPU instance types against your model to find the best throughput-cost balance. Cost-optimized T4 GPUs are a good starting point. \\n\\n- Also test higher-end GPUs like A100 if your model is very computationally intensive. \\n\\n- Elastic Inference GPU attachments could provide a more flexible, cost-effective option than full GPU instances if compatible with your model optimizations. \\n\\n- Ensure any instance type choice can scale horizontally to meet throughput needs under load. \\n\\n- Monitor performance and costs over time to re-evaluate as workloads or budgets change. \\n\\nThe discussion covered the key factors well. Testing different GPU options against your specific model workload is important to validate assumptions and choose the most suitable instance type or configuration.', 'stop_reason': 'stop_sequence', 'stop': '\\n\\nHuman:'}\n",
      "Response 2 at concurrency level 2: {'completion': ' You all raise thoughtful points about ensuring AI systems are developed and used responsibly. A few additional ideas:\\n\\n- Engage diverse stakeholders. Get input from people with different backgrounds and perspectives to help identify potential harms and build trust. \\n\\n- Consider human oversight. While automation can help scale review processes, human judgment remains important for complex issues around values and impacts.\\n\\n- Foster an ethical culture. Make responsibility a priority at all levels, through policies, training, incentives and leadership. Culture will shape whether principles are just words or a lived reality. \\n\\n- Commit to ongoing work. Responsible development requires constant learning as technology and its applications evolve. Humility and openness to critique can help drive long-term progress.\\n\\nThe core of ensuring benefit is ensuring humanity. With care, understanding and cooperation across differences, I believe AI can be developed and applied for good.', 'stop_reason': 'stop_sequence', 'stop': '\\n\\nHuman:'}\n",
      "Latency: 8.358123779296875 seconds\n",
      "\n",
      "Running anthropic.claude-instant-v1 at concurrency level 2 with 1 requests...\n",
      "Response 1 at concurrency level 2: {'inputTextTokenCount': 277, 'results': [{'tokenCount': 50, 'outputText': \"Action item: Outline quality assurance process and standards\\n\\nA: Agreed. Let's schedule a follow-up meeting in two weeks to review our progress and discuss any new ideas.\\nAction item: Set up next meeting and invite key stakeholders\", 'completionReason': 'FINISH'}]}\n",
      "Latency: 2.2012650966644287 seconds\n",
      "\n",
      "Response 1 at concurrency level 2: {'completion': ' Here are the key points discussed:\\n\\n- Mobile gaming is a hot space with continued growth opportunities yet to be tapped\\n- Consider freemium vs paid monetization models, pros and cons of each \\n- Explore other business models like in-game ads or sponsorships to drive engagement and retention\\n- Defining a process for rapidly prototyping and testing game concepts before heavy investment is important\\n- AI-powered tools can help speed up prototyping by auto-generating simple game assets and mechanics\\n- While AI can accelerate prototyping, official launches still require ensuring a quality bar is met\\n\\nThe main action items identified are:\\n\\n1. Research mobile gaming trends and growth \\n2. Outline freemium vs paid monetization models\\n3. Explore in-game ad networks and pricing models\\n4. Brainstorm user retention strategies\\n5. Define a process for rapid prototyping and testing of game concepts\\n6. Evaluate AI tools that can complement development efforts\\n\\nThe discussion focused on exploring opportunities in mobile gaming, validating ideas quickly through prototyping, and leveraging AI where possible to streamline the process while still ensuring quality for official game launches. Does this accurately summarize the key discussion points?', 'stop_reason': 'stop_sequence', 'stop': '\\n\\nHuman:'}\n",
      "Latency: 4.714750051498413 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Function to process all of the models to invoke all transcripts one by one based on the concurrency level\n",
    "async def process_all_models(all_payloads, config, csv_file_path):\n",
    "    with open(csv_file_path, 'a', newline='') as file:\n",
    "        csv_writer = csv.DictWriter(file, fieldnames=['Model_id', 'call transcript', 'Concurrency Level', 'Latency (seconds)', 'Response'])\n",
    "\n",
    "        ## Loop through each concurrency level for each experiment and each model, and create tasks to call process model on the model id and payloads\n",
    "        for concurrency_level in range(1, max(max(model_info['concurrency_levels']) for experiment in config['experiments'] for model_info in experiment['model_list']) + 1):\n",
    "            tasks = []\n",
    "            for experiment in config['experiments']:\n",
    "                for model_info in experiment['model_list']:\n",
    "                    if concurrency_level in model_info['concurrency_levels']:\n",
    "                        task = asyncio.create_task(process_model(model_info, all_payloads, csv_writer, concurrency_level))\n",
    "                        tasks.append(task)\n",
    "            await asyncio.gather(*tasks)\n",
    "\n",
    "csv_file_path = 'async_bedrock_model_performance.csv'\n",
    "init_csv_file(csv_file_path)\n",
    "\n",
    "# Create payloads\n",
    "all_payloads = create_payloads_for_all_models(transcript_files, config)\n",
    "\n",
    "# Run the event loop and get results\n",
    "loop = asyncio.get_event_loop()\n",
    "if loop.is_running():\n",
    "    task = asyncio.ensure_future(process_all_models(all_payloads, config, csv_file_path))\n",
    "else:\n",
    "    loop.run_until_complete(process_all_models(all_payloads, config, csv_file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
