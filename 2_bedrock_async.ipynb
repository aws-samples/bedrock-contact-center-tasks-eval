{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle asynchronous calls for Bedrock Models with concurrent calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/Users/madhurpt/Downloads/bedrock-contact-center-tasks-eval-master-2/utils.py'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "import json\n",
    "import yaml\n",
    "import glob\n",
    "import logging\n",
    "import pandas as pd\n",
    "from tokenizer_utils import count_tokens\n",
    "from bedrock_utils import get_bedrock_client\n",
    "\n",
    "## Re load the utils file to make sure all functions are included from the utils class before importing them\n",
    "import importlib\n",
    "import utils\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set the logger to log all of the information in\n",
    "logging.basicConfig(format='[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize the config file to get all global constants\n",
    "CONFIG_FILE_PATH = \"config.yaml\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-17 09:23:34,644] p60308 {3034282685.py:5} INFO - config read from config.yaml -> {\n",
      "  \"app_name\": \"contact-center-transcript-summarization\",\n",
      "  \"aws\": {\n",
      "    \"region\": \"<your-aws-account-region>\",\n",
      "    \"sagemaker_execution_role\": \"<your-sagemaker-execution-role>\"\n",
      "  },\n",
      "  \"dir\": {\n",
      "    \"data\": \"data\",\n",
      "    \"raw\": \"data/raw\",\n",
      "    \"golden\": \"data/raw/golden\",\n",
      "    \"prompts\": \"data/prompts\",\n",
      "    \"models\": \"data/models\",\n",
      "    \"metrics\": \"data/metrics\",\n",
      "    \"completions\": \"data/completions\",\n",
      "    \"async_completions\": \"data/async_completions\"\n",
      "  },\n",
      "  \"data\": {\n",
      "    \"raw_data_file\": \"data.csv\",\n",
      "    \"golden_transcript\": \"data/raw/golden/transcript.txt\",\n",
      "    \"golden_transcript_summary\": \"data/raw/golden/summary.txt\"\n",
      "  },\n",
      "  \"prompt\": {\n",
      "    \"very_large_prompt\": {\n",
      "      \"sleep_time\": 180,\n",
      "      \"threshold\": 70000\n",
      "    },\n",
      "    \"normal_prompt\": {\n",
      "      \"sleep_time\": 60\n",
      "    }\n",
      "  },\n",
      "  \"max_retries\": 3,\n",
      "  \"desired_word_count_for_summary\": 80,\n",
      "  \"experiments\": [\n",
      "    {\n",
      "      \"name\": \"single-line-reason\",\n",
      "      \"prompt_template\": null,\n",
      "      \"reps\": 3,\n",
      "      \"model_list\": [\n",
      "        {\n",
      "          \"model\": \"amazon.titan-text-express-v1\",\n",
      "          \"prompt_template\": \"titan_template.txt\",\n",
      "          \"concurrency_metric\": [\n",
      "            5\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"model\": \"anthropic.claude-instant-v1\",\n",
      "          \"prompt_template\": \"anthropic_template_single_line_reason.txt\",\n",
      "          \"concurrency_metric\": [\n",
      "            5\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"model\": \"cohere.command-text-v14\",\n",
      "          \"prompt_template\": \"cohere_template.txt\",\n",
      "          \"concurrency_metric\": [\n",
      "            5\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"bedrock_models\": {\n",
      "    \"cohere.command-text-v14\": {\n",
      "      \"context_length\": 4000,\n",
      "      \"prompt_token_pricing_per_million\": 1.5,\n",
      "      \"completion_token_pricing_per_million\": 2.0,\n",
      "      \"inference_param_set\": \"cohere\"\n",
      "    },\n",
      "    \"amazon.titan-text-express-v1\": {\n",
      "      \"context_length\": 8000,\n",
      "      \"prompt_token_pricing_per_million\": 0.8,\n",
      "      \"completion_token_pricing_per_million\": 1.6,\n",
      "      \"inference_param_set\": \"titan\"\n",
      "    },\n",
      "    \"anthropic.claude-v2:1\": {\n",
      "      \"context_length\": 100000,\n",
      "      \"prompt_token_pricing_per_million\": 8,\n",
      "      \"completion_token_pricing_per_million\": 24,\n",
      "      \"inference_param_set\": \"claude\"\n",
      "    },\n",
      "    \"anthropic.claude-instant-v1\": {\n",
      "      \"context_length\": 9000,\n",
      "      \"prompt_token_pricing_per_million\": 1.63,\n",
      "      \"completion_token_pricing_per_million\": 5.51,\n",
      "      \"inference_param_set\": \"claude\"\n",
      "    }\n",
      "  },\n",
      "  \"inference_params\": {\n",
      "    \"claude\": {\n",
      "      \"max_tokens_to_sample\": 512,\n",
      "      \"temperature\": 0.1,\n",
      "      \"top_k\": 250,\n",
      "      \"top_p\": 0.5,\n",
      "      \"stop_sequences\": [],\n",
      "      \"anthropic_version\": \"bedrock-2023-05-31\"\n",
      "    },\n",
      "    \"titan\": {\n",
      "      \"maxTokenCount\": 512,\n",
      "      \"stopSequences\": [],\n",
      "      \"temperature\": 0.1,\n",
      "      \"topP\": 0.9\n",
      "    },\n",
      "    \"cohere\": {\n",
      "      \"max_tokens\": 512,\n",
      "      \"temperature\": 0.1,\n",
      "      \"p\": 0.9,\n",
      "      \"k\": 0\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# read the config yaml file\n",
    "fpath = CONFIG_FILE_PATH\n",
    "with open(fpath, 'r') as yaml_in:\n",
    "    config = yaml.safe_load(yaml_in)\n",
    "logger.info(f\"config read from {fpath} -> {json.dumps(config, indent=2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-17 09:23:35,243] p60308 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new client\n",
      "  Using region: None\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock-runtime(https://bedrock-runtime.us-east-1.amazonaws.com)\n"
     ]
    }
   ],
   "source": [
    "## Initialize the bedrock client\n",
    "bedrock_client = get_bedrock_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-17 09:23:35,743] p60308 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new client\n",
      "  Using region: None\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock(https://bedrock.us-east-1.amazonaws.com)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelArn</th>\n",
       "      <th>modelId</th>\n",
       "      <th>modelName</th>\n",
       "      <th>providerName</th>\n",
       "      <th>inputModalities</th>\n",
       "      <th>outputModalities</th>\n",
       "      <th>responseStreamingSupported</th>\n",
       "      <th>customizationsSupported</th>\n",
       "      <th>inferenceTypesSupported</th>\n",
       "      <th>modelLifecycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-tg1-large</td>\n",
       "      <td>Titan Text Large</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-e1t-medium</td>\n",
       "      <td>Titan Text Embeddings</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[EMBEDDING]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'LEGACY'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-image-generator-v1:0</td>\n",
       "      <td>Titan Image Generator G1</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT, IMAGE]</td>\n",
       "      <td>[IMAGE]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[FINE_TUNING]</td>\n",
       "      <td>[ON_DEMAND, PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-image-generator-v1</td>\n",
       "      <td>Titan Image Generator G1</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT, IMAGE]</td>\n",
       "      <td>[IMAGE]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-embed-g1-text-02</td>\n",
       "      <td>Titan Text Embeddings v2</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[EMBEDDING]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-text-lite-v1:0:4k</td>\n",
       "      <td>Titan Text G1 - Lite</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[FINE_TUNING, CONTINUED_PRE_TRAINING]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-text-lite-v1</td>\n",
       "      <td>Titan Text G1 - Lite</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-text-express-v1:0:8k</td>\n",
       "      <td>Titan Text G1 - Express</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[FINE_TUNING, CONTINUED_PRE_TRAINING]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-text-express-v1</td>\n",
       "      <td>Titan Text G1 - Express</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-embed-text-v1:2:8k</td>\n",
       "      <td>Titan Embeddings G1 - Text</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[EMBEDDING]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-embed-text-v1</td>\n",
       "      <td>Titan Embeddings G1 - Text</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[EMBEDDING]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-embed-image-v1:0</td>\n",
       "      <td>Titan Multimodal Embeddings G1</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT, IMAGE]</td>\n",
       "      <td>[EMBEDDING]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[FINE_TUNING]</td>\n",
       "      <td>[ON_DEMAND, PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/am...</td>\n",
       "      <td>amazon.titan-embed-image-v1</td>\n",
       "      <td>Titan Multimodal Embeddings G1</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>[TEXT, IMAGE]</td>\n",
       "      <td>[EMBEDDING]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/st...</td>\n",
       "      <td>stability.stable-diffusion-xl</td>\n",
       "      <td>SDXL 0.8</td>\n",
       "      <td>Stability AI</td>\n",
       "      <td>[TEXT, IMAGE]</td>\n",
       "      <td>[IMAGE]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/st...</td>\n",
       "      <td>stability.stable-diffusion-xl-v0</td>\n",
       "      <td>SDXL 0.8</td>\n",
       "      <td>Stability AI</td>\n",
       "      <td>[TEXT, IMAGE]</td>\n",
       "      <td>[IMAGE]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/st...</td>\n",
       "      <td>stability.stable-diffusion-xl-v1:0</td>\n",
       "      <td>SDXL 1.0</td>\n",
       "      <td>Stability AI</td>\n",
       "      <td>[TEXT, IMAGE]</td>\n",
       "      <td>[IMAGE]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/st...</td>\n",
       "      <td>stability.stable-diffusion-xl-v1</td>\n",
       "      <td>SDXL 1.0</td>\n",
       "      <td>Stability AI</td>\n",
       "      <td>[TEXT, IMAGE]</td>\n",
       "      <td>[IMAGE]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/ai...</td>\n",
       "      <td>ai21.j2-grande-instruct</td>\n",
       "      <td>J2 Grande Instruct</td>\n",
       "      <td>AI21 Labs</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/ai...</td>\n",
       "      <td>ai21.j2-jumbo-instruct</td>\n",
       "      <td>J2 Jumbo Instruct</td>\n",
       "      <td>AI21 Labs</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/ai...</td>\n",
       "      <td>ai21.j2-mid</td>\n",
       "      <td>Jurassic-2 Mid</td>\n",
       "      <td>AI21 Labs</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/ai...</td>\n",
       "      <td>ai21.j2-mid-v1</td>\n",
       "      <td>Jurassic-2 Mid</td>\n",
       "      <td>AI21 Labs</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/ai...</td>\n",
       "      <td>ai21.j2-ultra</td>\n",
       "      <td>Jurassic-2 Ultra</td>\n",
       "      <td>AI21 Labs</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/ai...</td>\n",
       "      <td>ai21.j2-ultra-v1</td>\n",
       "      <td>Jurassic-2 Ultra</td>\n",
       "      <td>AI21 Labs</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/an...</td>\n",
       "      <td>anthropic.claude-instant-v1:2:100k</td>\n",
       "      <td>Claude Instant</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/an...</td>\n",
       "      <td>anthropic.claude-instant-v1</td>\n",
       "      <td>Claude Instant</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/an...</td>\n",
       "      <td>anthropic.claude-v1</td>\n",
       "      <td>Claude</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'LEGACY'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/an...</td>\n",
       "      <td>anthropic.claude-v2:0:18k</td>\n",
       "      <td>Claude</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/an...</td>\n",
       "      <td>anthropic.claude-v2:0:100k</td>\n",
       "      <td>Claude</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/an...</td>\n",
       "      <td>anthropic.claude-v2:1:18k</td>\n",
       "      <td>Claude</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/an...</td>\n",
       "      <td>anthropic.claude-v2:1:200k</td>\n",
       "      <td>Claude</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/an...</td>\n",
       "      <td>anthropic.claude-v2:1</td>\n",
       "      <td>Claude</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/an...</td>\n",
       "      <td>anthropic.claude-v2</td>\n",
       "      <td>Claude</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/co...</td>\n",
       "      <td>cohere.command-text-v14:7:4k</td>\n",
       "      <td>Command</td>\n",
       "      <td>Cohere</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[FINE_TUNING]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/co...</td>\n",
       "      <td>cohere.command-text-v14</td>\n",
       "      <td>Command</td>\n",
       "      <td>Cohere</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/co...</td>\n",
       "      <td>cohere.command-light-text-v14:7:4k</td>\n",
       "      <td>Command Light</td>\n",
       "      <td>Cohere</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[FINE_TUNING]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/co...</td>\n",
       "      <td>cohere.command-light-text-v14</td>\n",
       "      <td>Command Light</td>\n",
       "      <td>Cohere</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/co...</td>\n",
       "      <td>cohere.embed-english-v3</td>\n",
       "      <td>Embed English</td>\n",
       "      <td>Cohere</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[EMBEDDING]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/co...</td>\n",
       "      <td>cohere.embed-multilingual-v3</td>\n",
       "      <td>Embed Multilingual</td>\n",
       "      <td>Cohere</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[EMBEDDING]</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/me...</td>\n",
       "      <td>meta.llama2-13b-chat-v1:0:4k</td>\n",
       "      <td>Llama 2 Chat 13B</td>\n",
       "      <td>Meta</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[PROVISIONED]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/me...</td>\n",
       "      <td>meta.llama2-13b-chat-v1</td>\n",
       "      <td>Llama 2 Chat 13B</td>\n",
       "      <td>Meta</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/me...</td>\n",
       "      <td>meta.llama2-70b-chat-v1:0:4k</td>\n",
       "      <td>Llama 2 Chat 70B</td>\n",
       "      <td>Meta</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/me...</td>\n",
       "      <td>meta.llama2-70b-chat-v1</td>\n",
       "      <td>Llama 2 Chat 70B</td>\n",
       "      <td>Meta</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ON_DEMAND]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/me...</td>\n",
       "      <td>meta.llama2-13b-v1:0:4k</td>\n",
       "      <td>Llama 2 13B</td>\n",
       "      <td>Meta</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[FINE_TUNING]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/me...</td>\n",
       "      <td>meta.llama2-13b-v1</td>\n",
       "      <td>Llama 2 13B</td>\n",
       "      <td>Meta</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/me...</td>\n",
       "      <td>meta.llama2-70b-v1:0:4k</td>\n",
       "      <td>Llama 2 70B</td>\n",
       "      <td>Meta</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[FINE_TUNING]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>arn:aws:bedrock:us-east-1::foundation-model/me...</td>\n",
       "      <td>meta.llama2-70b-v1</td>\n",
       "      <td>Llama 2 70B</td>\n",
       "      <td>Meta</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>[TEXT]</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'status': 'ACTIVE'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             modelArn  \\\n",
       "0   arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "1   arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "2   arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "3   arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "4   arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "5   arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "6   arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "7   arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "8   arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "9   arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "10  arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "11  arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "12  arn:aws:bedrock:us-east-1::foundation-model/am...   \n",
       "13  arn:aws:bedrock:us-east-1::foundation-model/st...   \n",
       "14  arn:aws:bedrock:us-east-1::foundation-model/st...   \n",
       "15  arn:aws:bedrock:us-east-1::foundation-model/st...   \n",
       "16  arn:aws:bedrock:us-east-1::foundation-model/st...   \n",
       "17  arn:aws:bedrock:us-east-1::foundation-model/ai...   \n",
       "18  arn:aws:bedrock:us-east-1::foundation-model/ai...   \n",
       "19  arn:aws:bedrock:us-east-1::foundation-model/ai...   \n",
       "20  arn:aws:bedrock:us-east-1::foundation-model/ai...   \n",
       "21  arn:aws:bedrock:us-east-1::foundation-model/ai...   \n",
       "22  arn:aws:bedrock:us-east-1::foundation-model/ai...   \n",
       "23  arn:aws:bedrock:us-east-1::foundation-model/an...   \n",
       "24  arn:aws:bedrock:us-east-1::foundation-model/an...   \n",
       "25  arn:aws:bedrock:us-east-1::foundation-model/an...   \n",
       "26  arn:aws:bedrock:us-east-1::foundation-model/an...   \n",
       "27  arn:aws:bedrock:us-east-1::foundation-model/an...   \n",
       "28  arn:aws:bedrock:us-east-1::foundation-model/an...   \n",
       "29  arn:aws:bedrock:us-east-1::foundation-model/an...   \n",
       "30  arn:aws:bedrock:us-east-1::foundation-model/an...   \n",
       "31  arn:aws:bedrock:us-east-1::foundation-model/an...   \n",
       "32  arn:aws:bedrock:us-east-1::foundation-model/co...   \n",
       "33  arn:aws:bedrock:us-east-1::foundation-model/co...   \n",
       "34  arn:aws:bedrock:us-east-1::foundation-model/co...   \n",
       "35  arn:aws:bedrock:us-east-1::foundation-model/co...   \n",
       "36  arn:aws:bedrock:us-east-1::foundation-model/co...   \n",
       "37  arn:aws:bedrock:us-east-1::foundation-model/co...   \n",
       "38  arn:aws:bedrock:us-east-1::foundation-model/me...   \n",
       "39  arn:aws:bedrock:us-east-1::foundation-model/me...   \n",
       "40  arn:aws:bedrock:us-east-1::foundation-model/me...   \n",
       "41  arn:aws:bedrock:us-east-1::foundation-model/me...   \n",
       "42  arn:aws:bedrock:us-east-1::foundation-model/me...   \n",
       "43  arn:aws:bedrock:us-east-1::foundation-model/me...   \n",
       "44  arn:aws:bedrock:us-east-1::foundation-model/me...   \n",
       "45  arn:aws:bedrock:us-east-1::foundation-model/me...   \n",
       "\n",
       "                               modelId                       modelName  \\\n",
       "0               amazon.titan-tg1-large                Titan Text Large   \n",
       "1              amazon.titan-e1t-medium           Titan Text Embeddings   \n",
       "2    amazon.titan-image-generator-v1:0        Titan Image Generator G1   \n",
       "3      amazon.titan-image-generator-v1        Titan Image Generator G1   \n",
       "4        amazon.titan-embed-g1-text-02        Titan Text Embeddings v2   \n",
       "5       amazon.titan-text-lite-v1:0:4k            Titan Text G1 - Lite   \n",
       "6            amazon.titan-text-lite-v1            Titan Text G1 - Lite   \n",
       "7    amazon.titan-text-express-v1:0:8k         Titan Text G1 - Express   \n",
       "8         amazon.titan-text-express-v1         Titan Text G1 - Express   \n",
       "9      amazon.titan-embed-text-v1:2:8k      Titan Embeddings G1 - Text   \n",
       "10          amazon.titan-embed-text-v1      Titan Embeddings G1 - Text   \n",
       "11       amazon.titan-embed-image-v1:0  Titan Multimodal Embeddings G1   \n",
       "12         amazon.titan-embed-image-v1  Titan Multimodal Embeddings G1   \n",
       "13       stability.stable-diffusion-xl                        SDXL 0.8   \n",
       "14    stability.stable-diffusion-xl-v0                        SDXL 0.8   \n",
       "15  stability.stable-diffusion-xl-v1:0                        SDXL 1.0   \n",
       "16    stability.stable-diffusion-xl-v1                        SDXL 1.0   \n",
       "17             ai21.j2-grande-instruct              J2 Grande Instruct   \n",
       "18              ai21.j2-jumbo-instruct               J2 Jumbo Instruct   \n",
       "19                         ai21.j2-mid                  Jurassic-2 Mid   \n",
       "20                      ai21.j2-mid-v1                  Jurassic-2 Mid   \n",
       "21                       ai21.j2-ultra                Jurassic-2 Ultra   \n",
       "22                    ai21.j2-ultra-v1                Jurassic-2 Ultra   \n",
       "23  anthropic.claude-instant-v1:2:100k                  Claude Instant   \n",
       "24         anthropic.claude-instant-v1                  Claude Instant   \n",
       "25                 anthropic.claude-v1                          Claude   \n",
       "26           anthropic.claude-v2:0:18k                          Claude   \n",
       "27          anthropic.claude-v2:0:100k                          Claude   \n",
       "28           anthropic.claude-v2:1:18k                          Claude   \n",
       "29          anthropic.claude-v2:1:200k                          Claude   \n",
       "30               anthropic.claude-v2:1                          Claude   \n",
       "31                 anthropic.claude-v2                          Claude   \n",
       "32        cohere.command-text-v14:7:4k                         Command   \n",
       "33             cohere.command-text-v14                         Command   \n",
       "34  cohere.command-light-text-v14:7:4k                   Command Light   \n",
       "35       cohere.command-light-text-v14                   Command Light   \n",
       "36             cohere.embed-english-v3                   Embed English   \n",
       "37        cohere.embed-multilingual-v3              Embed Multilingual   \n",
       "38        meta.llama2-13b-chat-v1:0:4k                Llama 2 Chat 13B   \n",
       "39             meta.llama2-13b-chat-v1                Llama 2 Chat 13B   \n",
       "40        meta.llama2-70b-chat-v1:0:4k                Llama 2 Chat 70B   \n",
       "41             meta.llama2-70b-chat-v1                Llama 2 Chat 70B   \n",
       "42             meta.llama2-13b-v1:0:4k                     Llama 2 13B   \n",
       "43                  meta.llama2-13b-v1                     Llama 2 13B   \n",
       "44             meta.llama2-70b-v1:0:4k                     Llama 2 70B   \n",
       "45                  meta.llama2-70b-v1                     Llama 2 70B   \n",
       "\n",
       "    providerName inputModalities outputModalities responseStreamingSupported  \\\n",
       "0         Amazon          [TEXT]           [TEXT]                       True   \n",
       "1         Amazon          [TEXT]      [EMBEDDING]                        NaN   \n",
       "2         Amazon   [TEXT, IMAGE]          [IMAGE]                        NaN   \n",
       "3         Amazon   [TEXT, IMAGE]          [IMAGE]                        NaN   \n",
       "4         Amazon          [TEXT]      [EMBEDDING]                        NaN   \n",
       "5         Amazon          [TEXT]           [TEXT]                       True   \n",
       "6         Amazon          [TEXT]           [TEXT]                       True   \n",
       "7         Amazon          [TEXT]           [TEXT]                       True   \n",
       "8         Amazon          [TEXT]           [TEXT]                       True   \n",
       "9         Amazon          [TEXT]      [EMBEDDING]                      False   \n",
       "10        Amazon          [TEXT]      [EMBEDDING]                      False   \n",
       "11        Amazon   [TEXT, IMAGE]      [EMBEDDING]                        NaN   \n",
       "12        Amazon   [TEXT, IMAGE]      [EMBEDDING]                        NaN   \n",
       "13  Stability AI   [TEXT, IMAGE]          [IMAGE]                        NaN   \n",
       "14  Stability AI   [TEXT, IMAGE]          [IMAGE]                        NaN   \n",
       "15  Stability AI   [TEXT, IMAGE]          [IMAGE]                        NaN   \n",
       "16  Stability AI   [TEXT, IMAGE]          [IMAGE]                        NaN   \n",
       "17     AI21 Labs          [TEXT]           [TEXT]                      False   \n",
       "18     AI21 Labs          [TEXT]           [TEXT]                      False   \n",
       "19     AI21 Labs          [TEXT]           [TEXT]                      False   \n",
       "20     AI21 Labs          [TEXT]           [TEXT]                      False   \n",
       "21     AI21 Labs          [TEXT]           [TEXT]                      False   \n",
       "22     AI21 Labs          [TEXT]           [TEXT]                      False   \n",
       "23     Anthropic          [TEXT]           [TEXT]                       True   \n",
       "24     Anthropic          [TEXT]           [TEXT]                       True   \n",
       "25     Anthropic          [TEXT]           [TEXT]                       True   \n",
       "26     Anthropic          [TEXT]           [TEXT]                       True   \n",
       "27     Anthropic          [TEXT]           [TEXT]                       True   \n",
       "28     Anthropic          [TEXT]           [TEXT]                       True   \n",
       "29     Anthropic          [TEXT]           [TEXT]                       True   \n",
       "30     Anthropic          [TEXT]           [TEXT]                       True   \n",
       "31     Anthropic          [TEXT]           [TEXT]                       True   \n",
       "32        Cohere          [TEXT]           [TEXT]                       True   \n",
       "33        Cohere          [TEXT]           [TEXT]                       True   \n",
       "34        Cohere          [TEXT]           [TEXT]                       True   \n",
       "35        Cohere          [TEXT]           [TEXT]                       True   \n",
       "36        Cohere          [TEXT]      [EMBEDDING]                      False   \n",
       "37        Cohere          [TEXT]      [EMBEDDING]                      False   \n",
       "38          Meta          [TEXT]           [TEXT]                       True   \n",
       "39          Meta          [TEXT]           [TEXT]                       True   \n",
       "40          Meta          [TEXT]           [TEXT]                       True   \n",
       "41          Meta          [TEXT]           [TEXT]                       True   \n",
       "42          Meta          [TEXT]           [TEXT]                       True   \n",
       "43          Meta          [TEXT]           [TEXT]                       True   \n",
       "44          Meta          [TEXT]           [TEXT]                       True   \n",
       "45          Meta          [TEXT]           [TEXT]                       True   \n",
       "\n",
       "                  customizationsSupported   inferenceTypesSupported  \\\n",
       "0                                      []               [ON_DEMAND]   \n",
       "1                                      []               [ON_DEMAND]   \n",
       "2                           [FINE_TUNING]  [ON_DEMAND, PROVISIONED]   \n",
       "3                                      []               [ON_DEMAND]   \n",
       "4                                      []               [ON_DEMAND]   \n",
       "5   [FINE_TUNING, CONTINUED_PRE_TRAINING]             [PROVISIONED]   \n",
       "6                                      []               [ON_DEMAND]   \n",
       "7   [FINE_TUNING, CONTINUED_PRE_TRAINING]             [PROVISIONED]   \n",
       "8                                      []               [ON_DEMAND]   \n",
       "9                                      []             [PROVISIONED]   \n",
       "10                                     []               [ON_DEMAND]   \n",
       "11                          [FINE_TUNING]  [ON_DEMAND, PROVISIONED]   \n",
       "12                                     []               [ON_DEMAND]   \n",
       "13                                     []               [ON_DEMAND]   \n",
       "14                                     []               [ON_DEMAND]   \n",
       "15                                     []             [PROVISIONED]   \n",
       "16                                     []               [ON_DEMAND]   \n",
       "17                                     []               [ON_DEMAND]   \n",
       "18                                     []               [ON_DEMAND]   \n",
       "19                                     []               [ON_DEMAND]   \n",
       "20                                     []               [ON_DEMAND]   \n",
       "21                                     []               [ON_DEMAND]   \n",
       "22                                     []               [ON_DEMAND]   \n",
       "23                                     []             [PROVISIONED]   \n",
       "24                                     []               [ON_DEMAND]   \n",
       "25                                     []               [ON_DEMAND]   \n",
       "26                                     []             [PROVISIONED]   \n",
       "27                                     []             [PROVISIONED]   \n",
       "28                                     []             [PROVISIONED]   \n",
       "29                                     []             [PROVISIONED]   \n",
       "30                                     []               [ON_DEMAND]   \n",
       "31                                     []               [ON_DEMAND]   \n",
       "32                          [FINE_TUNING]             [PROVISIONED]   \n",
       "33                                     []               [ON_DEMAND]   \n",
       "34                          [FINE_TUNING]             [PROVISIONED]   \n",
       "35                                     []               [ON_DEMAND]   \n",
       "36                                     []               [ON_DEMAND]   \n",
       "37                                     []               [ON_DEMAND]   \n",
       "38                                     []             [PROVISIONED]   \n",
       "39                                     []               [ON_DEMAND]   \n",
       "40                                     []                        []   \n",
       "41                                     []               [ON_DEMAND]   \n",
       "42                          [FINE_TUNING]                        []   \n",
       "43                                     []                        []   \n",
       "44                          [FINE_TUNING]                        []   \n",
       "45                                     []                        []   \n",
       "\n",
       "          modelLifecycle  \n",
       "0   {'status': 'ACTIVE'}  \n",
       "1   {'status': 'LEGACY'}  \n",
       "2   {'status': 'ACTIVE'}  \n",
       "3   {'status': 'ACTIVE'}  \n",
       "4   {'status': 'ACTIVE'}  \n",
       "5   {'status': 'ACTIVE'}  \n",
       "6   {'status': 'ACTIVE'}  \n",
       "7   {'status': 'ACTIVE'}  \n",
       "8   {'status': 'ACTIVE'}  \n",
       "9   {'status': 'ACTIVE'}  \n",
       "10  {'status': 'ACTIVE'}  \n",
       "11  {'status': 'ACTIVE'}  \n",
       "12  {'status': 'ACTIVE'}  \n",
       "13  {'status': 'ACTIVE'}  \n",
       "14  {'status': 'ACTIVE'}  \n",
       "15  {'status': 'ACTIVE'}  \n",
       "16  {'status': 'ACTIVE'}  \n",
       "17  {'status': 'ACTIVE'}  \n",
       "18  {'status': 'ACTIVE'}  \n",
       "19  {'status': 'ACTIVE'}  \n",
       "20  {'status': 'ACTIVE'}  \n",
       "21  {'status': 'ACTIVE'}  \n",
       "22  {'status': 'ACTIVE'}  \n",
       "23  {'status': 'ACTIVE'}  \n",
       "24  {'status': 'ACTIVE'}  \n",
       "25  {'status': 'LEGACY'}  \n",
       "26  {'status': 'ACTIVE'}  \n",
       "27  {'status': 'ACTIVE'}  \n",
       "28  {'status': 'ACTIVE'}  \n",
       "29  {'status': 'ACTIVE'}  \n",
       "30  {'status': 'ACTIVE'}  \n",
       "31  {'status': 'ACTIVE'}  \n",
       "32  {'status': 'ACTIVE'}  \n",
       "33  {'status': 'ACTIVE'}  \n",
       "34  {'status': 'ACTIVE'}  \n",
       "35  {'status': 'ACTIVE'}  \n",
       "36  {'status': 'ACTIVE'}  \n",
       "37  {'status': 'ACTIVE'}  \n",
       "38  {'status': 'ACTIVE'}  \n",
       "39  {'status': 'ACTIVE'}  \n",
       "40  {'status': 'ACTIVE'}  \n",
       "41  {'status': 'ACTIVE'}  \n",
       "42  {'status': 'ACTIVE'}  \n",
       "43  {'status': 'ACTIVE'}  \n",
       "44  {'status': 'ACTIVE'}  \n",
       "45  {'status': 'ACTIVE'}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boto3_bedrock = get_bedrock_client(runtime=False)\n",
    "fm_list_response = boto3_bedrock.list_foundation_models()\n",
    "fm_list = fm_list_response['modelSummaries']\n",
    "df_fm = pd.DataFrame(fm_list)\n",
    "display(df_fm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-17 09:23:36,418] p60308 {3139140113.py:2} INFO - found 5 transcript_files ->\n",
      "['data/raw/0/call_center_transcript_1_transcript.txt', 'data/raw/1/call_center_transcript_0_transcript.txt', 'data/raw/4/call_center_transcript_4_transcript.txt', 'data/raw/3/call_center_transcript_3_transcript.txt', 'data/raw/2/call_center_transcript_2_transcript.txt']\n"
     ]
    }
   ],
   "source": [
    "transcript_files = glob.glob(os.path.join(config['dir']['raw'], \"*\", \"*transcript.txt\"))\n",
    "logger.info(f\"found {len(transcript_files)} transcript_files ->\\n{transcript_files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing all payloads to be sent via the Bedrock REST API for concurrent invocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-17 09:28:06,802] p60308 {3603549333.py:38} INFO - Total number of payloads that are recorded: 15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'model_id': 'amazon.titan-text-express-v1',\n",
       "  'payload': {'inputText': \"A: I wanted to discuss our strategy around generative AI and how we should approach this emerging technology. As you know, several applications have captured a lot of attention recently. \\nAction item: Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n\\nB: Yes, generative AI is definitely a hot topic right now. All the major tech companies seem to be investing heavily in this space.\\nAction item: Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nA: Exactly. I think we need to have a plan here too or risk falling behind. What kind of applications do you see for generative AI in our products? Could it be used to automate certain processes or enhance our users' experience?\\nAction item: Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nC: There's certainly potential, but we'd need to proceed cautiously. While the capabilities are impressive, the technology still has problems with accuracy and bias that could negatively impact customers if we don't validate it thoroughly before rolling anything out.\\nAction item: Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nB: I agree. We'll want to set clear guidelines for what generative AI should and\"}},\n",
       " {'model_id': 'anthropic.claude-instant-v1',\n",
       "  'payload': {'prompt': \"\\n\\nHuman: A: I wanted to discuss our strategy around generative AI and how we should approach this emerging technology. As you know, several applications have captured a lot of attention recently. \\nAction item: Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n\\nB: Yes, generative AI is definitely a hot topic right now. All the major tech companies seem to be investing heavily in this space.\\nAction item: Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nA: Exactly. I think we need to have a plan here too or risk falling behind. What kind of applications do you see for generative AI in our products? Could it be used to automate certain processes or enhance our users' experience?\\nAction item: Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nC: There's certainly potential, but we'd need to proceed cautiously. While the capabilities are impressive, the technology still has problems with accuracy and bias that could negatively impact customers if we don't validate it thoroughly before rolling anything out.\\nAction item: Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nB: I agree. We'll want to set clear guidelines for what generative AI should and\\n\\nAssistant:\",\n",
       "   'max_tokens_to_sample': 300,\n",
       "   'temperature': 0.5,\n",
       "   'top_k': 250,\n",
       "   'top_p': 1}},\n",
       " {'model_id': 'cohere.command-text-v14',\n",
       "  'payload': {'prompt': \"A: I wanted to discuss our strategy around generative AI and how we should approach this emerging technology. As you know, several applications have captured a lot of attention recently. \\nAction item: Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n\\nB: Yes, generative AI is definitely a hot topic right now. All the major tech companies seem to be investing heavily in this space.\\nAction item: Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nA: Exactly. I think we need to have a plan here too or risk falling behind. What kind of applications do you see for generative AI in our products? Could it be used to automate certain processes or enhance our users' experience?\\nAction item: Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nC: There's certainly potential, but we'd need to proceed cautiously. While the capabilities are impressive, the technology still has problems with accuracy and bias that could negatively impact customers if we don't validate it thoroughly before rolling anything out.\\nAction item: Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nB: I agree. We'll want to set clear guidelines for what generative AI should and\",\n",
       "   'max_tokens': 100,\n",
       "   'temperature': 0.8}},\n",
       " {'model_id': 'amazon.titan-text-express-v1',\n",
       "  'payload': {'inputText': 'Meeting transcript: \\nA: Hi B, I want to discuss the workstream for our new product launch\\nB: Sure A, is there anything in particular you want to discuss?\\nA: Yes, I want to talk about how users enter into the product.  \\nB: Ok, in that case let me add in C.\\nC: Hey everyone\\nB: Hi C, A wants to discuss how users enter into the product.\\nA: its too complicated and we should remove friction.  for example, why do I need to fill out additional forms? I also find it difficult to find where to access the product when I first land on the landing page.  \\nB: I would also add that I think there are too many steps.\\nC: Ok, I can work on the landing page to make the product more discoverable but B can you work on the additonal forms?\\nB: Yes but I would need to work with James from another team as he needs to unblock the sign up workflow. A can you document any other concerns so that I can discuss with James only once?\\nA: Sure.'}},\n",
       " {'model_id': 'anthropic.claude-instant-v1',\n",
       "  'payload': {'prompt': '\\n\\nHuman: Meeting transcript: \\nA: Hi B, I want to discuss the workstream for our new product launch\\nB: Sure A, is there anything in particular you want to discuss?\\nA: Yes, I want to talk about how users enter into the product.  \\nB: Ok, in that case let me add in C.\\nC: Hey everyone\\nB: Hi C, A wants to discuss how users enter into the product.\\nA: its too complicated and we should remove friction.  for example, why do I need to fill out additional forms? I also find it difficult to find where to access the product when I first land on the landing page.  \\nB: I would also add that I think there are too many steps.\\nC: Ok, I can work on the landing page to make the product more discoverable but B can you work on the additonal forms?\\nB: Yes but I would need to work with James from another team as he needs to unblock the sign up workflow. A can you document any other concerns so that I can discuss with James only once?\\nA: Sure.\\n\\nAssistant:',\n",
       "   'max_tokens_to_sample': 300,\n",
       "   'temperature': 0.5,\n",
       "   'top_k': 250,\n",
       "   'top_p': 1}},\n",
       " {'model_id': 'cohere.command-text-v14',\n",
       "  'payload': {'prompt': 'Meeting transcript: \\nA: Hi B, I want to discuss the workstream for our new product launch\\nB: Sure A, is there anything in particular you want to discuss?\\nA: Yes, I want to talk about how users enter into the product.  \\nB: Ok, in that case let me add in C.\\nC: Hey everyone\\nB: Hi C, A wants to discuss how users enter into the product.\\nA: its too complicated and we should remove friction.  for example, why do I need to fill out additional forms? I also find it difficult to find where to access the product when I first land on the landing page.  \\nB: I would also add that I think there are too many steps.\\nC: Ok, I can work on the landing page to make the product more discoverable but B can you work on the additonal forms?\\nB: Yes but I would need to work with James from another team as he needs to unblock the sign up workflow. A can you document any other concerns so that I can discuss with James only once?\\nA: Sure.',\n",
       "   'max_tokens': 100,\n",
       "   'temperature': 0.8}},\n",
       " {'model_id': 'amazon.titan-text-express-v1',\n",
       "  'payload': {'inputText': \"A: I wanted to further discuss options for the optimal cloud instance type to host our new product recommendation model. As a refresher on the requirements - this model will be query intensive, with thousands of customers hitting the prediction API simultaneously. And it relies on a large deep neural network for the recommendations. \\n\\nB: Yes, we should go through the pros and cons again of the main instance family options available. For standard instance types without GPUs, we'd likely need to go with a high CPU and memory specification to handle the computation and concurrency needs.\\n\\nC: Standard instances would be more cost-effective, but prediction latency would suffer without GPU acceleration. The neural network calculations could be 5-10x slower based on our initial benchmarks. For a customer-facing model, slow predictions could lead to poor user experience.\\n\\nA: That's a very good point. While GPU-powered instances would be more expensive, the business value of sub-second prediction latency for users is high. We want customers to get engaging, personalized recommendations immediately to drive conversions.\\n\\nB: I agree, I think GPU acceleration makes more sense despite the increased cloud costs. In addition to the deep learning performance boost, some of the other model parallelization and tuning optimizations we're doing would also run faster on GPUs.\\n\\nC: It seems like GPU instances are the way to go then as long as the total monthly cost is affordable. However, we may be able to optimize the specific type of GPU instance to find the best balance of throughput versus cost. \\n\\nA: Definitely, the major cloud providers offer an array of GPU instance types optimized for different use cases. We should benchmark performance against our workload with NVIDIA T4 GPUs, which are cost-optimized options, as well as some higher-end options like A100 GPUs.\\n\\nC: Do you think we should also explore using something like Elastic Inference GPU attachments? Those let you augment existing instances with fractional GPU access that is more cost-effective.\\n\\nB: Hmm good question. In theory that could work well for the cost-performance balance. We'd need to test compatibility with the types of GPU optimizations we're running in the model though...\"}},\n",
       " {'model_id': 'anthropic.claude-instant-v1',\n",
       "  'payload': {'prompt': \"\\n\\nHuman: A: I wanted to further discuss options for the optimal cloud instance type to host our new product recommendation model. As a refresher on the requirements - this model will be query intensive, with thousands of customers hitting the prediction API simultaneously. And it relies on a large deep neural network for the recommendations. \\n\\nB: Yes, we should go through the pros and cons again of the main instance family options available. For standard instance types without GPUs, we'd likely need to go with a high CPU and memory specification to handle the computation and concurrency needs.\\n\\nC: Standard instances would be more cost-effective, but prediction latency would suffer without GPU acceleration. The neural network calculations could be 5-10x slower based on our initial benchmarks. For a customer-facing model, slow predictions could lead to poor user experience.\\n\\nA: That's a very good point. While GPU-powered instances would be more expensive, the business value of sub-second prediction latency for users is high. We want customers to get engaging, personalized recommendations immediately to drive conversions.\\n\\nB: I agree, I think GPU acceleration makes more sense despite the increased cloud costs. In addition to the deep learning performance boost, some of the other model parallelization and tuning optimizations we're doing would also run faster on GPUs.\\n\\nC: It seems like GPU instances are the way to go then as long as the total monthly cost is affordable. However, we may be able to optimize the specific type of GPU instance to find the best balance of throughput versus cost. \\n\\nA: Definitely, the major cloud providers offer an array of GPU instance types optimized for different use cases. We should benchmark performance against our workload with NVIDIA T4 GPUs, which are cost-optimized options, as well as some higher-end options like A100 GPUs.\\n\\nC: Do you think we should also explore using something like Elastic Inference GPU attachments? Those let you augment existing instances with fractional GPU access that is more cost-effective.\\n\\nB: Hmm good question. In theory that could work well for the cost-performance balance. We'd need to test compatibility with the types of GPU optimizations we're running in the model though...\\n\\nAssistant:\",\n",
       "   'max_tokens_to_sample': 300,\n",
       "   'temperature': 0.5,\n",
       "   'top_k': 250,\n",
       "   'top_p': 1}},\n",
       " {'model_id': 'cohere.command-text-v14',\n",
       "  'payload': {'prompt': \"A: I wanted to further discuss options for the optimal cloud instance type to host our new product recommendation model. As a refresher on the requirements - this model will be query intensive, with thousands of customers hitting the prediction API simultaneously. And it relies on a large deep neural network for the recommendations. \\n\\nB: Yes, we should go through the pros and cons again of the main instance family options available. For standard instance types without GPUs, we'd likely need to go with a high CPU and memory specification to handle the computation and concurrency needs.\\n\\nC: Standard instances would be more cost-effective, but prediction latency would suffer without GPU acceleration. The neural network calculations could be 5-10x slower based on our initial benchmarks. For a customer-facing model, slow predictions could lead to poor user experience.\\n\\nA: That's a very good point. While GPU-powered instances would be more expensive, the business value of sub-second prediction latency for users is high. We want customers to get engaging, personalized recommendations immediately to drive conversions.\\n\\nB: I agree, I think GPU acceleration makes more sense despite the increased cloud costs. In addition to the deep learning performance boost, some of the other model parallelization and tuning optimizations we're doing would also run faster on GPUs.\\n\\nC: It seems like GPU instances are the way to go then as long as the total monthly cost is affordable. However, we may be able to optimize the specific type of GPU instance to find the best balance of throughput versus cost. \\n\\nA: Definitely, the major cloud providers offer an array of GPU instance types optimized for different use cases. We should benchmark performance against our workload with NVIDIA T4 GPUs, which are cost-optimized options, as well as some higher-end options like A100 GPUs.\\n\\nC: Do you think we should also explore using something like Elastic Inference GPU attachments? Those let you augment existing instances with fractional GPU access that is more cost-effective.\\n\\nB: Hmm good question. In theory that could work well for the cost-performance balance. We'd need to test compatibility with the types of GPU optimizations we're running in the model though...\",\n",
       "   'max_tokens': 100,\n",
       "   'temperature': 0.8}},\n",
       " {'model_id': 'amazon.titan-text-express-v1',\n",
       "  'payload': {'inputText': \"A: I wanted to have a broader discussion on responsible AI development principles. As we build more AI models, how do we ensure they are helpful, harmless, and aligned with human values?\\n\\nB: This is an important topic. We need to make ethical considerations a priority from the beginning of any AI project, not an afterthought. I think we should develop a review process focused on safety for all new models. \\n\\nAction item: Draft a proposal for an AI model safety review framework \\n\\nC: I agree. We should analyze potential risks like data bias and misuse upfront. Models also need to be secure - what if they were hacked?\\n\\nAction item: Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA: Valid points. Besides analyzing risks, we also need to ensure the objectives we give AI align with human values more broadly. Like being helpful to users, not just maximizing some narrow metric. \\n\\nAction item: Explore methodologies for value alignment in AI systems\\n\\nB: The objectives point connects to transparency too. Any AI decisions that impact users should be explainable. If we can't understand why an AI did something, we can't verify it's aligned.  \\n\\nAction item: Research existing XAI (explainable AI) techniques to augment our models\\n\\nC: Adding explainability makes sense. We should also discuss how to carefully test models before launch to catch additional issues. And have a plan to monitor their impacts over time.\\n\\nAction item: Develop testing and monitoring standards for AI models based on industry best practices\\n\\nA: Great suggestions all around. It seems like we have a blueprint to make responsibility, safety and ethics central to our AI efforts here. I'm optimistic if we build these considerations in from the start, we can drive real progress. Does anyone have any other thoughts before we break?\"}},\n",
       " {'model_id': 'anthropic.claude-instant-v1',\n",
       "  'payload': {'prompt': \"\\n\\nHuman: A: I wanted to have a broader discussion on responsible AI development principles. As we build more AI models, how do we ensure they are helpful, harmless, and aligned with human values?\\n\\nB: This is an important topic. We need to make ethical considerations a priority from the beginning of any AI project, not an afterthought. I think we should develop a review process focused on safety for all new models. \\n\\nAction item: Draft a proposal for an AI model safety review framework \\n\\nC: I agree. We should analyze potential risks like data bias and misuse upfront. Models also need to be secure - what if they were hacked?\\n\\nAction item: Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA: Valid points. Besides analyzing risks, we also need to ensure the objectives we give AI align with human values more broadly. Like being helpful to users, not just maximizing some narrow metric. \\n\\nAction item: Explore methodologies for value alignment in AI systems\\n\\nB: The objectives point connects to transparency too. Any AI decisions that impact users should be explainable. If we can't understand why an AI did something, we can't verify it's aligned.  \\n\\nAction item: Research existing XAI (explainable AI) techniques to augment our models\\n\\nC: Adding explainability makes sense. We should also discuss how to carefully test models before launch to catch additional issues. And have a plan to monitor their impacts over time.\\n\\nAction item: Develop testing and monitoring standards for AI models based on industry best practices\\n\\nA: Great suggestions all around. It seems like we have a blueprint to make responsibility, safety and ethics central to our AI efforts here. I'm optimistic if we build these considerations in from the start, we can drive real progress. Does anyone have any other thoughts before we break?\\n\\nAssistant:\",\n",
       "   'max_tokens_to_sample': 300,\n",
       "   'temperature': 0.5,\n",
       "   'top_k': 250,\n",
       "   'top_p': 1}},\n",
       " {'model_id': 'cohere.command-text-v14',\n",
       "  'payload': {'prompt': \"A: I wanted to have a broader discussion on responsible AI development principles. As we build more AI models, how do we ensure they are helpful, harmless, and aligned with human values?\\n\\nB: This is an important topic. We need to make ethical considerations a priority from the beginning of any AI project, not an afterthought. I think we should develop a review process focused on safety for all new models. \\n\\nAction item: Draft a proposal for an AI model safety review framework \\n\\nC: I agree. We should analyze potential risks like data bias and misuse upfront. Models also need to be secure - what if they were hacked?\\n\\nAction item: Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA: Valid points. Besides analyzing risks, we also need to ensure the objectives we give AI align with human values more broadly. Like being helpful to users, not just maximizing some narrow metric. \\n\\nAction item: Explore methodologies for value alignment in AI systems\\n\\nB: The objectives point connects to transparency too. Any AI decisions that impact users should be explainable. If we can't understand why an AI did something, we can't verify it's aligned.  \\n\\nAction item: Research existing XAI (explainable AI) techniques to augment our models\\n\\nC: Adding explainability makes sense. We should also discuss how to carefully test models before launch to catch additional issues. And have a plan to monitor their impacts over time.\\n\\nAction item: Develop testing and monitoring standards for AI models based on industry best practices\\n\\nA: Great suggestions all around. It seems like we have a blueprint to make responsibility, safety and ethics central to our AI efforts here. I'm optimistic if we build these considerations in from the start, we can drive real progress. Does anyone have any other thoughts before we break?\",\n",
       "   'max_tokens': 100,\n",
       "   'temperature': 0.8}},\n",
       " {'model_id': 'amazon.titan-text-express-v1',\n",
       "  'payload': {'inputText': 'A: I wanted to discuss ideas for a new startup in the mobile gaming space. The success of companies like Angry Birds shows there is a lot of potential still untapped. \\nAction item: Research recent trends and growth in mobile gaming to identify opportunities\\n\\nB: I agree mobile gaming is hot right now. Have you thought about potential types of games we could develop? Should we try freemium or paid apps?\\nAction item: Outline pros and cons for freemium vs paid monetization models\\n\\nC: We should consider other business models too like in-game ads or sponsorships. The key is retaining users and driving high engagement.\\nAction item: Explore in-game ad networks and pricing\\nAction item: Brainstorm ideas to maximize user retention \\n\\nA: Those are good points. I also think we need to prototype game concepts quickly to validate demand before investing too heavily in development.\\nAction item: Define process for rapidly prototyping and testing game concepts  \\n\\nB: Yes, we could even use some AI tools now to auto-generate simple game artwork and mechanics. This can help speed up testing. \\nAction item: Evaluate AI-powered game prototyping tools to complement our development efforts\\n\\nC: Automating pieces through AI makes sense. Though we still need to ensure quality bar for any games we officially launch.\\n'}},\n",
       " {'model_id': 'anthropic.claude-instant-v1',\n",
       "  'payload': {'prompt': '\\n\\nHuman: A: I wanted to discuss ideas for a new startup in the mobile gaming space. The success of companies like Angry Birds shows there is a lot of potential still untapped. \\nAction item: Research recent trends and growth in mobile gaming to identify opportunities\\n\\nB: I agree mobile gaming is hot right now. Have you thought about potential types of games we could develop? Should we try freemium or paid apps?\\nAction item: Outline pros and cons for freemium vs paid monetization models\\n\\nC: We should consider other business models too like in-game ads or sponsorships. The key is retaining users and driving high engagement.\\nAction item: Explore in-game ad networks and pricing\\nAction item: Brainstorm ideas to maximize user retention \\n\\nA: Those are good points. I also think we need to prototype game concepts quickly to validate demand before investing too heavily in development.\\nAction item: Define process for rapidly prototyping and testing game concepts  \\n\\nB: Yes, we could even use some AI tools now to auto-generate simple game artwork and mechanics. This can help speed up testing. \\nAction item: Evaluate AI-powered game prototyping tools to complement our development efforts\\n\\nC: Automating pieces through AI makes sense. Though we still need to ensure quality bar for any games we officially launch.\\n\\n\\nAssistant:',\n",
       "   'max_tokens_to_sample': 300,\n",
       "   'temperature': 0.5,\n",
       "   'top_k': 250,\n",
       "   'top_p': 1}},\n",
       " {'model_id': 'cohere.command-text-v14',\n",
       "  'payload': {'prompt': 'A: I wanted to discuss ideas for a new startup in the mobile gaming space. The success of companies like Angry Birds shows there is a lot of potential still untapped. \\nAction item: Research recent trends and growth in mobile gaming to identify opportunities\\n\\nB: I agree mobile gaming is hot right now. Have you thought about potential types of games we could develop? Should we try freemium or paid apps?\\nAction item: Outline pros and cons for freemium vs paid monetization models\\n\\nC: We should consider other business models too like in-game ads or sponsorships. The key is retaining users and driving high engagement.\\nAction item: Explore in-game ad networks and pricing\\nAction item: Brainstorm ideas to maximize user retention \\n\\nA: Those are good points. I also think we need to prototype game concepts quickly to validate demand before investing too heavily in development.\\nAction item: Define process for rapidly prototyping and testing game concepts  \\n\\nB: Yes, we could even use some AI tools now to auto-generate simple game artwork and mechanics. This can help speed up testing. \\nAction item: Evaluate AI-powered game prototyping tools to complement our development efforts\\n\\nC: Automating pieces through AI makes sense. Though we still need to ensure quality bar for any games we officially launch.\\n',\n",
       "   'max_tokens': 100,\n",
       "   'temperature': 0.8}}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import time\n",
    "from create_payload import model_payloads\n",
    "\n",
    "## Create a payload referring to the model_payloads script\n",
    "def create_payloads_for_all_models(transcript_files, config):\n",
    "\n",
    "    ## initialize a payload dict\n",
    "    all_payloads = []\n",
    "\n",
    "    ## Iterate through all of the transcript files available\n",
    "    for idx, tf in enumerate(transcript_files):\n",
    "        transcript = Path(tf).read_text()\n",
    "        fname = os.path.basename(tf)\n",
    "        file_id = \"_\".join(fname.split('_')[:-1])\n",
    "\n",
    "        ## Iterate through every experiment for each transcript file\n",
    "        for experiment in config['experiments']:\n",
    "            exp_name = experiment['name']\n",
    "            model_list = experiment['model_list']\n",
    "            \n",
    "            ## Iterate through each model for each transcript file\n",
    "            for model_info in model_list:\n",
    "                model_name = model_info['model']\n",
    "                model = config['bedrock_models'].get(model_name)\n",
    "\n",
    "                if model is None:\n",
    "                    logger.error(f\"model={model_name} not found in bedrock_models\")\n",
    "                    continue\n",
    "                \n",
    "                # Use the imported create_payload function to generate the payload\n",
    "                payload_dict = {\n",
    "                    \"model_id\": model_name,\n",
    "                    \"payload\": model_payloads(transcript, model_name) ## Initializing payload function from the script\n",
    "                }\n",
    "                all_payloads.append(payload_dict)\n",
    "    logger.info(f\"Total number of payloads that are recorded: {len(all_payloads)}\")\n",
    "    return all_payloads\n",
    "\n",
    "create_payloads_for_all_models(transcript_files, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the payloads against the Bedrock REST APIs concurrently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import requests as req\n",
    "import botocore.session\n",
    "from botocore.auth import SigV4Auth\n",
    "from botocore.awsrequest import AWSRequest\n",
    "from typing import Dict, List\n",
    "\n",
    "SERVICE_NAME = 'bedrock'\n",
    "region = 'us-east-1'\n",
    "\n",
    "## Utilizing the bedrock REST API to get inference from each bedrock model\n",
    "def get_inference(model_id: str, payload: Dict) -> Dict:\n",
    "    try:\n",
    "        endpoint = f\"https://{SERVICE_NAME}-runtime.{region}.amazonaws.com/model/{model_id}/invoke\"\n",
    "        request_body = json.dumps(payload)\n",
    "\n",
    "        request = AWSRequest(method='POST', url=endpoint, data=request_body, headers={'content-type': 'application/json'})\n",
    "        session = botocore.session.Session()\n",
    "        sigv4 = SigV4Auth(session.get_credentials(), SERVICE_NAME, region)\n",
    "        sigv4.add_auth(request)\n",
    "        prepped = request.prepare()\n",
    "\n",
    "        response = req.post(prepped.url, headers=prepped.headers, data=request_body)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(f\"Error: Received status code {response.status_code}, Response: {response.text}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Exception occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "## Utilize the async calls for creating a thread of model invocations\n",
    "async def async_calls_on_model(model_id, payload):\n",
    "    try:\n",
    "        response = await asyncio.to_thread(get_inference, model_id, payload)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Error in async_calls_on_model: {e}\")\n",
    "        return None\n",
    "\n",
    "async def async_invoke_model(model_name, payloads):\n",
    "    responses = []\n",
    "    for payload in payloads:\n",
    "        response = await async_calls_on_model(model_name, payload)\n",
    "        responses.append(response)\n",
    "    return responses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filter the model payloads by the type of model id offering at bedrock for simpler calling\n",
    "def filter_payloads_for_model(model_name, all_payloads):\n",
    "    return [payload for payload in all_payloads if payload['model_id'] == model_name]\n",
    "\n",
    "## Function to process a model through invoking it with transcripts through various concurrencies in config.yml\n",
    "async def process_model(model_info, all_payloads, csv_writer, concurrency_level):\n",
    "    ## filter the model by the id\n",
    "    model_payloads = filter_payloads_for_model(model_info['model'], all_payloads)\n",
    "\n",
    "    ## loop through the conc levels and the model_payloads\n",
    "    for i in range(0, len(model_payloads), concurrency_level):\n",
    "        batch_payloads = [payload['payload'] for payload in model_payloads[i:i + concurrency_level]]\n",
    "        print(f\"Running {model_info['model']} at concurrency level {concurrency_level}...\")\n",
    "\n",
    "        ## track metrics: latency\n",
    "        start_time = time.time()\n",
    "        responses = await async_invoke_model(model_info['model'], batch_payloads)\n",
    "        end_time = time.time()\n",
    "        latency = (end_time - start_time)  # in seconds\n",
    "\n",
    "        # Log and write each response to the CSV\n",
    "        for j, response in enumerate(responses):\n",
    "            csv_writer.writerow({\n",
    "                'Model_id': model_info['model'],\n",
    "                'input token count': count_tokens(f'{batch_payloads[j]}'),\n",
    "                'Latency (seconds)': latency,\n",
    "                'Concurrency Level': concurrency_level,\n",
    "                'call transcript': batch_payloads[j],\n",
    "                'Response': json.dumps(response)\n",
    "            })\n",
    "            \n",
    "            print(f\"Response {j+1} at concurrency level {concurrency_level} for {model_info['model']}: {response}\")\n",
    "\n",
    "        print(f\"Latency: {latency} seconds\\n\")\n",
    "\n",
    "## save to csv function\n",
    "def init_csv_file(csv_file_path):\n",
    "    with open(csv_file_path, 'w', newline='') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=['Model_id', 'input token count', 'Latency (seconds)', 'Concurrency Level', 'call transcript', 'Response'])\n",
    "        writer.writeheader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to process all of the models to invoke all transcripts one by one based on the concurrency level\n",
    "async def process_all_models(all_payloads, config, csv_file_path):\n",
    "    with open(csv_file_path, 'a', newline='') as file:\n",
    "        csv_writer = csv.DictWriter(file, fieldnames=['Model_id', 'input token count', 'Latency (seconds)', 'Concurrency Level', 'call transcript', 'Response'])\n",
    "\n",
    "        ## Loop through each concurrency level for each experiment and each model, and create tasks to call process model on the model id and payloads\n",
    "        for concurrency_level in range(1, max(max(model_info['concurrency_metric']) for experiment in config['experiments'] for model_info in experiment['model_list']) + 1):\n",
    "            tasks = []\n",
    "            for experiment in config['experiments']:\n",
    "                for model_info in experiment['model_list']:\n",
    "                    if concurrency_level in model_info['concurrency_metric']:\n",
    "                        task = asyncio.create_task(process_model(model_info, all_payloads, csv_writer, concurrency_level))\n",
    "                        time.sleep(2)\n",
    "                        tasks.append(task)\n",
    "            await asyncio.gather(*tasks)\n",
    "\n",
    "csv_file_path = 'async_bedrock_model_performance.csv'\n",
    "init_csv_file(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-17 09:28:11,344] p60308 {3603549333.py:38} INFO - Total number of payloads that are recorded: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-17 09:28:17,399] p60308 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "[2024-01-17 09:28:17,399] p60308 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "[2024-01-17 09:28:17,399] p60308 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running amazon.titan-text-express-v1 at concurrency level 5...\n",
      "Running anthropic.claude-instant-v1 at concurrency level 5...\n",
      "Running cohere.command-text-v14 at concurrency level 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-17 09:28:20,645] p60308 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "[2024-01-17 09:28:21,584] p60308 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "[2024-01-17 09:28:21,779] p60308 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "[2024-01-17 09:28:24,435] p60308 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "[2024-01-17 09:28:25,011] p60308 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "[2024-01-17 09:28:25,568] p60308 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "[2024-01-17 09:28:27,957] p60308 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "[2024-01-17 09:28:28,999] p60308 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "[2024-01-17 09:28:30,315] p60308 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "[2024-01-17 09:28:31,064] p60308 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "[2024-01-17 09:28:31,635] p60308 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1 at concurrency level 5 for amazon.titan-text-express-v1: {'inputTextTokenCount': 282, 'results': [{'tokenCount': 128, 'outputText': \" should not be used for, and ensure that our team has the necessary training and resources to implement it effectively.\\nAction item: Create a policy document outlining our approach to generative AI and distribute it to all relevant stakeholders\\nA: Excellent point. Let's also keep an eye on the regulatory landscape around generative AI. There may be new laws and regulations that we need to comply with in the future.\\nAction item: Stay up to date on regulatory developments and ensure that our policies and practices align with them\\n\\nBy following these action items, we can develop a comprehensive strategy for leveraging generative AI in our products while minimizing risks\", 'completionReason': 'LENGTH'}]}\n",
      "Response 2 at concurrency level 5 for amazon.titan-text-express-v1: {'inputTextTokenCount': 234, 'results': [{'tokenCount': 81, 'outputText': '\\nA and B discuss how users enter into the product. A wants to remove friction and make it more discoverable, while B can work on the additional forms. C can work on the landing page to make the product more discoverable, but B needs to work with James from another team to unblock the sign up workflow. A can document any other concerns so that B can discuss with James only once.', 'completionReason': 'FINISH'}]}\n",
      "Response 3 at concurrency level 5 for amazon.titan-text-express-v1: {'inputTextTokenCount': 460, 'results': [{'tokenCount': 128, 'outputText': \"\\n\\nA: That's a valid concern. We should definitely run some performance tests with Elastic Inference to see if it provides a significant improvement without sacrificing too much performance.\\n\\nB: Agreed. Let's also look into the option of using serverless computing with AWS Lambda for the prediction API. It could handle the bursty traffic and scale automatically based on demand, which could save us on costs.\\n\\nC: That's a great idea. We could use a serverless function to handle the initial request processing and then forward the requests to GPU-powered instances for the actual recommendation calculations.\\n\\nA: Exactly\", 'completionReason': 'LENGTH'}]}\n",
      "Response 4 at concurrency level 5 for amazon.titan-text-express-v1: {'inputTextTokenCount': 385, 'results': [{'tokenCount': 69, 'outputText': \"\\n\\nB: One thing I'd like to add is that we need to engage a diverse range of stakeholders in the discussion around AI safety. This includes experts in ethics, technology, and user experience. Their perspectives can help us identify blind spots and develop more comprehensive solutions.\\n\\nAction item: Identify and engage stakeholders in the AI safety discussion\", 'completionReason': 'FINISH'}]}\n",
      "Response 5 at concurrency level 5 for amazon.titan-text-express-v1: {'inputTextTokenCount': 277, 'results': [{'tokenCount': 61, 'outputText': \"Action item: Establish quality control processes to ensure game releases meet high standards\\n\\nA: Agreed. Let's also stay up to date on emerging technologies like augmented reality and virtual reality. These could open up new gameplay opportunities.\\nAction item: Explore AR/VR technologies and their potential for mobile gaming\", 'completionReason': 'FINISH'}]}\n",
      "Latency: 16.55426526069641 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-17 09:28:34,198] p60308 {credentials.py:1278} INFO - Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1 at concurrency level 5 for cohere.command-text-v14: {'generations': [{'finish_reason': 'MAX_TOKENS', 'id': 'a94c678b-0fb3-4c22-a452-a6ffd020383a', 'text': ' shouldn\\'t be used for, based on the outcomes we\\'re comfortable with, and ensure all teams are aligned before getting started.\\nAction item: Create a set of guidelines for responsible use of generative AI. This should be distributed across relevant teams for feedback and internal discussion. \\n\\nA: Absolutely, we need to avoid the \"garbage in, garbage out\" situation. If we\\'re going to leverage generative AI, we\\'ll need a plan for ensuring the data used to train and test'}], 'id': '1d52418b-55fa-4871-b6da-f2d16f4123af', 'prompt': \"A: I wanted to discuss our strategy around generative AI and how we should approach this emerging technology. As you know, several applications have captured a lot of attention recently. \\nAction item: Set up a follow-up meeting to brainstorm ideas for where generative AI could be applicable in our products\\n\\nB: Yes, generative AI is definitely a hot topic right now. All the major tech companies seem to be investing heavily in this space.\\nAction item: Research current generative AI initiatives at other tech companies to analyze the competitive landscape\\n\\nA: Exactly. I think we need to have a plan here too or risk falling behind. What kind of applications do you see for generative AI in our products? Could it be used to automate certain processes or enhance our users' experience?\\nAction item: Outline high-level ideas for where generative AI could drive automation or enhance user experience in our products\\n\\nC: There's certainly potential, but we'd need to proceed cautiously. While the capabilities are impressive, the technology still has problems with accuracy and bias that could negatively impact customers if we don't validate it thoroughly before rolling anything out.\\nAction item: Develop a validation framework to rigorously assess accuracy, ethics and safety of any generative AI applications we develop\\n\\nB: I agree. We'll want to set clear guidelines for what generative AI should and\"}\n",
      "Response 2 at concurrency level 5 for cohere.command-text-v14: {'generations': [{'finish_reason': 'MAX_TOKENS', 'id': '57b9431f-d92d-418a-8024-03d61e9ca97c', 'text': ' Based on the meeting transcript, it appears that the team is discussing ways to improve the user experience surrounding the entry to their new product. They discuss the pain points of the process, including unnecessary forms, a lack of discoverability, and too many steps. The team members assign tasks to themselves to work on these issues, such as improving the landing page, streamlining the sign-up process, and working with other teams to remove friction. The discussion focuses on specific actions items and owners, with the aim'}], 'id': 'eb4892d3-115d-43bc-b9c3-908e29b01be2', 'prompt': 'Meeting transcript: \\nA: Hi B, I want to discuss the workstream for our new product launch\\nB: Sure A, is there anything in particular you want to discuss?\\nA: Yes, I want to talk about how users enter into the product.  \\nB: Ok, in that case let me add in C.\\nC: Hey everyone\\nB: Hi C, A wants to discuss how users enter into the product.\\nA: its too complicated and we should remove friction.  for example, why do I need to fill out additional forms? I also find it difficult to find where to access the product when I first land on the landing page.  \\nB: I would also add that I think there are too many steps.\\nC: Ok, I can work on the landing page to make the product more discoverable but B can you work on the additonal forms?\\nB: Yes but I would need to work with James from another team as he needs to unblock the sign up workflow. A can you document any other concerns so that I can discuss with James only once?\\nA: Sure.'}\n",
      "Response 3 at concurrency level 5 for cohere.command-text-v14: {'generations': [{'finish_reason': 'COMPLETE', 'id': 'e0d01237-e474-430d-983a-41c4935c02aa', 'text': ' A, B and C discuss the instance type that need to be used to host their new product recommendation model. Given the query intensive nature of the model and the need to serve thousands of customers simultaneously, they conclude that GPU acceleration would provide the fastest predictions even though it would result in higher cloud costs. They agree to evaluate specific types of GPU instances and explore options like Elastic Inference GPU attachments to find the optimal balance of throughput and cost.'}], 'id': 'c4f85453-2178-4d70-b7d5-e3fe88c47e53', 'prompt': \"A: I wanted to further discuss options for the optimal cloud instance type to host our new product recommendation model. As a refresher on the requirements - this model will be query intensive, with thousands of customers hitting the prediction API simultaneously. And it relies on a large deep neural network for the recommendations. \\n\\nB: Yes, we should go through the pros and cons again of the main instance family options available. For standard instance types without GPUs, we'd likely need to go with a high CPU and memory specification to handle the computation and concurrency needs.\\n\\nC: Standard instances would be more cost-effective, but prediction latency would suffer without GPU acceleration. The neural network calculations could be 5-10x slower based on our initial benchmarks. For a customer-facing model, slow predictions could lead to poor user experience.\\n\\nA: That's a very good point. While GPU-powered instances would be more expensive, the business value of sub-second prediction latency for users is high. We want customers to get engaging, personalized recommendations immediately to drive conversions.\\n\\nB: I agree, I think GPU acceleration makes more sense despite the increased cloud costs. In addition to the deep learning performance boost, some of the other model parallelization and tuning optimizations we're doing would also run faster on GPUs.\\n\\nC: It seems like GPU instances are the way to go then as long as the total monthly cost is affordable. However, we may be able to optimize the specific type of GPU instance to find the best balance of throughput versus cost. \\n\\nA: Definitely, the major cloud providers offer an array of GPU instance types optimized for different use cases. We should benchmark performance against our workload with NVIDIA T4 GPUs, which are cost-optimized options, as well as some higher-end options like A100 GPUs.\\n\\nC: Do you think we should also explore using something like Elastic Inference GPU attachments? Those let you augment existing instances with fractional GPU access that is more cost-effective.\\n\\nB: Hmm good question. In theory that could work well for the cost-performance balance. We'd need to test compatibility with the types of GPU optimizations we're running in the model though...\"}\n",
      "Response 4 at concurrency level 5 for cohere.command-text-v14: {'generations': [{'finish_reason': 'COMPLETE', 'id': '682b8c9a-2357-411b-bbe2-48902b4d2711', 'text': ' As an AI model, I can assure you that the discussion of responsible AI development principles is indeed of utmost importance. While I do not have any further contributions to the discussion, I assure you that the action items outlined are solid steps towards ensuring that the development and deployment of AI models are carried out with the utmost consideration for safety, ethics, and human values.\\n\\nAre there any specific questions or concerns regarding the proposed action items that you would like to address further? '}], 'id': 'cef78bd6-8a38-4220-8db7-0b03a9ead255', 'prompt': \"A: I wanted to have a broader discussion on responsible AI development principles. As we build more AI models, how do we ensure they are helpful, harmless, and aligned with human values?\\n\\nB: This is an important topic. We need to make ethical considerations a priority from the beginning of any AI project, not an afterthought. I think we should develop a review process focused on safety for all new models. \\n\\nAction item: Draft a proposal for an AI model safety review framework \\n\\nC: I agree. We should analyze potential risks like data bias and misuse upfront. Models also need to be secure - what if they were hacked?\\n\\nAction item: Outline additional potential safety risks to address such as data/algorithm bias and security\\n\\nA: Valid points. Besides analyzing risks, we also need to ensure the objectives we give AI align with human values more broadly. Like being helpful to users, not just maximizing some narrow metric. \\n\\nAction item: Explore methodologies for value alignment in AI systems\\n\\nB: The objectives point connects to transparency too. Any AI decisions that impact users should be explainable. If we can't understand why an AI did something, we can't verify it's aligned.  \\n\\nAction item: Research existing XAI (explainable AI) techniques to augment our models\\n\\nC: Adding explainability makes sense. We should also discuss how to carefully test models before launch to catch additional issues. And have a plan to monitor their impacts over time.\\n\\nAction item: Develop testing and monitoring standards for AI models based on industry best practices\\n\\nA: Great suggestions all around. It seems like we have a blueprint to make responsibility, safety and ethics central to our AI efforts here. I'm optimistic if we build these considerations in from the start, we can drive real progress. Does anyone have any other thoughts before we break?\"}\n",
      "Response 5 at concurrency level 5 for cohere.command-text-v14: {'generations': [{'finish_reason': 'MAX_TOKENS', 'id': '66a26482-e70e-4b4f-9850-5e9a75327a7e', 'text': ' There are several tasks outlined in this conversation that I can help with:\\n\\n1. Research mobile gaming trends and growth areas. \\n2. Outline the advantages and disadvantages of freemium and paid apps for mobile games.\\n3. Explore in-game advertising networks and sponsorship opportunities.\\n4. Brainstorm and document strategies for user retention and engagement.\\n5. Define a rapid prototyping and testing process for game concepts, with a particular focus on how to leverage AI tools. \\n'}], 'id': '51a8de50-7a9a-4e59-866c-b546599bbc45', 'prompt': 'A: I wanted to discuss ideas for a new startup in the mobile gaming space. The success of companies like Angry Birds shows there is a lot of potential still untapped. \\nAction item: Research recent trends and growth in mobile gaming to identify opportunities\\n\\nB: I agree mobile gaming is hot right now. Have you thought about potential types of games we could develop? Should we try freemium or paid apps?\\nAction item: Outline pros and cons for freemium vs paid monetization models\\n\\nC: We should consider other business models too like in-game ads or sponsorships. The key is retaining users and driving high engagement.\\nAction item: Explore in-game ad networks and pricing\\nAction item: Brainstorm ideas to maximize user retention \\n\\nA: Those are good points. I also think we need to prototype game concepts quickly to validate demand before investing too heavily in development.\\nAction item: Define process for rapidly prototyping and testing game concepts  \\n\\nB: Yes, we could even use some AI tools now to auto-generate simple game artwork and mechanics. This can help speed up testing. \\nAction item: Evaluate AI-powered game prototyping tools to complement our development efforts\\n\\nC: Automating pieces through AI makes sense. Though we still need to ensure quality bar for any games we officially launch.\\n'}\n",
      "Latency: 16.919496059417725 seconds\n",
      "\n",
      "Response 1 at concurrency level 5 for anthropic.claude-instant-v1: {'completion': \" You all raise thoughtful points. While generative AI shows promise, ensuring safety, accuracy and ethical use should be top priorities. Some next steps:\\n\\n1. Map potential applications, but focus initial efforts on low-risk use cases where outputs can be closely monitored and corrected if needed. \\n\\n2. Develop rigorous validation and oversight processes before any public deployment. Independent reviews, user testing and mechanisms for detecting and addressing biases will be important.\\n\\n3. Consult experts in AI safety and ethics to help guide framework development and ongoing evaluation. Their insights will be invaluable as techniques evolve. \\n\\n4. Monitor regulatory discussions and develop compliance strategies. Regulations may lag technology, so proactive guidance will be prudent. \\n\\n5. Communicate transparently with users about capabilities and limitations. Setting clear expectations early will build trust as applications expand.\\n\\nBy taking a cautious, principles-focused approach and continually reevaluating impacts, generative AI can likely be developed responsibly. Does this perspective help continue the discussion productively? I'm happy to discuss any part of the framework in more detail.\", 'stop_reason': 'stop_sequence', 'stop': '\\n\\nHuman:'}\n",
      "Response 2 at concurrency level 5 for anthropic.claude-instant-v1: {'completion': \" Here is a summary of the key discussion points from the meeting transcript:\\n\\n- A wanted to discuss how users enter and access the new product. \\n\\n- A finds the current user onboarding process too complicated with too many steps and friction points like additional forms. \\n\\n- Specifically, A mentioned it is difficult to find where to access the product on the landing page.\\n\\n- B agreed there are too many steps in the process.\\n\\n- C offered to work on improving discoverability on the landing page. \\n\\n- B agreed to work on removing additional forms but will need to coordinate with James from another team to unblock the sign up workflow. \\n\\n- A agreed to document any other concerns so B can discuss with James in one go to streamline the process.\\n\\n- The overall goal discussed was to simplify and streamline the user onboarding and access process for the new product by removing friction points and unnecessary steps/forms based on A's feedback.\\n\\n- Key action items were for C to improve landing page, B to work on forms with James, and A to document further concerns.\", 'stop_reason': 'stop_sequence', 'stop': '\\n\\nHuman:'}\n",
      "Response 3 at concurrency level 5 for anthropic.claude-instant-v1: {'completion': \" Here are a few key points I gathered from your discussion:\\n\\n- GPU acceleration is important to enable sub-second prediction latency for a good customer experience. While more expensive, the business value justifies the cost.\\n\\n- Benchmarking different GPU instance types against your specific workload can help find the optimal balance of throughput and cost. Cost-optimized T4 GPUs as well as higher-end A100 GPUs should be tested. \\n\\n- Elastic Inference GPU attachments could potentially provide a more cost-effective alternative by adding fractional GPU access to existing instances, but compatibility with your model optimizations would need to be verified.\\n\\n- Further testing and benchmarking is warranted to evaluate performance, costs and tradeoffs of the different GPU options before selecting the best cloud instance configuration. \\n\\nOverall it seems you're having a thoughtful discussion around balancing performance, user experience, costs and technical requirements. Continued experimentation and data-driven decision making will help optimize the cloud architecture design. Please let me know if any other considerations come up in your evaluation.\", 'stop_reason': 'stop_sequence', 'stop': '\\n\\nHuman:'}\n",
      "Response 4 at concurrency level 5 for anthropic.claude-instant-v1: {'completion': ' You all raise thoughtful points. A few additional ideas:\\n\\n- Consult experts in ethics, law and society to ensure technical solutions also address human values and social impacts. \\n\\n- Consider how to make review processes transparent and invite feedback from diverse stakeholders, not just internal teams. Public trust depends on openness.\\n\\n- Plan for ongoing accountability. Establish processes to re-evaluate models as technology and society evolve, and address issues that emerge over the long run. \\n\\n- Prioritize use cases that clearly benefit people. When in doubt, choose applications that avoid potential downsides or harms until safety is better understood. \\n\\nThe goal of responsibility requires vigilance as well as vision. By keeping dialogue open, continuously re-examining assumptions and welcoming outside perspective, I believe you have the right approach to build AI that helps and respects humanity. Please let me know if any part of this discussion would benefit from additional viewpoints or resources.', 'stop_reason': 'stop_sequence', 'stop': '\\n\\nHuman:'}\n",
      "Response 5 at concurrency level 5 for anthropic.claude-instant-v1: {'completion': ' Here are some key points I would take away from this discussion:\\n\\n- Mobile gaming is a large and growing market, so there is opportunity to succeed with the right idea and execution. \\n\\n- Freemium and paid models both have pros and cons for monetization that should be weighed based on the game concept. In-game ads and sponsorships could also be explored. \\n\\n- User retention and engagement will be critical for long-term success. Game design should focus on maximizing these factors. \\n\\n- Rapid prototyping of game concepts is important to validate demand before significant development investment. This can help identify promising ideas faster.\\n\\n- AI-powered tools show potential to accelerate the prototyping process by automating certain artwork, mechanics, etc. However, quality must still be ensured for any officially launched games. \\n\\n- An iterative process balancing automated prototyping, testing, refinement and manual development seems wise. This allows validating concepts quickly while maintaining quality standards.\\n\\nThe key will be identifying game ideas with strong retention drivers, testing them rapidly and cheaply via prototyping, then focusing resources on the most promising concepts. Automation can help accelerate prototyping but not replace quality assurance. Both freemium and paid models warrant consideration depending on the game.', 'stop_reason': 'stop_sequence', 'stop': '\\n\\nHuman:'}\n",
      "Latency: 21.058629035949707 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create payloads\n",
    "all_payloads = create_payloads_for_all_models(transcript_files, config)\n",
    "\n",
    "# Run the event loop and get results\n",
    "loop = asyncio.get_event_loop()\n",
    "if loop.is_running():\n",
    "    task = asyncio.ensure_future(process_all_models(all_payloads, config, csv_file_path))\n",
    "else:\n",
    "    loop.run_until_complete(process_all_models(all_payloads, config, csv_file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking metrics as Concurrency level increases/decreases for accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
